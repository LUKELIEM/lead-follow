{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate_Training\n",
    "\n",
    "### **1T-10L: 1 Teams composed of 10 agents **\n",
    "\n",
    "We run single/multiple game-play to evaluate whether organizing agents under a leader-followers team can induce more agents to cross over and gather from the 2nd food pile. \n",
    "\n",
    "10 follower agents are organized into one team with a leader. The leader agent is envisioned to be a drone hovering atop a “target zone” (green frame) and is not physically represented in the game space. In full CTMA implementation, the leader will learn a trajectory for guiding its followers to the area of the game space where they can achieve the global optimum (the 2nd food pile). For now, we have hard-coded eight trajectories for the leader. \n",
    "\n",
    "<img src=\"images/leader-followers.png\" width=\"800\">\n",
    "\n",
    "During training, the follower agents are trained in 2 settings:\n",
    "\n",
    "(1) Static target zone   \n",
    "(2) Moving target zone  \n",
    "\n",
    "During multiple game-play,  we conduct repeated game play (30 episodes) whereby a team of 10 agents loaded with their saved models follow the 8 pre-defined target zone trajectories to the 2nd food pile. Then we average over the results of these games to calculate game metrics for each trajectory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version:  3.6.4\n",
      "Pytorch version: 0.4.1.post2\n",
      "OpenAI Gym version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This is the Crossing game environment\n",
    "from teams_env import CrossingEnv\n",
    "from teams_model import *\n",
    "from interface import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"OpenAI Gym version: {}\".format(gym.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectories\n",
    "\n",
    "These scanarios are essentially trajectories, which are defined by [(pos1, time1), (pos2, time2), (pos3, time3), ...] where:\n",
    "* pos - ((zone position), (zone dimension))\n",
    "* time - duration it stays stationary\n",
    "\n",
    "Trajectories used:\n",
    "\n",
    "<img src=\"images/zone_trajectories.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pace = 50\n",
    "pace = 100\n",
    "\n",
    "trajectories = [\n",
    "    [ # T1 - A south-east trajectory towards the 2nd food pile\n",
    "            {'loc':((10,3),(5,5)), 'duration': pace},\n",
    "            {'loc':((20,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((40,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((50,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T2 - A east-south trajectory towards the 2nd food pile\n",
    "            {'loc':((10,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((20,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((40,3),(5,5)), 'duration': pace},\n",
    "            {'loc':((50,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T3 - A slanted trajectory towards the 2nd food pile\n",
    "            {'loc':((10,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((20,1),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,2),(5,5)), 'duration': pace},\n",
    "            {'loc':((40,3),(5,5)), 'duration': pace},\n",
    "            {'loc':((50,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T4 - A zig-zag trajectory towards the 2nd food pile\n",
    "            {'loc':((10,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((20,10),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,2),(5,5)), 'duration': pace},\n",
    "            {'loc':((40,10),(5,5)), 'duration': pace},\n",
    "            {'loc':((50,2),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400} \n",
    "    ],\n",
    "    [# T5 - A shortened south-east trajectory towards the 2nd food pile\n",
    "            {'loc':((15,3),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((45,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T6 - A shortened east-south trajectory towards the 2nd food pile\n",
    "            {'loc':((15,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((45,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T7 -  A shortened slanted trajectory towards the 2nd food pile\n",
    "            {'loc':((15,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((30,2),(5,5)), 'duration': pace},\n",
    "            {'loc':((45,5),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ],\n",
    "    [# T8 - A super-short trajectory towards the 2nd food pile\n",
    "            {'loc':((15,0),(5,5)), 'duration': pace},\n",
    "            {'loc':((35,2),(5,5)), 'duration': pace},\n",
    "            {'loc':((55,5),(5,5)), 'duration': 400}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Models\n",
    "\n",
    "The code block contains the folder locations of the trained models of follower agents as well as the parameters used in their training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    # Agents trained with a static target zone\n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/',   # scenario=1\n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/',   # scenario=2\n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/',   # scenario=3    \n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s1/',   # scenario=4\n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s2/',   # scenario=5\n",
    "    'models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s3/',   # scenario=6\n",
    "    # Agents trained with a moving target zone, map = food_d37\n",
    "    \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/\",   # scenario=7\n",
    "    \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/\",   # scenario=8 \n",
    "    \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/\",   # scenario=9\n",
    "    \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/\",   # scenario=10 \n",
    "    # Agents trained using moving target zone and map = food_d37_river_w1_d25\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/\",   # scenario=11\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/\",   # scenario=12\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/\",   # scenario=13\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/\"   # scenario=14\n",
    "]\n",
    "\n",
    "# Parameter sets pertaining to the trained models in the folders above (not used in the code)\n",
    "parameters =[ \n",
    "            # Temperature for explore/exploit; penalty per step in river; game steps per episode\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,0),(5,5)),\\\n",
    "             'game_steps':300, 'set': 1},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,1),(5,5)),\\\n",
    "             'game_steps':300, 'set': 2},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,2),(5,5)),\\\n",
    "             'game_steps':300, 'set': 3},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,0),(5,5)),\\\n",
    "             'game_steps':300, 'set': 1},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,1),(5,5)),\\\n",
    "             'game_steps':300, 'set': 2},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'target_zone':((20,2),(5,5)),\\\n",
    "             'game_steps':300, 'set': 3},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[6],\\\n",
    "             'game_steps':600, 'set': 1},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[7],\\\n",
    "             'game_steps':500, 'set': 2},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[6],\\\n",
    "             'game_steps':600, 'set': 1},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[7],\\\n",
    "             'game_steps':500, 'set': 2},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[6],\\\n",
    "             'game_steps':600, 'set': 1},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[7],\\\n",
    "             'game_steps':500, 'set': 2},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[6],\\\n",
    "             'game_steps':600, 'set': 1},\n",
    "            {'temp_start':1.5, 'river_penalty':-1.0, 'target_reward':5.0, 'trajectory':trajectories[7],\\\n",
    "             'game_steps':500, 'set': 2},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Game-Play - Static Target\n",
    "\n",
    "Play a single game with rendering to observe agents' learning and resulting behaviors. A target zone is positioned somewhere in the game space (zone_num), which allows us to evaluate how well follower agents look for and assemble within a target zone in different part of the game space.\n",
    "\n",
    "Change the scenario to load agent models. Change the zone_num to locate the static target zone for the game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load saved model for agent 9\n",
      "\n",
      "Statistics by Agent\n",
      "===================\n",
      "Agent0 reward is 3\n",
      "Agent1 reward is 0\n",
      "Agent2 reward is 1\n",
      "Agent3 reward is 2\n",
      "Agent4 reward is 0\n",
      "Agent5 reward is 3\n",
      "Agent6 reward is 24\n",
      "Agent7 reward is 1\n",
      "Agent8 reward is 0\n",
      "Agent9 reward is 1\n",
      "\n",
      "Statistics in Aggregate\n",
      "=======================\n",
      "Total rewards gathered = 35\n",
      "Av. rewards per agent = 3.50\n",
      "Num agents gathering from 2nd food pile: 2\n",
      "\n",
      "Statistics by Team\n",
      "===================\n",
      "Tribe Vikings has total reward of 35\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from teams_env import CrossingEnv\n",
    "\n",
    "map_name = \"food_d37\"\n",
    "culture = \"pacifist_follower\"\n",
    "\n",
    "zones =[\n",
    "    ((10,0),(5,5)),\n",
    "    ((10,5),(5,5)),\n",
    "    ((10,10),(5,5)),\n",
    "    ((20,0),(5,5)),\n",
    "    ((20,5),(5,5)),\n",
    "    ((20,10),(5,5)),\n",
    "    ((30,0),(5,5)),\n",
    "    ((30,5),(5,5)),    \n",
    "    ((30,10),(5,5)), \n",
    "]\n",
    "\n",
    "\n",
    "################ User Inputs ######################\n",
    "\n",
    "scenario = 10   # This picks the folder from which the followers' trained models are loaded from\n",
    "zone_num = 6   # This picks the location of the target zone for the game\n",
    "episodes = 3000  # This is used to recall a model file trained to a # of episodes\n",
    "\n",
    "####################################################\n",
    "\n",
    "dir_name = folders[scenario-1]\n",
    "target_zone = zones[zone_num-1]\n",
    "\n",
    "\n",
    "# There will be 10 agents - 0 teams of 0 AI agents each and 0 random agent\n",
    "num_ai_agents = 10\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = True\n",
    "SPEED = 1/30\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 7\n",
    "max_episodes = 1\n",
    "max_frames = 1000\n",
    "\n",
    "# Initialize parameters for Crossing and Explore\n",
    "river_penalty = -1\n",
    "crossed = [0 for i in range(num_ai_agents)]  # Keep track of agents gathering from 2nd food pile\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "jumping_zone = False\n",
    "\n",
    "\n",
    "# Load models for AI agents\n",
    "if episodes > 0:\n",
    "    agents= [[] for i in range(num_ai_agents)]\n",
    "    # If episodes is provided (not 0), load the model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        model_file = dir_name+'MA{}_Crossing_ep{}.p'.format(i,episodes)\n",
    "        try:\n",
    "            with open(model_file, 'rb') as f:\n",
    "                print(\"Load saved model for agent {}\".format(i))\n",
    "                agent = Policy(num_frames, num_actions, 0)\n",
    "                optimizer = optim.Adam(agent.parameters(), lr=0.1)\n",
    "\n",
    "                # New way to save and load models - based on: \n",
    "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                _ = load_model(agent, optimizer, f)\n",
    "                agent.eval()\n",
    "                agents[i] = agent\n",
    "        except OSError:\n",
    "            print('Model file not found.')\n",
    "            raise\n",
    "else:\n",
    "    # If episodes=0, start with a freshly initialized model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        print(\"Load AI agent {}\".format(i))\n",
    "        agents.append(Policy(num_frames, num_actions, i))\n",
    "\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load random agent {}\".format(i))\n",
    "    agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "actions = [0 for i in range(num_agents)]\n",
    "tags = [0 for i in range(num_agents)]\n",
    "\n",
    "# Establish tribal association\n",
    "tribes = []\n",
    "tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2], agents[3], agents[4], \\\n",
    "                           agents[5], agents[6], agents[7], agents[8], agents[9]]))\n",
    "tribes[0].set_target_zone(target_zone)\n",
    "\n",
    "#tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "#                    agents=[agents[4], agents[5], agents[6], agents[7]]))\n",
    "#tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "#                    agents=[agents[8], agents[9], agents[10], agents[11]]))\n",
    "# tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[3], \\\n",
    "#                    agents[4], agents[5]]))   # random agents are crazy!!!\n",
    "\n",
    "# 1 tribes of 6 agents, used map defined in food_d37.txt\n",
    "agent_colors = [agent.color for agent in agents]\n",
    "agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "# Added to implement exile and colonize cultures\n",
    "tribe_names = [tribe.name for tribe in tribes]\n",
    "tribe_target_zones = [tribe.target_zone for tribe in tribes]\n",
    "    \n",
    "    \n",
    "env = CrossingEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty, tribes=tribe_names, \\\n",
    "                  target_zones=tribe_target_zones, debug_agent=0)    \n",
    "    \n",
    "for ep in range(max_episodes):\n",
    "    \n",
    "    US_hits = [0 for i in range(num_agents)]\n",
    "    THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "    env_obs = env.reset()  # Environment return observations\n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack observations into data structure compatible with agent Policy\n",
    "    agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "    for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "        agents[i].reset_info()    \n",
    "    \n",
    "    env.render()\n",
    "    time.sleep(SPEED)  # Change speed of video rendering\n",
    "    \n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "    state = np.stack([state]*num_frames)\n",
    "\n",
    "    # Reset LSTM hidden units when episode begins\n",
    "    cx = Variable(torch.zeros(1, 256))\n",
    "    hx = Variable(torch.zeros(1, 256))\n",
    "    \"\"\"\n",
    "\n",
    "    for frame in range(max_frames):\n",
    "\n",
    "        for i in range(num_ai_agents):    # For AI agents\n",
    "            actions[i], _ = select_action(agents[i], agents_obs[i], cuda=False)\n",
    "            if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "        for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "            actions[i] = agents[i].select_action(agents_obs[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "        \"\"\"\n",
    "        For now, we do not implement LSTM\n",
    "        # Select action\n",
    "        action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "        \"\"\"\n",
    "\n",
    "        # if frame % 10 == 0:\n",
    "        #     print (actions)    \n",
    "            \n",
    "        # Perform step        \n",
    "        env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        \"\"\"\n",
    "        For Debug only\n",
    "        print (env_obs)\n",
    "        print (reward)\n",
    "        print (done) \n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(num_ai_agents):\n",
    "            agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "        # Unpack observations into data structure compatible with agent Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        load_info(agents, info, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            US_hits[i] += agents[i].US_hit\n",
    "            THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "        \"\"\"\n",
    "        For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "        # Evict oldest diff add new diff to state\n",
    "        next_state = np.stack([next_state]*num_frames)\n",
    "        next_state[1:, :, :] = state[:-1, :, :]\n",
    "        state = next_state\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        for i in range(num_ai_agents):\n",
    "            agent_reward = sum(agents[i].rewards)\n",
    "            total += agent_reward\n",
    "        \n",
    "        env.render()\n",
    "        time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "        if any(done):\n",
    "            print(\"Done after {} frames\".format(frame))\n",
    "            break\n",
    "        \n",
    "        \n",
    "        if jumping_zone:\n",
    "            if frame % 100 is 0:          # move the target zone to the end\n",
    "                (x,y), (w,h) = env.target_zones[0]\n",
    "                x_random = random.randint(1,20)\n",
    "                y_random = random.randint(-1,3)\n",
    "                env.target_zones[0]= ((min(x+x_random,55),max(min(y+y_random,6), 0)), (w,h))    \n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of AI agents\n",
    "\n",
    "total_rewards = 0\n",
    "total_tags = 0\n",
    "total_US_hits = 0\n",
    "total_THEM_hits = 0\n",
    "\n",
    "print ('\\nStatistics by Agent')\n",
    "print ('===================')\n",
    "for i in range(num_ai_agents):\n",
    "    agent_tags = sum(agents[i].tag_hist)\n",
    "    total_tags += agent_tags\n",
    "#    print (\"Agent{} aggressiveness is {:.2f}\".format(i, sum(agents[i].tag_hist)/frame))\n",
    "\n",
    "    agent_reward = sum(agents[i].rewards)\n",
    "    total_rewards += agent_reward\n",
    "    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "\n",
    "    agent_US_hits = sum(agents[i].US_hits)\n",
    "    agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "    total_US_hits += agent_US_hits\n",
    "    total_THEM_hits += agent_THEM_hits\n",
    "\n",
    "#    print('US agents hit = {}'.format(agent_US_hits))\n",
    "#    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "\n",
    "print ('\\nStatistics in Aggregate')\n",
    "print ('=======================')\n",
    "print ('Total rewards gathered = {}'.format(total_rewards))\n",
    "print ('Av. rewards per agent = {0:.2f}'.format(total_rewards/num_ai_agents))\n",
    "# print ('Num laser fired = {}'.format(total_tags))\n",
    "# print ('Total US Hit (friendly fire) = {}'.format(total_US_hits))\n",
    "# print ('Total THEM Hit = {}'.format(total_THEM_hits))\n",
    "# print ('friendly fire (%) = {0:.3f}'.format(total_US_hits/(total_US_hits+total_THEM_hits+1e-7)))\n",
    "\n",
    "for (i, loc) in env.consumption:\n",
    "    if loc[0] > second_pile_x:\n",
    "        # print ('agent {} gathered an apple in 2nd pile'.format(i))\n",
    "        crossed[i] = 1\n",
    "        \n",
    "print (\"Num agents gathering from 2nd food pile: {}\".format(sum(crossed)))\n",
    "\n",
    "print ('\\nStatistics by Team')\n",
    "print ('===================')\n",
    "top_tribe = None\n",
    "top_tribe_reward = 0\n",
    "\n",
    "for i, tribe in enumerate(tribes):\n",
    "    if tribe.name is not 'Crazies':\n",
    "        tribe_reward = sum(tribe.sum_rewards())\n",
    "        print ('Tribe {} has total reward of {}'.format(tribe.name, tribe_reward))\n",
    "                           \n",
    "        if tribe_reward > top_tribe_reward:   # Keep track of dominating team\n",
    "            top_tribe_reward = tribe_reward\n",
    "            top_tribe = tribe.name\n",
    "\n",
    "# Team dominance calculation\n",
    "if len(tribes) > 1:\n",
    "    print ('Dominating Team: {}'.format(top_tribe))\n",
    "    dominance = top_tribe_reward/((total_rewards-top_tribe_reward+1.1e-7)/(len(tribes)-1))    \n",
    "    print ('Team dominance: {0:.2f}x'.format(dominance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Game-Play - Moving Target\n",
    "\n",
    "Play a single game with rendering to observe agents' learning and resulting behaviors. A target zone moves within the game space based on a trajectory (traj_num),  which allows us to evaluate how well follower agents follow the trajectory of a moving target zone.\n",
    "\n",
    "Change the scenario to load agent models. Change the traj_num to select from one of eight pre-defined trajectories defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load saved model for agent 9\n",
      "\n",
      "Statistics by Agent\n",
      "===================\n",
      "Agent0 reward is -8\n",
      "Agent1 reward is 6\n",
      "Agent2 reward is 0\n",
      "Agent3 reward is -22\n",
      "Agent4 reward is 20\n",
      "Agent5 reward is 0\n",
      "Agent6 reward is 26\n",
      "Agent7 reward is 14\n",
      "Agent8 reward is 1\n",
      "Agent9 reward is -1\n",
      "\n",
      "Statistics in Aggregate\n",
      "=======================\n",
      "Total rewards gathered = 36\n",
      "Av. rewards per agent = 3.60\n",
      "Num agents gathering from 2nd food pile: 5\n",
      "\n",
      "Statistics by Team\n",
      "===================\n",
      "Tribe Vikings has total reward of 36\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from teams_env import CrossingEnv\n",
    "\n",
    "\n",
    "# map_name = \"food_d37\"\n",
    "map_name = \"food_d37_river_w1_d25\"\n",
    "culture = \"pacifist_follower\"\n",
    "\n",
    "################ User Inputs ######################\n",
    "\n",
    "scenario = 12   # This picks the folder from which the followers' trained models are loaded from\n",
    "traj_num = 3   # This picks the trajectory of the moving target zone for the game\n",
    "episodes = 2000  # This is used to recall a model file trained to a # of episodes\n",
    "\n",
    "####################################################\n",
    "\n",
    "\n",
    "trajectory = trajectories[traj_num-1]\n",
    "position = trajectory [0]  # shift the target zone to first position in trajectory\n",
    "target_zone = position['loc']  \n",
    "duration = position['duration']\n",
    "dir_name = folders[scenario-1]\n",
    "\n",
    "\n",
    "# There will be 10 agents - 0 teams of 0 AI agents each and 0 random agent\n",
    "num_ai_agents = 10\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = True\n",
    "SPEED = 1/30\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 7\n",
    "max_episodes = 1\n",
    "max_frames = 800\n",
    "\n",
    "# Initialize parameters for Crossing and Explore\n",
    "river_penalty = -1\n",
    "crossed = [0 for i in range(num_ai_agents)]  # Keep track of agents gathering from 2nd food pile\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "jumping_zone = False\n",
    "\n",
    "\n",
    "# Load models for AI agents\n",
    "if episodes > 0:\n",
    "    agents= [[] for i in range(num_ai_agents)]\n",
    "    # If episodes is provided (not 0), load the model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        model_file = dir_name+'MA{}_Crossing_ep{}.p'.format(i,episodes)\n",
    "        try:\n",
    "            with open(model_file, 'rb') as f:\n",
    "                print(\"Load saved model for agent {}\".format(i))\n",
    "                agent = Policy(num_frames, num_actions, 0)\n",
    "                optimizer = optim.Adam(agent.parameters(), lr=0.1)\n",
    "\n",
    "                # New way to save and load models - based on: \n",
    "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                _ = load_model(agent, optimizer, f)\n",
    "                agent.eval()\n",
    "                agents[i] = agent\n",
    "        except OSError:\n",
    "            print('Model file not found.')\n",
    "            raise\n",
    "else:\n",
    "    # If episodes=0, start with a freshly initialized model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        print(\"Load AI agent {}\".format(i))\n",
    "        agents.append(Policy(num_frames, num_actions, i))\n",
    "\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load random agent {}\".format(i))\n",
    "    agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "actions = [0 for i in range(num_agents)]\n",
    "tags = [0 for i in range(num_agents)]\n",
    "\n",
    "# Establish tribal association\n",
    "tribes = []\n",
    "tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2], agents[3], agents[4], \\\n",
    "                           agents[5], agents[6], agents[7], agents[8], agents[9]]))\n",
    "tribes[0].set_target_zone(target_zone)\n",
    "\n",
    "#tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "#                    agents=[agents[4], agents[5], agents[6], agents[7]]))\n",
    "#tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "#                    agents=[agents[8], agents[9], agents[10], agents[11]]))\n",
    "# tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[3], \\\n",
    "#                    agents[4], agents[5]]))   # random agents are crazy!!!\n",
    "\n",
    "# 1 tribes of 6 agents, used map defined in food_d37.txt\n",
    "agent_colors = [agent.color for agent in agents]\n",
    "agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "# Added to implement exile and colonize cultures\n",
    "tribe_names = [tribe.name for tribe in tribes]\n",
    "tribe_target_zones = [tribe.target_zone for tribe in tribes]\n",
    "    \n",
    "    \n",
    "env = CrossingEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty, tribes=tribe_names, \\\n",
    "                  target_zones=tribe_target_zones, debug_agent=0)    \n",
    "    \n",
    "for ep in range(max_episodes):\n",
    "    \n",
    "    US_hits = [0 for i in range(num_agents)]\n",
    "    THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "    env_obs = env.reset()  # Environment return observations\n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack observations into data structure compatible with agent Policy\n",
    "    agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "    for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "        agents[i].reset_info()    \n",
    "    \n",
    "    env.render()\n",
    "    time.sleep(SPEED)  # Change speed of video rendering\n",
    "    \n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "    state = np.stack([state]*num_frames)\n",
    "\n",
    "    # Reset LSTM hidden units when episode begins\n",
    "    cx = Variable(torch.zeros(1, 256))\n",
    "    hx = Variable(torch.zeros(1, 256))\n",
    "    \"\"\"\n",
    "\n",
    "    index = 0\n",
    "    position = trajectory [index]  # shift the target zone to first position in trajectory\n",
    "    env.target_zones[0] = position['loc']  \n",
    "    duration = position['duration']\n",
    "    \n",
    "    for frame in range(max_frames):\n",
    "        \n",
    "        if (frame+1) % duration == 0:     # time to shift the target zone\n",
    "            index += 1                    # shift the target zone to new point in trajectory \n",
    "            if index < len(trajectory):   \n",
    "                position = trajectory[index]  \n",
    "                duration = position['duration']\n",
    "                env.target_zones[0] = position['loc'] \n",
    "\n",
    "        for i in range(num_ai_agents):    # For AI agents\n",
    "            actions[i], _ = select_action(agents[i], agents_obs[i], cuda=False)\n",
    "            if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "        for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "            actions[i] = agents[i].select_action(agents_obs[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "        \"\"\"\n",
    "        For now, we do not implement LSTM\n",
    "        # Select action\n",
    "        action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "        \"\"\"\n",
    "\n",
    "        # if frame % 10 == 0:\n",
    "        #     print (actions)    \n",
    "            \n",
    "        # Perform step        \n",
    "        env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        \"\"\"\n",
    "        For Debug only\n",
    "        print (env_obs)\n",
    "        print (reward)\n",
    "        print (done) \n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(num_ai_agents):\n",
    "            agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "        # Unpack observations into data structure compatible with agent Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        load_info(agents, info, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            US_hits[i] += agents[i].US_hit\n",
    "            THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "        \"\"\"\n",
    "        For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "        # Evict oldest diff add new diff to state\n",
    "        next_state = np.stack([next_state]*num_frames)\n",
    "        next_state[1:, :, :] = state[:-1, :, :]\n",
    "        state = next_state\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        for i in range(num_ai_agents):\n",
    "            agent_reward = sum(agents[i].rewards)\n",
    "            total += agent_reward\n",
    "        \n",
    "        env.render()\n",
    "        time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "        if any(done):\n",
    "            print(\"Done after {} frames\".format(frame))\n",
    "            break\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of AI agents\n",
    "\n",
    "total_rewards = 0\n",
    "total_tags = 0\n",
    "total_US_hits = 0\n",
    "total_THEM_hits = 0\n",
    "\n",
    "print ('\\nStatistics by Agent')\n",
    "print ('===================')\n",
    "for i in range(num_ai_agents):\n",
    "    agent_tags = sum(agents[i].tag_hist)\n",
    "    total_tags += agent_tags\n",
    "    # print (\"Agent{} aggressiveness is {:.2f}\".format(i, sum(agents[i].tag_hist)/frame))\n",
    "\n",
    "    agent_reward = sum(agents[i].rewards)\n",
    "    total_rewards += agent_reward\n",
    "    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "\n",
    "    agent_US_hits = sum(agents[i].US_hits)\n",
    "    agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "    total_US_hits += agent_US_hits\n",
    "    total_THEM_hits += agent_THEM_hits\n",
    "\n",
    "    # print('US agents hit = {}'.format(agent_US_hits))\n",
    "    # print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "\n",
    "print ('\\nStatistics in Aggregate')\n",
    "print ('=======================')\n",
    "print ('Total rewards gathered = {}'.format(total_rewards))\n",
    "print ('Av. rewards per agent = {0:.2f}'.format(total_rewards/num_ai_agents))\n",
    "# print ('Num laser fired = {}'.format(total_tags))\n",
    "# print ('Total US Hit (friendly fire) = {}'.format(total_US_hits))\n",
    "# print ('Total THEM Hit = {}'.format(total_THEM_hits))\n",
    "# print ('friendly fire (%) = {0:.3f}'.format(total_US_hits/(total_US_hits+total_THEM_hits+1e-7)))\n",
    "        \n",
    "for (i, loc) in env.consumption:\n",
    "    if loc[0] > second_pile_x:\n",
    "        # print ('agent {} gathered an apple in 2nd pile'.format(i))\n",
    "        crossed[i] = 1\n",
    "        \n",
    "print (\"Num agents gathering from 2nd food pile: {}\".format(sum(crossed)))\n",
    "\n",
    "print ('\\nStatistics by Team')\n",
    "print ('===================')\n",
    "top_tribe = None\n",
    "top_tribe_reward = 0\n",
    "\n",
    "for i, tribe in enumerate(tribes):\n",
    "    if tribe.name is not 'Crazies':\n",
    "        tribe_reward = sum(tribe.sum_rewards())\n",
    "        print ('Tribe {} has total reward of {}'.format(tribe.name, tribe_reward))\n",
    "                           \n",
    "        if tribe_reward > top_tribe_reward:   # Keep track of dominating team\n",
    "            top_tribe_reward = tribe_reward\n",
    "            top_tribe = tribe.name\n",
    "\n",
    "# Team dominance calculation\n",
    "if len(tribes) > 1:\n",
    "    print ('Dominating Team: {}'.format(top_tribe))\n",
    "    dominance = top_tribe_reward/((total_rewards-top_tribe_reward+1.1e-7)/(len(tribes)-1))    \n",
    "    print ('Team dominance: {0:.2f}x'.format(dominance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Game-Play - Trajectories (Map = food_d37)\n",
    "\n",
    "Our research requires the gathering of agent and team metrics averaged over 30 episodes of game play. The two metrics gathered and averaged are:\n",
    "\n",
    "* Average agent reward - average number of apples gathered per agent per episode  \n",
    "* The number of agents gathering apples at the 2nd food pile \n",
    "\n",
    "<img src=\"images/leader-followers.png\" width=\"600\">\n",
    "\n",
    "This is a batch run of 30-episode game-plays over:  \n",
    "(1) Trajectories  \n",
    "(2) Training parameters (starting temp, steps/episode, static target loc, or moving target trajectory)  \n",
    "(3) Episodes trained (500, 1000, 1500, 2000, 2500, 3000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Trajectory = T1 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 162.3\n",
      "Av. agent reward = 16.23\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 8.8\n",
      "Agent1 reward is 1.1\n",
      "Agent2 reward is 21.0\n",
      "Agent3 reward is 15.7\n",
      "Agent4 reward is 34.4\n",
      "Agent5 reward is 0.6\n",
      "Agent6 reward is 11.6\n",
      "Agent7 reward is 12.9\n",
      "Agent8 reward is 35.9\n",
      "Agent9 reward is 20.4\n",
      "Training time per epochs: 10.49 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 155.2\n",
      "Av. agent reward = 15.52\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 155.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.6\n",
      "Agent1 reward is 30.6\n",
      "Agent2 reward is 30.2\n",
      "Agent3 reward is 5.7\n",
      "Agent4 reward is 24.3\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 21.1\n",
      "Agent7 reward is 14.4\n",
      "Agent8 reward is 5.6\n",
      "Agent9 reward is 8.7\n",
      "Training time per epochs: 10.00 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 146.5\n",
      "Av. agent reward = 14.65\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 146.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.1\n",
      "Agent1 reward is 22.3\n",
      "Agent2 reward is 21.8\n",
      "Agent3 reward is 27.2\n",
      "Agent4 reward is 20.3\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 15.2\n",
      "Agent7 reward is 1.4\n",
      "Agent8 reward is 3.8\n",
      "Agent9 reward is 18.4\n",
      "Training time per epochs: 10.34 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 125.6\n",
      "Av. agent reward = 12.56\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 125.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 10.0\n",
      "Agent1 reward is 24.7\n",
      "Agent2 reward is 13.9\n",
      "Agent3 reward is 13.6\n",
      "Agent4 reward is 50.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 2.3\n",
      "Agent7 reward is 2.3\n",
      "Agent8 reward is 7.5\n",
      "Agent9 reward is 1.3\n",
      "Training time per epochs: 10.35 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 164.7\n",
      "Av. agent reward = 16.47\n",
      "Agents crossed (2nd food pile) = 4.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 164.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.1\n",
      "Agent1 reward is 24.7\n",
      "Agent2 reward is 5.6\n",
      "Agent3 reward is 49.6\n",
      "Agent4 reward is 40.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 9.4\n",
      "Agent7 reward is 3.0\n",
      "Agent8 reward is 0.3\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.56 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 125.0\n",
      "Av. agent reward = 12.50\n",
      "Agents crossed (2nd food pile) = 4.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 125.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.7\n",
      "Agent1 reward is 24.3\n",
      "Agent2 reward is 3.1\n",
      "Agent3 reward is 45.7\n",
      "Agent4 reward is 24.9\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 4.2\n",
      "Agent7 reward is 3.1\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.01 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 191.8\n",
      "Av. agent reward = 19.18\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 191.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.5\n",
      "Agent1 reward is 27.1\n",
      "Agent2 reward is 22.1\n",
      "Agent3 reward is 10.9\n",
      "Agent4 reward is 20.0\n",
      "Agent5 reward is 22.4\n",
      "Agent6 reward is 37.8\n",
      "Agent7 reward is 25.2\n",
      "Agent8 reward is 14.2\n",
      "Agent9 reward is 11.6\n",
      "Training time per epochs: 9.17 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 198.3\n",
      "Av. agent reward = 19.83\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 198.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.1\n",
      "Agent2 reward is 26.9\n",
      "Agent3 reward is 35.7\n",
      "Agent4 reward is 16.0\n",
      "Agent5 reward is 21.7\n",
      "Agent6 reward is 14.3\n",
      "Agent7 reward is 22.3\n",
      "Agent8 reward is 19.0\n",
      "Agent9 reward is 23.4\n",
      "Training time per epochs: 9.55 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 197.4\n",
      "Av. agent reward = 19.74\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 197.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 14.0\n",
      "Agent2 reward is 37.4\n",
      "Agent3 reward is 34.0\n",
      "Agent4 reward is 9.1\n",
      "Agent5 reward is 20.8\n",
      "Agent6 reward is 18.1\n",
      "Agent7 reward is 25.1\n",
      "Agent8 reward is 12.2\n",
      "Agent9 reward is 26.8\n",
      "Training time per epochs: 9.63 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 161.1\n",
      "Av. agent reward = 16.11\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 161.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 21.0\n",
      "Agent2 reward is 24.8\n",
      "Agent3 reward is 26.6\n",
      "Agent4 reward is 6.3\n",
      "Agent5 reward is 22.5\n",
      "Agent6 reward is 2.1\n",
      "Agent7 reward is 19.0\n",
      "Agent8 reward is 13.1\n",
      "Agent9 reward is 25.8\n",
      "Training time per epochs: 9.57 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 159.4\n",
      "Av. agent reward = 15.94\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 159.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 16.2\n",
      "Agent2 reward is 19.3\n",
      "Agent3 reward is 29.1\n",
      "Agent4 reward is 11.1\n",
      "Agent5 reward is 12.4\n",
      "Agent6 reward is 0.8\n",
      "Agent7 reward is 30.0\n",
      "Agent8 reward is 18.0\n",
      "Agent9 reward is 22.4\n",
      "Training time per epochs: 9.33 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 143.4\n",
      "Av. agent reward = 14.34\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 143.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 15.3\n",
      "Agent2 reward is 25.7\n",
      "Agent3 reward is 25.6\n",
      "Agent4 reward is 7.7\n",
      "Agent5 reward is 6.5\n",
      "Agent6 reward is 0.9\n",
      "Agent7 reward is 26.2\n",
      "Agent8 reward is 14.5\n",
      "Agent9 reward is 21.2\n",
      "Training time per epochs: 9.32 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 200.1\n",
      "Av. agent reward = 20.01\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 200.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 35.0\n",
      "Agent1 reward is 6.7\n",
      "Agent2 reward is 0.6\n",
      "Agent3 reward is 16.6\n",
      "Agent4 reward is 35.5\n",
      "Agent5 reward is 12.9\n",
      "Agent6 reward is 46.8\n",
      "Agent7 reward is 13.5\n",
      "Agent8 reward is 9.0\n",
      "Agent9 reward is 23.4\n",
      "Training time per epochs: 9.50 sec\n",
      "###### Trained episodes = 1000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.8\n",
      "Av. agent reward = 21.18\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 24.3\n",
      "Agent1 reward is 20.0\n",
      "Agent2 reward is 10.3\n",
      "Agent3 reward is 19.8\n",
      "Agent4 reward is 31.3\n",
      "Agent5 reward is 20.0\n",
      "Agent6 reward is 47.5\n",
      "Agent7 reward is 12.5\n",
      "Agent8 reward is 9.8\n",
      "Agent9 reward is 16.3\n",
      "Training time per epochs: 9.49 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 213.4\n",
      "Av. agent reward = 21.34\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 213.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 44.6\n",
      "Agent1 reward is 20.4\n",
      "Agent2 reward is 28.4\n",
      "Agent3 reward is 20.2\n",
      "Agent4 reward is 28.8\n",
      "Agent5 reward is 2.7\n",
      "Agent6 reward is 21.9\n",
      "Agent7 reward is 16.9\n",
      "Agent8 reward is 7.3\n",
      "Agent9 reward is 22.2\n",
      "Training time per epochs: 9.32 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 199.6\n",
      "Av. agent reward = 19.96\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 199.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 55.8\n",
      "Agent1 reward is 10.5\n",
      "Agent2 reward is 34.7\n",
      "Agent3 reward is 21.9\n",
      "Agent4 reward is 16.4\n",
      "Agent5 reward is 1.1\n",
      "Agent6 reward is 9.0\n",
      "Agent7 reward is 19.5\n",
      "Agent8 reward is 4.6\n",
      "Agent9 reward is 26.0\n",
      "Training time per epochs: 9.33 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 205.9\n",
      "Av. agent reward = 20.59\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 205.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 43.1\n",
      "Agent1 reward is 19.9\n",
      "Agent2 reward is 29.1\n",
      "Agent3 reward is 25.8\n",
      "Agent4 reward is 17.5\n",
      "Agent5 reward is 8.0\n",
      "Agent6 reward is 29.3\n",
      "Agent7 reward is 12.4\n",
      "Agent8 reward is 7.7\n",
      "Agent9 reward is 13.1\n",
      "Training time per epochs: 9.56 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.3\n",
      "Av. agent reward = 18.43\n",
      "Agents crossed (2nd food pile) = 5.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.0\n",
      "Agent1 reward is 33.4\n",
      "Agent2 reward is 28.3\n",
      "Agent3 reward is 25.1\n",
      "Agent4 reward is 22.5\n",
      "Agent5 reward is 1.5\n",
      "Agent6 reward is 12.5\n",
      "Agent7 reward is 11.1\n",
      "Agent8 reward is 2.7\n",
      "Agent9 reward is 20.1\n",
      "Training time per epochs: 9.56 sec\n",
      "###### Trajectory = T2 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 166.0\n",
      "Av. agent reward = 16.60\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 166.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 8.0\n",
      "Agent1 reward is 1.3\n",
      "Agent2 reward is 24.7\n",
      "Agent3 reward is 20.5\n",
      "Agent4 reward is 34.7\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 16.3\n",
      "Agent7 reward is 8.8\n",
      "Agent8 reward is 30.0\n",
      "Agent9 reward is 21.5\n",
      "Training time per epochs: 9.45 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 164.6\n",
      "Av. agent reward = 16.46\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 164.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.4\n",
      "Agent1 reward is 34.1\n",
      "Agent2 reward is 29.4\n",
      "Agent3 reward is 9.7\n",
      "Agent4 reward is 17.2\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 19.8\n",
      "Agent7 reward is 14.9\n",
      "Agent8 reward is 6.8\n",
      "Agent9 reward is 13.2\n",
      "Training time per epochs: 9.46 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 158.8\n",
      "Av. agent reward = 15.88\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.0\n",
      "Agent1 reward is 18.7\n",
      "Agent2 reward is 34.9\n",
      "Agent3 reward is 24.4\n",
      "Agent4 reward is 15.2\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 11.2\n",
      "Agent7 reward is 0.0\n",
      "Agent8 reward is 8.9\n",
      "Agent9 reward is 18.5\n",
      "Training time per epochs: 9.21 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 133.0\n",
      "Av. agent reward = 13.30\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 133.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.4\n",
      "Agent1 reward is 19.9\n",
      "Agent2 reward is 18.6\n",
      "Agent3 reward is 15.4\n",
      "Agent4 reward is 41.9\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 0.9\n",
      "Agent7 reward is 1.2\n",
      "Agent8 reward is 17.4\n",
      "Agent9 reward is 3.3\n",
      "Training time per epochs: 9.47 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 165.5\n",
      "Av. agent reward = 16.55\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 165.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 34.5\n",
      "Agent1 reward is 24.3\n",
      "Agent2 reward is 12.3\n",
      "Agent3 reward is 39.1\n",
      "Agent4 reward is 30.1\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 18.9\n",
      "Agent7 reward is 2.5\n",
      "Agent8 reward is 3.9\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.47 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 124.9\n",
      "Av. agent reward = 12.49\n",
      "Agents crossed (2nd food pile) = 4.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 124.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 26.0\n",
      "Agent1 reward is 17.2\n",
      "Agent2 reward is 7.7\n",
      "Agent3 reward is 37.1\n",
      "Agent4 reward is 19.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 15.6\n",
      "Agent7 reward is 0.8\n",
      "Agent8 reward is 1.5\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.45 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 187.7\n",
      "Av. agent reward = 18.77\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 187.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.4\n",
      "Agent1 reward is 26.6\n",
      "Agent2 reward is 25.4\n",
      "Agent3 reward is 12.7\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 21.7\n",
      "Agent6 reward is 25.4\n",
      "Agent7 reward is 23.0\n",
      "Agent8 reward is 15.6\n",
      "Agent9 reward is 18.2\n",
      "Training time per epochs: 9.72 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 189.4\n",
      "Av. agent reward = 18.94\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 189.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.1\n",
      "Agent1 reward is 18.8\n",
      "Agent2 reward is 29.7\n",
      "Agent3 reward is 37.9\n",
      "Agent4 reward is 17.9\n",
      "Agent5 reward is 19.9\n",
      "Agent6 reward is 8.0\n",
      "Agent7 reward is 16.8\n",
      "Agent8 reward is 18.7\n",
      "Agent9 reward is 21.6\n",
      "Training time per epochs: 10.64 sec\n",
      "###### Trained episodes = 1500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 179.2\n",
      "Av. agent reward = 17.92\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 179.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 21.6\n",
      "Agent2 reward is 26.6\n",
      "Agent3 reward is 30.7\n",
      "Agent4 reward is 5.8\n",
      "Agent5 reward is 16.9\n",
      "Agent6 reward is 16.3\n",
      "Agent7 reward is 19.7\n",
      "Agent8 reward is 15.7\n",
      "Agent9 reward is 25.9\n",
      "Training time per epochs: 11.37 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 163.7\n",
      "Av. agent reward = 16.37\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 163.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 22.0\n",
      "Agent2 reward is 21.4\n",
      "Agent3 reward is 23.6\n",
      "Agent4 reward is 5.8\n",
      "Agent5 reward is 18.4\n",
      "Agent6 reward is 3.1\n",
      "Agent7 reward is 20.7\n",
      "Agent8 reward is 18.8\n",
      "Agent9 reward is 29.9\n",
      "Training time per epochs: 9.55 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 163.4\n",
      "Av. agent reward = 16.34\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 163.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 21.5\n",
      "Agent2 reward is 19.4\n",
      "Agent3 reward is 37.3\n",
      "Agent4 reward is 14.4\n",
      "Agent5 reward is 10.7\n",
      "Agent6 reward is 0.2\n",
      "Agent7 reward is 22.7\n",
      "Agent8 reward is 17.1\n",
      "Agent9 reward is 20.1\n",
      "Training time per epochs: 10.10 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 149.7\n",
      "Av. agent reward = 14.97\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 149.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 25.8\n",
      "Agent2 reward is 24.5\n",
      "Agent3 reward is 24.7\n",
      "Agent4 reward is 14.5\n",
      "Agent5 reward is 4.5\n",
      "Agent6 reward is 0.5\n",
      "Agent7 reward is 20.4\n",
      "Agent8 reward is 18.2\n",
      "Agent9 reward is 16.6\n",
      "Training time per epochs: 10.07 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.7\n",
      "Av. agent reward = 21.17\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.6\n",
      "Agent1 reward is 10.6\n",
      "Agent2 reward is 0.9\n",
      "Agent3 reward is 19.2\n",
      "Agent4 reward is 34.0\n",
      "Agent5 reward is 16.4\n",
      "Agent6 reward is 40.7\n",
      "Agent7 reward is 22.6\n",
      "Agent8 reward is 6.4\n",
      "Agent9 reward is 33.2\n",
      "Training time per epochs: 14.86 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 201.2\n",
      "Av. agent reward = 20.12\n",
      "Agents crossed (2nd food pile) = 8.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 201.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.2\n",
      "Agent1 reward is 15.8\n",
      "Agent2 reward is 13.4\n",
      "Agent3 reward is 19.8\n",
      "Agent4 reward is 27.1\n",
      "Agent5 reward is 18.3\n",
      "Agent6 reward is 41.2\n",
      "Agent7 reward is 18.2\n",
      "Agent8 reward is 8.4\n",
      "Agent9 reward is 17.8\n",
      "Training time per epochs: 14.80 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 219.0\n",
      "Av. agent reward = 21.90\n",
      "Agents crossed (2nd food pile) = 8.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 219.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.4\n",
      "Agent1 reward is 19.6\n",
      "Agent2 reward is 25.4\n",
      "Agent3 reward is 39.1\n",
      "Agent4 reward is 20.4\n",
      "Agent5 reward is 12.7\n",
      "Agent6 reward is 21.7\n",
      "Agent7 reward is 21.7\n",
      "Agent8 reward is 5.6\n",
      "Agent9 reward is 22.5\n",
      "Training time per epochs: 15.66 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 195.3\n",
      "Av. agent reward = 19.53\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 195.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 34.9\n",
      "Agent1 reward is 9.4\n",
      "Agent2 reward is 32.1\n",
      "Agent3 reward is 23.6\n",
      "Agent4 reward is 17.7\n",
      "Agent5 reward is 4.0\n",
      "Agent6 reward is 11.9\n",
      "Agent7 reward is 28.3\n",
      "Agent8 reward is 8.7\n",
      "Agent9 reward is 24.7\n",
      "Training time per epochs: 15.11 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 189.0\n",
      "Av. agent reward = 18.90\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 189.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 33.3\n",
      "Agent1 reward is 20.6\n",
      "Agent2 reward is 24.4\n",
      "Agent3 reward is 12.5\n",
      "Agent4 reward is 16.7\n",
      "Agent5 reward is 15.2\n",
      "Agent6 reward is 20.1\n",
      "Agent7 reward is 15.1\n",
      "Agent8 reward is 10.4\n",
      "Agent9 reward is 20.7\n",
      "Training time per epochs: 15.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 229.4\n",
      "Av. agent reward = 22.94\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 229.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 26.9\n",
      "Agent1 reward is 20.0\n",
      "Agent2 reward is 29.2\n",
      "Agent3 reward is 46.0\n",
      "Agent4 reward is 17.1\n",
      "Agent5 reward is 18.4\n",
      "Agent6 reward is 15.3\n",
      "Agent7 reward is 17.2\n",
      "Agent8 reward is 11.9\n",
      "Agent9 reward is 27.4\n",
      "Training time per epochs: 15.36 sec\n",
      "###### Trajectory = T3 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 153.6\n",
      "Av. agent reward = 15.36\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 153.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 6.8\n",
      "Agent1 reward is 2.5\n",
      "Agent2 reward is 11.9\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 33.8\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 16.2\n",
      "Agent7 reward is 7.2\n",
      "Agent8 reward is 34.5\n",
      "Agent9 reward is 21.7\n",
      "Training time per epochs: 10.36 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 150.1\n",
      "Av. agent reward = 15.01\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 150.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.7\n",
      "Agent1 reward is 33.2\n",
      "Agent2 reward is 35.2\n",
      "Agent3 reward is 9.3\n",
      "Agent4 reward is 17.8\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 11.4\n",
      "Agent7 reward is 13.6\n",
      "Agent8 reward is 4.8\n",
      "Agent9 reward is 7.2\n",
      "Training time per epochs: 9.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 162.1\n",
      "Av. agent reward = 16.21\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 26.3\n",
      "Agent1 reward is 22.0\n",
      "Agent2 reward is 31.1\n",
      "Agent3 reward is 28.4\n",
      "Agent4 reward is 17.8\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 13.1\n",
      "Agent7 reward is 0.2\n",
      "Agent8 reward is 5.9\n",
      "Agent9 reward is 17.2\n",
      "Training time per epochs: 9.55 sec\n",
      "###### Trained episodes = 2000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 135.4\n",
      "Av. agent reward = 13.54\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 135.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 15.0\n",
      "Agent1 reward is 23.7\n",
      "Agent2 reward is 15.0\n",
      "Agent3 reward is 13.1\n",
      "Agent4 reward is 44.7\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 4.5\n",
      "Agent7 reward is 0.4\n",
      "Agent8 reward is 16.1\n",
      "Agent9 reward is 3.0\n",
      "Training time per epochs: 9.58 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 163.6\n",
      "Av. agent reward = 16.36\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 163.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 29.0\n",
      "Agent1 reward is 23.2\n",
      "Agent2 reward is 9.4\n",
      "Agent3 reward is 46.0\n",
      "Agent4 reward is 29.1\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 22.9\n",
      "Agent7 reward is 2.6\n",
      "Agent8 reward is 1.3\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.61 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 115.0\n",
      "Av. agent reward = 11.50\n",
      "Agents crossed (2nd food pile) = 4.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 115.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.1\n",
      "Agent1 reward is 16.4\n",
      "Agent2 reward is 7.9\n",
      "Agent3 reward is 36.3\n",
      "Agent4 reward is 18.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 17.7\n",
      "Agent7 reward is 1.1\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.57 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.5\n",
      "Av. agent reward = 18.65\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.2\n",
      "Agent1 reward is 30.4\n",
      "Agent2 reward is 27.9\n",
      "Agent3 reward is 8.8\n",
      "Agent4 reward is 17.4\n",
      "Agent5 reward is 22.8\n",
      "Agent6 reward is 22.3\n",
      "Agent7 reward is 25.5\n",
      "Agent8 reward is 14.3\n",
      "Agent9 reward is 16.9\n",
      "Training time per epochs: 7.41 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 188.6\n",
      "Av. agent reward = 18.86\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 188.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.1\n",
      "Agent1 reward is 18.6\n",
      "Agent2 reward is 25.8\n",
      "Agent3 reward is 32.5\n",
      "Agent4 reward is 18.9\n",
      "Agent5 reward is 18.8\n",
      "Agent6 reward is 8.1\n",
      "Agent7 reward is 23.3\n",
      "Agent8 reward is 20.7\n",
      "Agent9 reward is 21.8\n",
      "Training time per epochs: 6.93 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 189.4\n",
      "Av. agent reward = 18.94\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 189.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 20.1\n",
      "Agent2 reward is 32.7\n",
      "Agent3 reward is 30.7\n",
      "Agent4 reward is 6.7\n",
      "Agent5 reward is 17.7\n",
      "Agent6 reward is 15.4\n",
      "Agent7 reward is 24.2\n",
      "Agent8 reward is 17.4\n",
      "Agent9 reward is 24.6\n",
      "Training time per epochs: 7.33 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 161.0\n",
      "Av. agent reward = 16.10\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 161.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 21.3\n",
      "Agent2 reward is 21.7\n",
      "Agent3 reward is 24.7\n",
      "Agent4 reward is 6.6\n",
      "Agent5 reward is 21.6\n",
      "Agent6 reward is 1.9\n",
      "Agent7 reward is 19.5\n",
      "Agent8 reward is 17.9\n",
      "Agent9 reward is 25.8\n",
      "Training time per epochs: 7.11 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 163.0\n",
      "Av. agent reward = 16.30\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 163.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 22.0\n",
      "Agent2 reward is 17.3\n",
      "Agent3 reward is 31.0\n",
      "Agent4 reward is 15.6\n",
      "Agent5 reward is 7.5\n",
      "Agent6 reward is 7.2\n",
      "Agent7 reward is 21.7\n",
      "Agent8 reward is 20.0\n",
      "Agent9 reward is 20.8\n",
      "Training time per epochs: 7.76 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 150.3\n",
      "Av. agent reward = 15.03\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 150.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 16.6\n",
      "Agent2 reward is 25.2\n",
      "Agent3 reward is 25.1\n",
      "Agent4 reward is 14.4\n",
      "Agent5 reward is 7.5\n",
      "Agent6 reward is 4.3\n",
      "Agent7 reward is 19.2\n",
      "Agent8 reward is 16.2\n",
      "Agent9 reward is 21.8\n",
      "Training time per epochs: 8.14 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 203.4\n",
      "Av. agent reward = 20.34\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 203.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 26.5\n",
      "Agent1 reward is 9.4\n",
      "Agent2 reward is 1.1\n",
      "Agent3 reward is 15.2\n",
      "Agent4 reward is 33.0\n",
      "Agent5 reward is 18.4\n",
      "Agent6 reward is 42.4\n",
      "Agent7 reward is 21.0\n",
      "Agent8 reward is 7.7\n",
      "Agent9 reward is 28.8\n",
      "Training time per epochs: 7.01 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.7\n",
      "Av. agent reward = 19.67\n",
      "Agents crossed (2nd food pile) = 8.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.1\n",
      "Agent1 reward is 16.6\n",
      "Agent2 reward is 10.3\n",
      "Agent3 reward is 19.0\n",
      "Agent4 reward is 29.3\n",
      "Agent5 reward is 16.5\n",
      "Agent6 reward is 43.0\n",
      "Agent7 reward is 14.2\n",
      "Agent8 reward is 10.4\n",
      "Agent9 reward is 18.3\n",
      "Training time per epochs: 7.37 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 205.3\n",
      "Av. agent reward = 20.53\n",
      "Agents crossed (2nd food pile) = 8.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 205.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.3\n",
      "Agent1 reward is 17.6\n",
      "Agent2 reward is 27.9\n",
      "Agent3 reward is 19.4\n",
      "Agent4 reward is 22.9\n",
      "Agent5 reward is 13.2\n",
      "Agent6 reward is 21.8\n",
      "Agent7 reward is 21.9\n",
      "Agent8 reward is 9.6\n",
      "Agent9 reward is 23.7\n",
      "Training time per epochs: 7.82 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 194.7\n",
      "Av. agent reward = 19.47\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 194.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.9\n",
      "Agent1 reward is 16.3\n",
      "Agent2 reward is 31.4\n",
      "Agent3 reward is 23.6\n",
      "Agent4 reward is 19.2\n",
      "Agent5 reward is 1.5\n",
      "Agent6 reward is 13.2\n",
      "Agent7 reward is 22.6\n",
      "Agent8 reward is 10.1\n",
      "Agent9 reward is 23.9\n",
      "Training time per epochs: 7.86 sec\n",
      "###### Trained episodes = 2500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.3\n",
      "Av. agent reward = 18.63\n",
      "Agents crossed (2nd food pile) = 8.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.4\n",
      "Agent1 reward is 22.5\n",
      "Agent2 reward is 26.6\n",
      "Agent3 reward is 17.1\n",
      "Agent4 reward is 13.7\n",
      "Agent5 reward is 16.2\n",
      "Agent6 reward is 18.4\n",
      "Agent7 reward is 12.0\n",
      "Agent8 reward is 10.3\n",
      "Agent9 reward is 19.2\n",
      "Training time per epochs: 7.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 202.9\n",
      "Av. agent reward = 20.29\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 202.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 31.2\n",
      "Agent1 reward is 21.1\n",
      "Agent2 reward is 29.2\n",
      "Agent3 reward is 31.8\n",
      "Agent4 reward is 23.3\n",
      "Agent5 reward is 10.6\n",
      "Agent6 reward is 12.6\n",
      "Agent7 reward is 12.8\n",
      "Agent8 reward is 5.5\n",
      "Agent9 reward is 24.8\n",
      "Training time per epochs: 7.79 sec\n",
      "###### Trajectory = T4 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 149.1\n",
      "Av. agent reward = 14.91\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 149.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 6.8\n",
      "Agent1 reward is 1.3\n",
      "Agent2 reward is 18.6\n",
      "Agent3 reward is 16.1\n",
      "Agent4 reward is 27.1\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 14.3\n",
      "Agent7 reward is 13.7\n",
      "Agent8 reward is 32.1\n",
      "Agent9 reward is 18.9\n",
      "Training time per epochs: 6.99 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 153.6\n",
      "Av. agent reward = 15.36\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 153.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 10.2\n",
      "Agent1 reward is 34.4\n",
      "Agent2 reward is 27.5\n",
      "Agent3 reward is 6.8\n",
      "Agent4 reward is 23.1\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 18.6\n",
      "Agent7 reward is 18.8\n",
      "Agent8 reward is 9.8\n",
      "Agent9 reward is 4.4\n",
      "Training time per epochs: 7.08 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 158.5\n",
      "Av. agent reward = 15.85\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.0\n",
      "Agent1 reward is 28.0\n",
      "Agent2 reward is 28.4\n",
      "Agent3 reward is 26.2\n",
      "Agent4 reward is 21.4\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 13.9\n",
      "Agent7 reward is 0.3\n",
      "Agent8 reward is 4.5\n",
      "Agent9 reward is 16.6\n",
      "Training time per epochs: 7.58 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 142.5\n",
      "Av. agent reward = 14.25\n",
      "Agents crossed (2nd food pile) = 6.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 142.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 3.1\n",
      "Agent1 reward is 23.3\n",
      "Agent2 reward is 21.2\n",
      "Agent3 reward is 18.7\n",
      "Agent4 reward is 57.4\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 4.3\n",
      "Agent7 reward is 1.9\n",
      "Agent8 reward is 9.8\n",
      "Agent9 reward is 2.8\n",
      "Training time per epochs: 7.75 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 146.9\n",
      "Av. agent reward = 14.69\n",
      "Agents crossed (2nd food pile) = 4.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 146.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 12.2\n",
      "Agent1 reward is 26.0\n",
      "Agent2 reward is 7.8\n",
      "Agent3 reward is 43.1\n",
      "Agent4 reward is 41.3\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 13.5\n",
      "Agent7 reward is 2.3\n",
      "Agent8 reward is 0.8\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 8.07 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 114.4\n",
      "Av. agent reward = 11.44\n",
      "Agents crossed (2nd food pile) = 3.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 114.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 6.9\n",
      "Agent1 reward is 19.0\n",
      "Agent2 reward is 3.6\n",
      "Agent3 reward is 46.8\n",
      "Agent4 reward is 24.2\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 11.8\n",
      "Agent7 reward is 2.1\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 7.08 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 165.6\n",
      "Av. agent reward = 16.56\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 165.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 29.2\n",
      "Agent2 reward is 26.8\n",
      "Agent3 reward is 6.7\n",
      "Agent4 reward is 17.1\n",
      "Agent5 reward is 20.1\n",
      "Agent6 reward is 26.6\n",
      "Agent7 reward is 23.0\n",
      "Agent8 reward is 8.3\n",
      "Agent9 reward is 7.8\n",
      "Training time per epochs: 7.04 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.8\n",
      "Av. agent reward = 18.68\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 24.8\n",
      "Agent2 reward is 31.2\n",
      "Agent3 reward is 15.5\n",
      "Agent4 reward is 18.2\n",
      "Agent5 reward is 23.9\n",
      "Agent6 reward is 18.5\n",
      "Agent7 reward is 24.6\n",
      "Agent8 reward is 22.1\n",
      "Agent9 reward is 8.0\n",
      "Training time per epochs: 7.04 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 187.1\n",
      "Av. agent reward = 18.71\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 187.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.5\n",
      "Agent2 reward is 34.0\n",
      "Agent3 reward is 29.0\n",
      "Agent4 reward is 11.3\n",
      "Agent5 reward is 20.4\n",
      "Agent6 reward is 15.4\n",
      "Agent7 reward is 28.1\n",
      "Agent8 reward is 11.4\n",
      "Agent9 reward is 18.0\n",
      "Training time per epochs: 6.99 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 149.5\n",
      "Av. agent reward = 14.95\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 149.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 23.4\n",
      "Agent2 reward is 36.1\n",
      "Agent3 reward is 13.5\n",
      "Agent4 reward is 8.2\n",
      "Agent5 reward is 27.9\n",
      "Agent6 reward is 5.1\n",
      "Agent7 reward is 18.6\n",
      "Agent8 reward is 6.8\n",
      "Agent9 reward is 9.9\n",
      "Training time per epochs: 7.50 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 167.4\n",
      "Av. agent reward = 16.74\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 167.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.2\n",
      "Agent2 reward is 34.0\n",
      "Agent3 reward is 21.7\n",
      "Agent4 reward is 7.5\n",
      "Agent5 reward is 18.0\n",
      "Agent6 reward is 3.8\n",
      "Agent7 reward is 23.2\n",
      "Agent8 reward is 14.3\n",
      "Agent9 reward is 25.5\n",
      "Training time per epochs: 7.90 sec\n",
      "###### Trained episodes = 3000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 165.4\n",
      "Av. agent reward = 16.54\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 165.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.1\n",
      "Agent2 reward is 51.0\n",
      "Agent3 reward is 29.7\n",
      "Agent4 reward is 5.4\n",
      "Agent5 reward is 5.7\n",
      "Agent6 reward is 0.3\n",
      "Agent7 reward is 21.5\n",
      "Agent8 reward is 14.0\n",
      "Agent9 reward is 18.8\n",
      "Training time per epochs: 7.94 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 210.6\n",
      "Av. agent reward = 21.06\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 210.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.9\n",
      "Agent1 reward is 7.4\n",
      "Agent2 reward is 1.5\n",
      "Agent3 reward is 15.4\n",
      "Agent4 reward is 38.8\n",
      "Agent5 reward is 21.1\n",
      "Agent6 reward is 51.3\n",
      "Agent7 reward is 20.6\n",
      "Agent8 reward is 6.9\n",
      "Agent9 reward is 21.7\n",
      "Training time per epochs: 7.89 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 240.2\n",
      "Av. agent reward = 24.02\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 240.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 54.9\n",
      "Agent1 reward is 17.6\n",
      "Agent2 reward is 11.0\n",
      "Agent3 reward is 11.4\n",
      "Agent4 reward is 39.3\n",
      "Agent5 reward is 11.2\n",
      "Agent6 reward is 53.1\n",
      "Agent7 reward is 20.9\n",
      "Agent8 reward is 10.2\n",
      "Agent9 reward is 10.6\n",
      "Training time per epochs: 13.57 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 275.2\n",
      "Av. agent reward = 27.52\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 275.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 80.3\n",
      "Agent1 reward is 23.2\n",
      "Agent2 reward is 17.5\n",
      "Agent3 reward is 25.9\n",
      "Agent4 reward is 41.5\n",
      "Agent5 reward is 8.2\n",
      "Agent6 reward is 30.7\n",
      "Agent7 reward is 21.6\n",
      "Agent8 reward is 9.9\n",
      "Agent9 reward is 16.3\n",
      "Training time per epochs: 13.12 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 258.9\n",
      "Av. agent reward = 25.89\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 258.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 107.7\n",
      "Agent1 reward is 26.6\n",
      "Agent2 reward is 15.2\n",
      "Agent3 reward is 22.4\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 7.2\n",
      "Agent6 reward is 11.4\n",
      "Agent7 reward is 23.0\n",
      "Agent8 reward is 7.0\n",
      "Agent9 reward is 19.8\n",
      "Training time per epochs: 12.73 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 245.5\n",
      "Av. agent reward = 24.55\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 245.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 65.6\n",
      "Agent1 reward is 19.2\n",
      "Agent2 reward is 21.9\n",
      "Agent3 reward is 11.7\n",
      "Agent4 reward is 56.7\n",
      "Agent5 reward is 13.0\n",
      "Agent6 reward is 24.3\n",
      "Agent7 reward is 15.0\n",
      "Agent8 reward is 8.6\n",
      "Agent9 reward is 9.3\n",
      "Training time per epochs: 12.85 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 268.7\n",
      "Av. agent reward = 26.87\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 268.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 80.1\n",
      "Agent1 reward is 38.1\n",
      "Agent2 reward is 24.9\n",
      "Agent3 reward is 20.4\n",
      "Agent4 reward is 27.9\n",
      "Agent5 reward is 10.7\n",
      "Agent6 reward is 25.3\n",
      "Agent7 reward is 12.4\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 20.7\n",
      "Training time per epochs: 12.84 sec\n",
      "###### Trajectory = T5 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 128.8\n",
      "Av. agent reward = 12.88\n",
      "Agents crossed (2nd food pile) = 5.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 128.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 4.5\n",
      "Agent1 reward is 0.7\n",
      "Agent2 reward is 12.1\n",
      "Agent3 reward is 19.2\n",
      "Agent4 reward is 25.5\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 7.0\n",
      "Agent7 reward is 9.5\n",
      "Agent8 reward is 33.2\n",
      "Agent9 reward is 16.8\n",
      "Training time per epochs: 10.06 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 134.3\n",
      "Av. agent reward = 13.43\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 134.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 11.4\n",
      "Agent1 reward is 28.4\n",
      "Agent2 reward is 21.1\n",
      "Agent3 reward is 7.0\n",
      "Agent4 reward is 23.2\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 14.0\n",
      "Agent7 reward is 12.2\n",
      "Agent8 reward is 9.3\n",
      "Agent9 reward is 7.8\n",
      "Training time per epochs: 9.74 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 137.4\n",
      "Av. agent reward = 13.74\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 137.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.3\n",
      "Agent1 reward is 21.4\n",
      "Agent2 reward is 19.3\n",
      "Agent3 reward is 27.0\n",
      "Agent4 reward is 16.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 12.3\n",
      "Agent7 reward is 1.0\n",
      "Agent8 reward is 8.9\n",
      "Agent9 reward is 15.2\n",
      "Training time per epochs: 9.95 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 131.3\n",
      "Av. agent reward = 13.13\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 131.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 7.7\n",
      "Agent1 reward is 19.9\n",
      "Agent2 reward is 12.6\n",
      "Agent3 reward is 14.7\n",
      "Agent4 reward is 52.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 11.4\n",
      "Agent7 reward is 3.7\n",
      "Agent8 reward is 5.7\n",
      "Agent9 reward is 3.1\n",
      "Training time per epochs: 9.82 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 139.4\n",
      "Av. agent reward = 13.94\n",
      "Agents crossed (2nd food pile) = 4.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 139.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.0\n",
      "Agent1 reward is 21.8\n",
      "Agent2 reward is 2.1\n",
      "Agent3 reward is 47.6\n",
      "Agent4 reward is 35.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 6.7\n",
      "Agent7 reward is 4.6\n",
      "Agent8 reward is 1.6\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.52 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 106.1\n",
      "Av. agent reward = 10.61\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 106.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.3\n",
      "Agent1 reward is 17.6\n",
      "Agent2 reward is 2.7\n",
      "Agent3 reward is 45.2\n",
      "Agent4 reward is 23.4\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 1.5\n",
      "Agent7 reward is 1.7\n",
      "Agent8 reward is 0.6\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 9.90 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 144.6\n",
      "Av. agent reward = 14.46\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 144.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.2\n",
      "Agent1 reward is 23.1\n",
      "Agent2 reward is 19.2\n",
      "Agent3 reward is 6.8\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 16.3\n",
      "Agent6 reward is 29.4\n",
      "Agent7 reward is 17.5\n",
      "Agent8 reward is 8.8\n",
      "Agent9 reward is 4.5\n",
      "Training time per epochs: 9.75 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.5\n",
      "Av. agent reward = 18.45\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.4\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 29.0\n",
      "Agent3 reward is 31.1\n",
      "Agent4 reward is 16.1\n",
      "Agent5 reward is 20.7\n",
      "Agent6 reward is 15.2\n",
      "Agent7 reward is 23.5\n",
      "Agent8 reward is 17.2\n",
      "Agent9 reward is 12.5\n",
      "Training time per epochs: 10.01 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.0\n",
      "Av. agent reward = 18.40\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 15.6\n",
      "Agent2 reward is 34.2\n",
      "Agent3 reward is 35.9\n",
      "Agent4 reward is 5.9\n",
      "Agent5 reward is 22.7\n",
      "Agent6 reward is 18.3\n",
      "Agent7 reward is 22.8\n",
      "Agent8 reward is 2.9\n",
      "Agent9 reward is 25.8\n",
      "Training time per epochs: 10.01 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 141.7\n",
      "Av. agent reward = 14.17\n",
      "Agents crossed (2nd food pile) = 5.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 141.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 20.5\n",
      "Agent2 reward is 22.8\n",
      "Agent3 reward is 29.5\n",
      "Agent4 reward is 4.8\n",
      "Agent5 reward is 27.4\n",
      "Agent6 reward is 2.8\n",
      "Agent7 reward is 13.4\n",
      "Agent8 reward is 1.1\n",
      "Agent9 reward is 19.4\n",
      "Training time per epochs: 9.74 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 133.6\n",
      "Av. agent reward = 13.36\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 133.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 12.1\n",
      "Agent3 reward is 19.4\n",
      "Agent4 reward is 16.5\n",
      "Agent5 reward is 17.0\n",
      "Agent6 reward is 0.2\n",
      "Agent7 reward is 25.4\n",
      "Agent8 reward is 7.6\n",
      "Agent9 reward is 16.4\n",
      "Training time per epochs: 9.63 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 138.7\n",
      "Av. agent reward = 13.87\n",
      "Agents crossed (2nd food pile) = 5.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 138.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 13.4\n",
      "Agent2 reward is 19.1\n",
      "Agent3 reward is 22.0\n",
      "Agent4 reward is 12.9\n",
      "Agent5 reward is 5.7\n",
      "Agent6 reward is 0.4\n",
      "Agent7 reward is 26.5\n",
      "Agent8 reward is 15.0\n",
      "Agent9 reward is 23.7\n",
      "Training time per epochs: 10.03 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 179.7\n",
      "Av. agent reward = 17.97\n",
      "Agents crossed (2nd food pile) = 5.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 179.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.8\n",
      "Agent1 reward is 3.7\n",
      "Agent2 reward is 0.3\n",
      "Agent3 reward is 15.2\n",
      "Agent4 reward is 23.3\n",
      "Agent5 reward is 11.3\n",
      "Agent6 reward is 43.4\n",
      "Agent7 reward is 22.7\n",
      "Agent8 reward is 7.5\n",
      "Agent9 reward is 21.5\n",
      "Training time per epochs: 10.15 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 189.1\n",
      "Av. agent reward = 18.91\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 189.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 29.0\n",
      "Agent1 reward is 14.9\n",
      "Agent2 reward is 6.6\n",
      "Agent3 reward is 10.6\n",
      "Agent4 reward is 32.0\n",
      "Agent5 reward is 15.7\n",
      "Agent6 reward is 48.6\n",
      "Agent7 reward is 9.0\n",
      "Agent8 reward is 8.9\n",
      "Agent9 reward is 13.7\n",
      "Training time per epochs: 9.68 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 198.3\n",
      "Av. agent reward = 19.83\n",
      "Agents crossed (2nd food pile) = 7.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 198.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 36.3\n",
      "Agent1 reward is 18.0\n",
      "Agent2 reward is 25.0\n",
      "Agent3 reward is 22.6\n",
      "Agent4 reward is 29.2\n",
      "Agent5 reward is 2.5\n",
      "Agent6 reward is 16.8\n",
      "Agent7 reward is 17.8\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 22.0\n",
      "Training time per epochs: 10.70 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 185.0\n",
      "Av. agent reward = 18.50\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 185.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 41.4\n",
      "Agent1 reward is 17.4\n",
      "Agent2 reward is 30.2\n",
      "Agent3 reward is 22.6\n",
      "Agent4 reward is 13.2\n",
      "Agent5 reward is 1.8\n",
      "Agent6 reward is 9.1\n",
      "Agent7 reward is 16.3\n",
      "Agent8 reward is 6.0\n",
      "Agent9 reward is 27.1\n",
      "Training time per epochs: 10.47 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 193.6\n",
      "Av. agent reward = 19.36\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 193.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 41.5\n",
      "Agent1 reward is 22.0\n",
      "Agent2 reward is 26.4\n",
      "Agent3 reward is 14.7\n",
      "Agent4 reward is 12.3\n",
      "Agent5 reward is 10.9\n",
      "Agent6 reward is 29.2\n",
      "Agent7 reward is 19.3\n",
      "Agent8 reward is 6.4\n",
      "Agent9 reward is 11.0\n",
      "Training time per epochs: 9.89 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 190.4\n",
      "Av. agent reward = 19.04\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 190.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.4\n",
      "Agent1 reward is 22.2\n",
      "Agent2 reward is 25.4\n",
      "Agent3 reward is 28.2\n",
      "Agent4 reward is 16.0\n",
      "Agent5 reward is 7.8\n",
      "Agent6 reward is 27.7\n",
      "Agent7 reward is 7.6\n",
      "Agent8 reward is 9.4\n",
      "Agent9 reward is 26.7\n",
      "Training time per epochs: 9.91 sec\n",
      "###### Trajectory = T6 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 142.9\n",
      "Av. agent reward = 14.29\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 142.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 5.3\n",
      "Agent1 reward is 1.5\n",
      "Agent2 reward is 17.4\n",
      "Agent3 reward is 16.2\n",
      "Agent4 reward is 26.2\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 19.1\n",
      "Agent7 reward is 16.3\n",
      "Agent8 reward is 24.9\n",
      "Agent9 reward is 15.9\n",
      "Training time per epochs: 9.68 sec\n",
      "###### Trained episodes = 1000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 145.1\n",
      "Av. agent reward = 14.51\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 145.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 11.1\n",
      "Agent1 reward is 29.5\n",
      "Agent2 reward is 21.9\n",
      "Agent3 reward is 8.0\n",
      "Agent4 reward is 15.1\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 21.2\n",
      "Agent7 reward is 19.6\n",
      "Agent8 reward is 5.1\n",
      "Agent9 reward is 13.5\n",
      "Training time per epochs: 10.16 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.3\n",
      "Av. agent reward = 14.03\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.1\n",
      "Agent1 reward is 19.7\n",
      "Agent2 reward is 22.5\n",
      "Agent3 reward is 31.6\n",
      "Agent4 reward is 11.4\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 13.0\n",
      "Agent7 reward is 2.6\n",
      "Agent8 reward is 5.1\n",
      "Agent9 reward is 12.4\n",
      "Training time per epochs: 10.43 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 118.0\n",
      "Av. agent reward = 11.80\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 118.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 7.3\n",
      "Agent1 reward is 23.8\n",
      "Agent2 reward is 11.6\n",
      "Agent3 reward is 12.7\n",
      "Agent4 reward is 41.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 6.2\n",
      "Agent7 reward is 1.0\n",
      "Agent8 reward is 11.4\n",
      "Agent9 reward is 3.0\n",
      "Training time per epochs: 10.26 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.6\n",
      "Av. agent reward = 14.06\n",
      "Agents crossed (2nd food pile) = 5.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.3\n",
      "Agent1 reward is 21.3\n",
      "Agent2 reward is 10.3\n",
      "Agent3 reward is 43.1\n",
      "Agent4 reward is 21.7\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 12.7\n",
      "Agent7 reward is 5.2\n",
      "Agent8 reward is 1.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 10.00 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 95.2\n",
      "Av. agent reward = 9.52\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 95.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.2\n",
      "Agent1 reward is 19.9\n",
      "Agent2 reward is 2.4\n",
      "Agent3 reward is 41.8\n",
      "Agent4 reward is 13.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 3.0\n",
      "Agent7 reward is 1.4\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 10.19 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 154.9\n",
      "Av. agent reward = 15.49\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 154.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.1\n",
      "Agent1 reward is 24.4\n",
      "Agent2 reward is 21.6\n",
      "Agent3 reward is 8.1\n",
      "Agent4 reward is 15.1\n",
      "Agent5 reward is 14.9\n",
      "Agent6 reward is 23.9\n",
      "Agent7 reward is 20.0\n",
      "Agent8 reward is 10.4\n",
      "Agent9 reward is 16.4\n",
      "Training time per epochs: 9.77 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 159.5\n",
      "Av. agent reward = 15.95\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 159.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.3\n",
      "Agent1 reward is 20.6\n",
      "Agent2 reward is 25.9\n",
      "Agent3 reward is 31.1\n",
      "Agent4 reward is 14.9\n",
      "Agent5 reward is 16.1\n",
      "Agent6 reward is 7.6\n",
      "Agent7 reward is 16.7\n",
      "Agent8 reward is 15.0\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 10.54 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 181.0\n",
      "Av. agent reward = 18.10\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 181.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.2\n",
      "Agent2 reward is 31.8\n",
      "Agent3 reward is 35.3\n",
      "Agent4 reward is 9.1\n",
      "Agent5 reward is 19.8\n",
      "Agent6 reward is 10.6\n",
      "Agent7 reward is 17.4\n",
      "Agent8 reward is 8.9\n",
      "Agent9 reward is 29.0\n",
      "Training time per epochs: 10.37 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.2\n",
      "Av. agent reward = 14.02\n",
      "Agents crossed (2nd food pile) = 5.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 20.0\n",
      "Agent2 reward is 16.9\n",
      "Agent3 reward is 28.3\n",
      "Agent4 reward is 7.1\n",
      "Agent5 reward is 22.6\n",
      "Agent6 reward is 3.2\n",
      "Agent7 reward is 15.0\n",
      "Agent8 reward is 7.6\n",
      "Agent9 reward is 19.4\n",
      "Training time per epochs: 9.94 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 149.0\n",
      "Av. agent reward = 14.90\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 149.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 21.5\n",
      "Agent2 reward is 13.7\n",
      "Agent3 reward is 38.4\n",
      "Agent4 reward is 16.0\n",
      "Agent5 reward is 11.1\n",
      "Agent6 reward is 0.3\n",
      "Agent7 reward is 19.9\n",
      "Agent8 reward is 7.6\n",
      "Agent9 reward is 20.6\n",
      "Training time per epochs: 9.64 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 122.2\n",
      "Av. agent reward = 12.22\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 122.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 13.8\n",
      "Agent2 reward is 19.3\n",
      "Agent3 reward is 23.9\n",
      "Agent4 reward is 12.5\n",
      "Agent5 reward is 6.1\n",
      "Agent6 reward is 0.0\n",
      "Agent7 reward is 16.0\n",
      "Agent8 reward is 12.2\n",
      "Agent9 reward is 18.5\n",
      "Training time per epochs: 9.99 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 175.0\n",
      "Av. agent reward = 17.50\n",
      "Agents crossed (2nd food pile) = 5.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.2\n",
      "Agent1 reward is 3.6\n",
      "Agent2 reward is 1.0\n",
      "Agent3 reward is 17.1\n",
      "Agent4 reward is 25.0\n",
      "Agent5 reward is 10.4\n",
      "Agent6 reward is 45.1\n",
      "Agent7 reward is 17.8\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 25.8\n",
      "Training time per epochs: 10.46 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 174.2\n",
      "Av. agent reward = 17.42\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 174.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.5\n",
      "Agent1 reward is 13.7\n",
      "Agent2 reward is 7.9\n",
      "Agent3 reward is 11.8\n",
      "Agent4 reward is 28.4\n",
      "Agent5 reward is 15.5\n",
      "Agent6 reward is 39.9\n",
      "Agent7 reward is 7.9\n",
      "Agent8 reward is 9.6\n",
      "Agent9 reward is 15.9\n",
      "Training time per epochs: 9.96 sec\n",
      "###### Trained episodes = 1500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 194.0\n",
      "Av. agent reward = 19.40\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 194.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 28.4\n",
      "Agent1 reward is 15.4\n",
      "Agent2 reward is 25.1\n",
      "Agent3 reward is 25.7\n",
      "Agent4 reward is 24.9\n",
      "Agent5 reward is 8.6\n",
      "Agent6 reward is 18.0\n",
      "Agent7 reward is 22.1\n",
      "Agent8 reward is 7.0\n",
      "Agent9 reward is 18.6\n",
      "Training time per epochs: 11.53 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.2\n",
      "Av. agent reward = 18.42\n",
      "Agents crossed (2nd food pile) = 7.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.9\n",
      "Agent1 reward is 10.8\n",
      "Agent2 reward is 30.8\n",
      "Agent3 reward is 20.0\n",
      "Agent4 reward is 13.0\n",
      "Agent5 reward is 3.7\n",
      "Agent6 reward is 9.6\n",
      "Agent7 reward is 31.1\n",
      "Agent8 reward is 7.9\n",
      "Agent9 reward is 24.4\n",
      "Training time per epochs: 10.24 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 179.3\n",
      "Av. agent reward = 17.93\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 179.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 37.5\n",
      "Agent1 reward is 20.6\n",
      "Agent2 reward is 27.1\n",
      "Agent3 reward is 11.7\n",
      "Agent4 reward is 13.5\n",
      "Agent5 reward is 19.9\n",
      "Agent6 reward is 14.7\n",
      "Agent7 reward is 12.6\n",
      "Agent8 reward is 7.7\n",
      "Agent9 reward is 14.0\n",
      "Training time per epochs: 10.36 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 222.6\n",
      "Av. agent reward = 22.26\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 222.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.8\n",
      "Agent1 reward is 13.1\n",
      "Agent2 reward is 25.8\n",
      "Agent3 reward is 54.4\n",
      "Agent4 reward is 11.7\n",
      "Agent5 reward is 12.7\n",
      "Agent6 reward is 11.7\n",
      "Agent7 reward is 15.2\n",
      "Agent8 reward is 12.6\n",
      "Agent9 reward is 41.5\n",
      "Training time per epochs: 10.46 sec\n",
      "###### Trajectory = T7 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 122.6\n",
      "Av. agent reward = 12.26\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 122.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 5.5\n",
      "Agent1 reward is 1.6\n",
      "Agent2 reward is 12.4\n",
      "Agent3 reward is 16.3\n",
      "Agent4 reward is 28.9\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 11.9\n",
      "Agent7 reward is 7.0\n",
      "Agent8 reward is 25.1\n",
      "Agent9 reward is 13.7\n",
      "Training time per epochs: 10.10 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 139.3\n",
      "Av. agent reward = 13.93\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 139.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 10.7\n",
      "Agent1 reward is 34.0\n",
      "Agent2 reward is 21.9\n",
      "Agent3 reward is 7.6\n",
      "Agent4 reward is 14.8\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 18.8\n",
      "Agent7 reward is 17.1\n",
      "Agent8 reward is 3.4\n",
      "Agent9 reward is 11.0\n",
      "Training time per epochs: 10.12 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.4\n",
      "Av. agent reward = 14.04\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.0\n",
      "Agent1 reward is 21.7\n",
      "Agent2 reward is 21.0\n",
      "Agent3 reward is 30.8\n",
      "Agent4 reward is 15.6\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 9.3\n",
      "Agent7 reward is 1.1\n",
      "Agent8 reward is 4.8\n",
      "Agent9 reward is 18.3\n",
      "Training time per epochs: 9.70 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 113.5\n",
      "Av. agent reward = 11.35\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 113.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 5.0\n",
      "Agent1 reward is 21.4\n",
      "Agent2 reward is 11.9\n",
      "Agent3 reward is 13.8\n",
      "Agent4 reward is 44.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 2.8\n",
      "Agent7 reward is 0.1\n",
      "Agent8 reward is 11.0\n",
      "Agent9 reward is 3.0\n",
      "Training time per epochs: 9.92 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 132.6\n",
      "Av. agent reward = 13.26\n",
      "Agents crossed (2nd food pile) = 4.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 132.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.2\n",
      "Agent1 reward is 17.0\n",
      "Agent2 reward is 5.7\n",
      "Agent3 reward is 52.0\n",
      "Agent4 reward is 26.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 11.8\n",
      "Agent7 reward is 2.8\n",
      "Agent8 reward is 0.1\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 10.06 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 104.9\n",
      "Av. agent reward = 10.49\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 104.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 15.5\n",
      "Agent1 reward is 15.6\n",
      "Agent2 reward is 1.6\n",
      "Agent3 reward is 48.9\n",
      "Agent4 reward is 17.8\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 2.0\n",
      "Agent7 reward is 3.3\n",
      "Agent8 reward is 0.2\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 10.08 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 161.4\n",
      "Av. agent reward = 16.14\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 161.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.2\n",
      "Agent1 reward is 21.3\n",
      "Agent2 reward is 26.6\n",
      "Agent3 reward is 9.8\n",
      "Agent4 reward is 17.7\n",
      "Agent5 reward is 17.7\n",
      "Agent6 reward is 27.6\n",
      "Agent7 reward is 19.6\n",
      "Agent8 reward is 10.7\n",
      "Agent9 reward is 10.2\n",
      "Training time per epochs: 10.25 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 172.3\n",
      "Av. agent reward = 17.23\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 16.6\n",
      "Agent2 reward is 20.9\n",
      "Agent3 reward is 33.3\n",
      "Agent4 reward is 14.2\n",
      "Agent5 reward is 17.7\n",
      "Agent6 reward is 9.4\n",
      "Agent7 reward is 19.5\n",
      "Agent8 reward is 19.7\n",
      "Agent9 reward is 21.0\n",
      "Training time per epochs: 10.12 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 176.1\n",
      "Av. agent reward = 17.61\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 176.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 19.2\n",
      "Agent2 reward is 33.6\n",
      "Agent3 reward is 29.6\n",
      "Agent4 reward is 6.1\n",
      "Agent5 reward is 18.5\n",
      "Agent6 reward is 13.0\n",
      "Agent7 reward is 19.5\n",
      "Agent8 reward is 8.3\n",
      "Agent9 reward is 28.3\n",
      "Training time per epochs: 10.15 sec\n",
      "###### Trained episodes = 2000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 147.7\n",
      "Av. agent reward = 14.77\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 147.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 22.4\n",
      "Agent2 reward is 20.0\n",
      "Agent3 reward is 29.0\n",
      "Agent4 reward is 5.9\n",
      "Agent5 reward is 21.0\n",
      "Agent6 reward is 2.9\n",
      "Agent7 reward is 13.3\n",
      "Agent8 reward is 9.9\n",
      "Agent9 reward is 23.3\n",
      "Training time per epochs: 10.16 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 146.6\n",
      "Av. agent reward = 14.66\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 146.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 18.3\n",
      "Agent2 reward is 13.2\n",
      "Agent3 reward is 37.9\n",
      "Agent4 reward is 15.5\n",
      "Agent5 reward is 12.2\n",
      "Agent6 reward is 3.0\n",
      "Agent7 reward is 19.7\n",
      "Agent8 reward is 7.7\n",
      "Agent9 reward is 19.0\n",
      "Training time per epochs: 10.13 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 134.0\n",
      "Av. agent reward = 13.40\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 134.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 13.4\n",
      "Agent2 reward is 19.4\n",
      "Agent3 reward is 23.6\n",
      "Agent4 reward is 12.6\n",
      "Agent5 reward is 3.9\n",
      "Agent6 reward is 4.3\n",
      "Agent7 reward is 22.0\n",
      "Agent8 reward is 15.0\n",
      "Agent9 reward is 19.7\n",
      "Training time per epochs: 10.25 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 172.9\n",
      "Av. agent reward = 17.29\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.2\n",
      "Agent1 reward is 5.3\n",
      "Agent2 reward is 0.9\n",
      "Agent3 reward is 16.4\n",
      "Agent4 reward is 34.1\n",
      "Agent5 reward is 8.9\n",
      "Agent6 reward is 37.0\n",
      "Agent7 reward is 22.6\n",
      "Agent8 reward is 5.3\n",
      "Agent9 reward is 21.2\n",
      "Training time per epochs: 9.83 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.4\n",
      "Av. agent reward = 18.44\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 29.2\n",
      "Agent1 reward is 10.3\n",
      "Agent2 reward is 8.5\n",
      "Agent3 reward is 12.2\n",
      "Agent4 reward is 31.4\n",
      "Agent5 reward is 15.5\n",
      "Agent6 reward is 41.2\n",
      "Agent7 reward is 13.9\n",
      "Agent8 reward is 6.2\n",
      "Agent9 reward is 16.0\n",
      "Training time per epochs: 9.85 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 190.7\n",
      "Av. agent reward = 19.07\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 190.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 31.4\n",
      "Agent1 reward is 15.9\n",
      "Agent2 reward is 26.8\n",
      "Agent3 reward is 22.9\n",
      "Agent4 reward is 25.0\n",
      "Agent5 reward is 8.7\n",
      "Agent6 reward is 22.8\n",
      "Agent7 reward is 15.5\n",
      "Agent8 reward is 2.0\n",
      "Agent9 reward is 19.6\n",
      "Training time per epochs: 10.38 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 172.9\n",
      "Av. agent reward = 17.29\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 34.4\n",
      "Agent1 reward is 8.0\n",
      "Agent2 reward is 31.7\n",
      "Agent3 reward is 21.8\n",
      "Agent4 reward is 13.3\n",
      "Agent5 reward is 7.1\n",
      "Agent6 reward is 12.7\n",
      "Agent7 reward is 14.5\n",
      "Agent8 reward is 6.5\n",
      "Agent9 reward is 23.0\n",
      "Training time per epochs: 9.90 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 175.0\n",
      "Av. agent reward = 17.50\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 38.7\n",
      "Agent1 reward is 16.2\n",
      "Agent2 reward is 26.2\n",
      "Agent3 reward is 13.9\n",
      "Agent4 reward is 11.8\n",
      "Agent5 reward is 17.7\n",
      "Agent6 reward is 11.6\n",
      "Agent7 reward is 12.6\n",
      "Agent8 reward is 12.6\n",
      "Agent9 reward is 13.8\n",
      "Training time per epochs: 10.90 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.9\n",
      "Av. agent reward = 21.19\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.7\n",
      "Agent1 reward is 17.7\n",
      "Agent2 reward is 21.3\n",
      "Agent3 reward is 51.9\n",
      "Agent4 reward is 14.5\n",
      "Agent5 reward is 15.5\n",
      "Agent6 reward is 13.4\n",
      "Agent7 reward is 13.7\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 32.0\n",
      "Training time per epochs: 10.75 sec\n",
      "###### Trajectory = T8 #######\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 114.3\n",
      "Av. agent reward = 11.43\n",
      "Agents crossed (2nd food pile) = 5.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 114.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 3.8\n",
      "Agent1 reward is 0.8\n",
      "Agent2 reward is 9.4\n",
      "Agent3 reward is 20.1\n",
      "Agent4 reward is 17.3\n",
      "Agent5 reward is 0.1\n",
      "Agent6 reward is 16.9\n",
      "Agent7 reward is 11.9\n",
      "Agent8 reward is 26.2\n",
      "Agent9 reward is 7.8\n",
      "Training time per epochs: 8.41 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 139.2\n",
      "Av. agent reward = 13.92\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 139.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 9.4\n",
      "Agent1 reward is 25.1\n",
      "Agent2 reward is 12.0\n",
      "Agent3 reward is 9.9\n",
      "Agent4 reward is 17.1\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 23.0\n",
      "Agent7 reward is 19.9\n",
      "Agent8 reward is 10.3\n",
      "Agent9 reward is 12.5\n",
      "Training time per epochs: 8.75 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 133.4\n",
      "Av. agent reward = 13.34\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 133.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 12.5\n",
      "Agent1 reward is 16.9\n",
      "Agent2 reward is 16.8\n",
      "Agent3 reward is 30.9\n",
      "Agent4 reward is 14.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 17.3\n",
      "Agent7 reward is 2.3\n",
      "Agent8 reward is 5.6\n",
      "Agent9 reward is 16.5\n",
      "Training time per epochs: 8.61 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 115.6\n",
      "Av. agent reward = 11.56\n",
      "Agents crossed (2nd food pile) = 5.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 115.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.0\n",
      "Agent1 reward is 21.5\n",
      "Agent2 reward is 7.2\n",
      "Agent3 reward is 13.7\n",
      "Agent4 reward is 50.0\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 8.7\n",
      "Agent7 reward is 1.3\n",
      "Agent8 reward is 9.1\n",
      "Agent9 reward is 3.1\n",
      "Training time per epochs: 8.24 sec\n",
      "###### Trained episodes = 2500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 125.2\n",
      "Av. agent reward = 12.52\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 125.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 8.5\n",
      "Agent1 reward is 22.3\n",
      "Agent2 reward is 6.8\n",
      "Agent3 reward is 39.6\n",
      "Agent4 reward is 28.7\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 15.3\n",
      "Agent7 reward is 3.9\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 8.34 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 89.3\n",
      "Av. agent reward = 8.93\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 89.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.9\n",
      "Agent1 reward is 16.9\n",
      "Agent2 reward is 2.0\n",
      "Agent3 reward is 36.1\n",
      "Agent4 reward is 20.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 8.7\n",
      "Agent7 reward is 0.6\n",
      "Agent8 reward is 2.6\n",
      "Agent9 reward is 0.0\n",
      "Training time per epochs: 8.18 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 141.2\n",
      "Av. agent reward = 14.12\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 141.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.5\n",
      "Agent1 reward is 21.1\n",
      "Agent2 reward is 15.1\n",
      "Agent3 reward is 10.4\n",
      "Agent4 reward is 15.9\n",
      "Agent5 reward is 17.9\n",
      "Agent6 reward is 27.1\n",
      "Agent7 reward is 18.4\n",
      "Agent8 reward is 11.3\n",
      "Agent9 reward is 3.5\n",
      "Training time per epochs: 8.35 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 148.7\n",
      "Av. agent reward = 14.87\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 148.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 18.3\n",
      "Agent2 reward is 27.5\n",
      "Agent3 reward is 14.7\n",
      "Agent4 reward is 15.3\n",
      "Agent5 reward is 16.7\n",
      "Agent6 reward is 7.7\n",
      "Agent7 reward is 26.3\n",
      "Agent8 reward is 15.7\n",
      "Agent9 reward is 6.6\n",
      "Training time per epochs: 8.15 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 160.0\n",
      "Av. agent reward = 16.00\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 160.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 20.0\n",
      "Agent2 reward is 25.1\n",
      "Agent3 reward is 33.1\n",
      "Agent4 reward is 10.1\n",
      "Agent5 reward is 16.6\n",
      "Agent6 reward is 10.4\n",
      "Agent7 reward is 21.8\n",
      "Agent8 reward is 6.7\n",
      "Agent9 reward is 16.2\n",
      "Training time per epochs: 8.64 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 119.5\n",
      "Av. agent reward = 11.95\n",
      "Agents crossed (2nd food pile) = 5.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 119.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 23.4\n",
      "Agent3 reward is 12.7\n",
      "Agent4 reward is 6.0\n",
      "Agent5 reward is 19.2\n",
      "Agent6 reward is 0.0\n",
      "Agent7 reward is 19.3\n",
      "Agent8 reward is 14.3\n",
      "Agent9 reward is 5.6\n",
      "Training time per epochs: 8.28 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 117.6\n",
      "Av. agent reward = 11.76\n",
      "Agents crossed (2nd food pile) = 5.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 117.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 15.8\n",
      "Agent2 reward is 18.5\n",
      "Agent3 reward is 4.2\n",
      "Agent4 reward is 12.9\n",
      "Agent5 reward is 11.6\n",
      "Agent6 reward is 1.9\n",
      "Agent7 reward is 23.5\n",
      "Agent8 reward is 10.6\n",
      "Agent9 reward is 18.6\n",
      "Training time per epochs: 8.32 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 112.1\n",
      "Av. agent reward = 11.21\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 112.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 5.2\n",
      "Agent2 reward is 17.8\n",
      "Agent3 reward is 20.5\n",
      "Agent4 reward is 13.6\n",
      "Agent5 reward is 5.1\n",
      "Agent6 reward is 3.3\n",
      "Agent7 reward is 19.0\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 19.5\n",
      "Training time per epochs: 8.45 sec\n",
      "###### Dir = models/1T-10L/followers/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 164.5\n",
      "Av. agent reward = 16.45\n",
      "Agents crossed (2nd food pile) = 4.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 164.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.9\n",
      "Agent1 reward is 4.9\n",
      "Agent2 reward is 0.9\n",
      "Agent3 reward is 15.8\n",
      "Agent4 reward is 29.7\n",
      "Agent5 reward is 11.9\n",
      "Agent6 reward is 33.6\n",
      "Agent7 reward is 26.1\n",
      "Agent8 reward is 4.9\n",
      "Agent9 reward is 19.9\n",
      "Training time per epochs: 8.77 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 180.1\n",
      "Av. agent reward = 18.01\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 180.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.0\n",
      "Agent1 reward is 11.8\n",
      "Agent2 reward is 5.3\n",
      "Agent3 reward is 10.7\n",
      "Agent4 reward is 25.3\n",
      "Agent5 reward is 15.9\n",
      "Agent6 reward is 42.9\n",
      "Agent7 reward is 23.3\n",
      "Agent8 reward is 9.5\n",
      "Agent9 reward is 15.4\n",
      "Training time per epochs: 8.36 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 175.0\n",
      "Av. agent reward = 17.50\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.5\n",
      "Agent1 reward is 15.0\n",
      "Agent2 reward is 18.6\n",
      "Agent3 reward is 22.4\n",
      "Agent4 reward is 22.0\n",
      "Agent5 reward is 11.5\n",
      "Agent6 reward is 27.3\n",
      "Agent7 reward is 18.3\n",
      "Agent8 reward is 5.4\n",
      "Agent9 reward is 13.1\n",
      "Training time per epochs: 6.04 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 162.4\n",
      "Av. agent reward = 16.24\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 24.2\n",
      "Agent1 reward is 8.6\n",
      "Agent2 reward is 20.4\n",
      "Agent3 reward is 19.6\n",
      "Agent4 reward is 15.5\n",
      "Agent5 reward is 13.5\n",
      "Agent6 reward is 11.0\n",
      "Agent7 reward is 17.6\n",
      "Agent8 reward is 14.4\n",
      "Agent9 reward is 17.5\n",
      "Training time per epochs: 4.73 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 158.4\n",
      "Av. agent reward = 15.84\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.5\n",
      "Agent1 reward is 16.6\n",
      "Agent2 reward is 19.4\n",
      "Agent3 reward is 11.2\n",
      "Agent4 reward is 8.3\n",
      "Agent5 reward is 21.7\n",
      "Agent6 reward is 12.7\n",
      "Agent7 reward is 10.2\n",
      "Agent8 reward is 14.0\n",
      "Agent9 reward is 18.7\n",
      "Training time per epochs: 4.53 sec\n",
      "###### Trained episodes = 3000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 210.8\n",
      "Av. agent reward = 21.08\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 210.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.8\n",
      "Agent1 reward is 10.8\n",
      "Agent2 reward is 18.3\n",
      "Agent3 reward is 61.1\n",
      "Agent4 reward is 11.3\n",
      "Agent5 reward is 18.9\n",
      "Agent6 reward is 10.5\n",
      "Agent7 reward is 8.6\n",
      "Agent8 reward is 20.5\n",
      "Agent9 reward is 31.9\n",
      "Training time per epochs: 5.33 sec\n",
      "[[16.233333333333334, 15.52, 14.653333333333332, 12.559999999999999, 16.466666666666665, 12.496666666666666], [19.18, 19.826666666666668, 19.736666666666668, 16.106666666666666, 15.943333333333333, 14.343333333333334], [20.009999999999998, 21.17666666666667, 21.34, 19.96333333333333, 20.593333333333334, 18.43]]\n",
      "[[16.6, 16.46, 15.883333333333335, 13.303333333333333, 16.553333333333335, 12.493333333333334], [18.766666666666666, 18.94, 17.923333333333332, 16.366666666666667, 16.336666666666666, 14.966666666666665], [21.166666666666664, 20.116666666666667, 21.903333333333332, 19.533333333333335, 18.903333333333332, 22.943333333333335]]\n",
      "[[15.363333333333333, 15.01, 16.21333333333333, 13.543333333333333, 16.363333333333333, 11.503333333333334], [18.653333333333332, 18.856666666666666, 18.94, 16.10333333333333, 16.303333333333335, 15.026666666666667], [20.343333333333334, 19.666666666666664, 20.533333333333335, 19.473333333333333, 18.630000000000003, 20.28666666666667]]\n",
      "[[14.913333333333332, 15.363333333333333, 15.846666666666668, 14.253333333333334, 14.693333333333333, 11.443333333333333], [16.556666666666665, 18.67666666666667, 18.706666666666667, 14.946666666666667, 16.740000000000002, 16.53666666666667], [21.056666666666665, 24.016666666666666, 27.51666666666667, 25.886666666666667, 24.55, 26.866666666666667]]\n",
      "[[12.876666666666669, 13.430000000000001, 13.736666666666668, 13.126666666666669, 13.940000000000001, 10.613333333333333], [14.463333333333333, 18.453333333333333, 18.39666666666667, 14.166666666666666, 13.356666666666666, 13.873333333333331], [17.97, 18.91, 19.826666666666668, 18.496666666666666, 19.363333333333333, 19.043333333333333]]\n",
      "[[14.293333333333333, 14.506666666666666, 14.033333333333335, 11.796666666666667, 14.059999999999999, 9.52], [15.493333333333334, 15.95, 18.10333333333333, 14.016666666666666, 14.903333333333332, 12.223333333333333], [17.503333333333334, 17.416666666666664, 19.4, 18.416666666666664, 17.92666666666667, 22.256666666666668]]\n",
      "[[12.26, 13.930000000000001, 14.043333333333333, 11.35, 13.26, 10.486666666666666], [16.14, 17.23, 17.61, 14.773333333333332, 14.656666666666666, 13.4], [17.293333333333333, 18.443333333333335, 19.07, 17.293333333333333, 17.5, 21.193333333333335]]\n",
      "[[11.426666666666666, 13.919999999999998, 13.336666666666668, 11.563333333333334, 12.52, 8.933333333333334], [14.123333333333331, 14.873333333333331, 16.0, 11.953333333333333, 11.756666666666666, 11.209999999999999], [16.45, 18.009999999999998, 17.5, 16.236666666666668, 15.836666666666668, 21.083333333333336]]\n",
      "[[6.066666666666666, 7.433333333333334, 6.0, 6.466666666666667, 4.666666666666667, 4.166666666666667], [7.133333333333334, 8.033333333333333, 7.166666666666667, 6.5, 6.266666666666667, 5.766666666666667], [5.766666666666667, 7.866666666666666, 8.0, 7.966666666666667, 7.233333333333333, 5.466666666666667]]\n",
      "[[6.4, 7.4, 7.066666666666666, 6.266666666666667, 5.433333333333334, 4.933333333333334], [7.533333333333333, 7.9, 7.433333333333334, 7.0, 6.9, 6.5], [6.133333333333334, 8.166666666666666, 8.266666666666667, 8.0, 7.9, 7.166666666666667]]\n",
      "[[6.433333333333334, 7.033333333333333, 6.766666666666667, 6.533333333333333, 5.233333333333333, 4.7], [7.666666666666667, 7.933333333333334, 7.433333333333334, 6.866666666666666, 7.3, 6.633333333333334], [6.333333333333333, 8.066666666666666, 8.3, 7.733333333333333, 8.1, 6.666666666666667]]\n",
      "[[6.133333333333334, 7.266666666666667, 6.733333333333333, 6.2, 4.7, 3.9], [6.533333333333333, 6.7, 6.966666666666667, 5.766666666666667, 6.433333333333334, 5.433333333333334], [5.366666666666666, 7.166666666666667, 7.566666666666666, 7.566666666666666, 7.066666666666666, 6.433333333333334]]\n",
      "[[5.466666666666667, 6.933333333333334, 6.333333333333333, 6.066666666666666, 4.333333333333333, 4.133333333333334], [5.966666666666667, 7.266666666666667, 6.533333333333333, 5.6, 5.833333333333333, 5.7], [5.133333333333334, 6.7, 7.833333333333333, 7.5, 6.833333333333333, 6.133333333333334]]\n",
      "[[5.966666666666667, 7.233333333333333, 6.8, 6.133333333333334, 5.0, 4.066666666666666], [7.133333333333334, 7.3, 7.3, 5.933333333333334, 6.533333333333333, 5.833333333333333], [5.0, 6.933333333333334, 8.0, 7.766666666666667, 7.033333333333333, 6.633333333333334]]\n",
      "[[5.366666666666666, 7.1, 6.433333333333334, 5.366666666666666, 4.8, 4.133333333333334], [6.833333333333333, 7.6, 7.333333333333333, 6.4, 6.733333333333333, 6.133333333333334], [5.233333333333333, 7.3, 7.533333333333333, 7.666666666666667, 6.8, 6.366666666666666]]\n",
      "[[5.066666666666666, 7.4, 6.5, 5.066666666666666, 5.233333333333333, 4.066666666666666], [6.9, 6.8, 7.4, 5.633333333333334, 5.733333333333333, 5.366666666666666], [4.9, 7.333333333333333, 7.566666666666666, 7.966666666666667, 7.366666666666666, 6.5]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\n",
    "             # Models of follower agents trained using a static target zone\n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s1/\",\n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s2/\", \n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_300gs_s3/\", \n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s1/\",\n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s2/\", \n",
    "             \"models/1T-10L/followers_static/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_300gs_s3/\",\n",
    "             # Models of follower agents trained using a moving target zone\n",
    "             \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/\",\n",
    "             \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/\", \n",
    "             \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/\",\n",
    "             \"models/1T-10L/followers_trajectory/food_d37/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/\", \n",
    "             ]\n",
    "\n",
    "episodes = [500, 1000, 1500, 2000, 2500, 3000] \n",
    "\n",
    "game = 'Crossing'\n",
    "map_name = \"food_d37\"\n",
    "culture = \"pacifist_follower\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "av_agent_crossed = [[[0 for i in episodes] for j in dir_names] for k in trajectories]  \n",
    "dominating_tribe = [[[None for i in episodes] for j in dir_names] for k in trajectories]\n",
    "dom_tribe_reward = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "dominance = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "\n",
    "# There will be 10 agents - 0 teams of 0 AI agents each and 0 random agent\n",
    "num_ai_agents = 10\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = True\n",
    "SPEED = 1/30\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 7\n",
    "max_episodes = 30\n",
    "# max_frames = 800\n",
    "verbose = False\n",
    "\n",
    "# Initialize parameters for Crossing and Explore\n",
    "river_penalty = -1\n",
    "crossed = [0 for i in range(num_ai_agents)]  # Keep track of agents gathering from 2nd food pile\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "jumping_zone = False\n",
    "\n",
    "for traj_num, trajectory in enumerate(trajectories):\n",
    "    print (\"###### Trajectory = T{} #######\".format(traj_num+1))\n",
    "    \n",
    "    # Adjust game steps per episode based on the trajectory pacing\n",
    "    max_frames=0\n",
    "    for point in trajectory:\n",
    "        max_frames += point['duration']\n",
    "\n",
    "    position = trajectory [0]  # shift the target zone to first position in trajectory\n",
    "    target_zone = position['loc']  \n",
    "    duration = position['duration']\n",
    "    \n",
    "    for dir_num, dir_name in enumerate(dir_names):\n",
    "        print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "        for eps_num, eps in enumerate(episodes):\n",
    "            print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "            # Load models for AI agents\n",
    "            agents= [[] for i in range(num_ai_agents)]\n",
    "            # If episodes is provided (not 0), load the model for each AI agent\n",
    "            for i in range(num_ai_agents):\n",
    "                model_file = dir_name+'MA{}_{}_ep{}.p'.format(i,game,eps)\n",
    "                try:\n",
    "                    with open(model_file, 'rb') as f:\n",
    "                        print(\"Load saved model for agent {}\".format(i))\n",
    "                        agent = Policy(num_frames, num_actions, 0)\n",
    "                        optimizer = optim.Adam(agent.parameters(), lr=0.1)\n",
    "\n",
    "                        # New way to save and load models - based on: \n",
    "                        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                        _ = load_model(agent, optimizer, f)\n",
    "                        agent.eval()\n",
    "                        agents[i] = agent\n",
    "                except OSError:\n",
    "                    print('Model file not found.')\n",
    "                    raise\n",
    "\n",
    "            # Load random agents    \n",
    "            for i in range(num_ai_agents,num_agents):\n",
    "                # print(\"Load random agent {}\".format(i))\n",
    "                agents.append(Rdn_Policy())\n",
    "        \n",
    "            # Establish tribal association\n",
    "            tribes = []\n",
    "            tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2], agents[3], agents[4], \\\n",
    "                           agents[5], agents[6], agents[7], agents[8], agents[9]]))\n",
    "            tribes[0].set_target_zone(target_zone)\n",
    "\n",
    "            # Set up agent and tribe info to pass into env\n",
    "            agent_colors = [agent.color for agent in agents]\n",
    "            agent_tribes = [agent.tribe for agent in agents]\n",
    "            tribe_names = [tribe.name for tribe in tribes]\n",
    "            tribe_target_zones = [tribe.target_zone for tribe in tribes]\n",
    "        \n",
    "            env = CrossingEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty, tribes=tribe_names, \\\n",
    "                  target_zones=tribe_target_zones, debug_agent=0) \n",
    "\n",
    "            # Used to accumulate episode stats for averaging\n",
    "            cum_rewards = 0\n",
    "            cum_crossed = 0\n",
    "            cum_tags = 0\n",
    "            cum_US_hits = 0\n",
    "            cum_THEM_hits = 0\n",
    "            cum_agent_rewards = [0 for agent in agents]\n",
    "            cum_agent_tags = [0 for agent in agents]\n",
    "            cum_agent_US_hits = [0 for agent in agents]\n",
    "            cum_agent_THEM_hits = [0 for agent in agents]\n",
    "            cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "            cuda = False\n",
    "            start = time.time()\n",
    "\n",
    "            for ep in range(max_episodes):\n",
    "    \n",
    "                print('.', end='')  # To show progress\n",
    "    \n",
    "                # Initialize AI and random agent data\n",
    "                actions = [0 for i in range(num_agents)]\n",
    "                tags = [0 for i in range(num_agents)]\n",
    "                US_hits = [0 for i in range(num_agents)]\n",
    "                THEM_hits = [0 for i in range(num_agents)]\n",
    "            \n",
    "                # Keep track of agents gathering from 2nd food pile\n",
    "                crossed = [0 for i in range(num_ai_agents)]\n",
    "\n",
    "                env_obs = env.reset()  # Environment return observations\n",
    "                \"\"\"\n",
    "                # For Debug only\n",
    "                print (len(agents_obs))\n",
    "                print (agents_obs[0].shape)\n",
    "                \"\"\"\n",
    "    \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "                for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                    agents[i].reset_info()    \n",
    "    \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(SPEED)  # Change speed of video rendering\n",
    "    \n",
    "                \"\"\"\n",
    "                # For Debug only\n",
    "                print (len(agents_obs))\n",
    "                print (agents_obs[0].shape)\n",
    "                \"\"\"\n",
    "    \n",
    "                \"\"\"\n",
    "                For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "                state = np.stack([state]*num_frames)\n",
    "\n",
    "                # Reset LSTM hidden units when episode begins\n",
    "                cx = Variable(torch.zeros(1, 256))\n",
    "                hx = Variable(torch.zeros(1, 256))\n",
    "                \"\"\"\n",
    "    \n",
    "                index = 0\n",
    "                position = trajectory [index]  # shift the target zone to first position in trajectory\n",
    "                env.target_zones[0] = position['loc']  \n",
    "                duration = position['duration']\n",
    "    \n",
    "                for frame in range(max_frames):\n",
    "            \n",
    "                    if (frame+1) % duration == 0:     # time to shift the target zone\n",
    "                        index += 1                    # shift the target zone to new point in trajectory \n",
    "                        if index < len(trajectory):   \n",
    "                            position = trajectory[index]  \n",
    "                            duration = position['duration']\n",
    "                            env.target_zones[0] = position['loc'] \n",
    "             \n",
    "                    for i in range(num_ai_agents):    # For AI agents\n",
    "                        actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                        if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                    for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                        actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                        if actions[i] is 6:\n",
    "                            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                    \"\"\"\n",
    "                    For now, we do not implement LSTM\n",
    "                    # Select action\n",
    "                    action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                    \"\"\"\n",
    "\n",
    "                    # if frame % 10 == 0:\n",
    "                    #     print (actions)    \n",
    "            \n",
    "                    # Perform step        \n",
    "                    env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                    \"\"\"\n",
    "                    For Debug only\n",
    "                    print (env_obs)\n",
    "                    print (reward)\n",
    "                    print (done) \n",
    "                    \"\"\"\n",
    "\n",
    "                    for i in range(num_ai_agents):\n",
    "                        agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                    # Unpack observations into data structure compatible with agent Policy\n",
    "                    agents_obs = unpack_env_obs(env_obs)\n",
    "                    load_info(agents, info, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                    for i in range(num_agents):\n",
    "                        US_hits[i] += agents[i].US_hit\n",
    "                        THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                    \"\"\"\n",
    "                    For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                    # Evict oldest diff add new diff to state\n",
    "                    next_state = np.stack([next_state]*num_frames)\n",
    "                    next_state[1:, :, :] = state[:-1, :, :]\n",
    "                    state = next_state\n",
    "                    \"\"\"\n",
    "        \n",
    "                    if render and ep is 0:   # render only the 1st episode per batch of 30\n",
    "                        env.render()\n",
    "                        time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "                    if any(done):\n",
    "                        print(\"Done after {} frames\".format(frame))\n",
    "                        break\n",
    "                    \n",
    "                    for (i, loc) in env.consumption:\n",
    "                        if loc[0] > second_pile_x:\n",
    "                            # print ('agent {} gathered an apple in 2nd pile'.format(i))\n",
    "                            crossed[i] = 1\n",
    "            \n",
    "                # Print out statistics of AI agents\n",
    "                ep_rewards = 0\n",
    "                ep_tags = 0\n",
    "                ep_US_hits = 0\n",
    "                ep_THEM_hits = 0\n",
    "                ep_crossed = sum(crossed)     # calculated num agents gathering in 2nd pile for episode\n",
    "\n",
    "                if verbose:\n",
    "                    print ('\\nStatistics by Agent')\n",
    "                    print ('===================')\n",
    "                for i in range(num_ai_agents):\n",
    "                    agent_tags = sum(agents[i].tag_hist)\n",
    "                    ep_tags += agent_tags\n",
    "                    cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                    agent_reward = sum(agents[i].rewards)\n",
    "                    ep_rewards += agent_reward\n",
    "                    cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                    agent_US_hits = sum(agents[i].US_hits)\n",
    "                    agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                    ep_US_hits += agent_US_hits\n",
    "                    ep_THEM_hits += agent_THEM_hits\n",
    "                    cum_agent_US_hits[i] += agent_US_hits\n",
    "                    cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                    if verbose:\n",
    "                        # print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                        print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                        # print('US agents hit = {}'.format(agent_US_hits))\n",
    "                        # print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "                cum_rewards += ep_rewards\n",
    "                cum_crossed += ep_crossed\n",
    "                cum_tags += ep_tags\n",
    "                cum_US_hits += ep_US_hits\n",
    "                cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "                if verbose:\n",
    "                    print ('\\nStatistics in Aggregate')\n",
    "                    print ('=======================')\n",
    "                    print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                    print ('Num agents crossed = {}'.format(ep_crossed))\n",
    "                    # print ('Num laser fired = {}'.format(ep_tags))\n",
    "                    # print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                    # print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                    # print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "                if verbose:\n",
    "                    print ('\\nStatistics by Tribe')\n",
    "                    print ('===================')\n",
    "                for i, t in enumerate(tribes):\n",
    "                    if t.name is not 'Crazies':\n",
    "                        ep_tribe_reward = sum(t.sum_rewards())\n",
    "                        cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                        if verbose:\n",
    "                            print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].clear_history()\n",
    "\n",
    "            env.close()  # Close the rendering window\n",
    "            end = time.time()\n",
    "\n",
    "            print ('\\nAverage Statistics in Aggregate')\n",
    "            print ('=================================')\n",
    "            total_rewards = cum_rewards/max_episodes\n",
    "            print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "            av_agent_reward[traj_num][dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "            print ('Av. agent reward = {:.2f}'.format(av_agent_reward[traj_num][dir_num][eps_num]))\n",
    "            av_agent_crossed[traj_num][dir_num][eps_num] = cum_crossed/max_episodes\n",
    "            print ('Agents crossed (2nd food pile) = {:.1f}'.format(av_agent_crossed[traj_num][dir_num][eps_num]))\n",
    "            # print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "            # print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "            # print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "            # print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "            print ('\\nAverage Statistics by Tribe')\n",
    "            print ('=============================')\n",
    "       \n",
    "            for i, tribe in enumerate(tribes):\n",
    "                if tribe.name is not 'Crazies':\n",
    "                    tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                    print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                    # Keep track of dominating team and the rewards gathered (only if more than 1 tribe)\n",
    "                    if len(tribes) > 1:\n",
    "                        if tribe_reward > dom_tribe_reward[traj_num][dir_num][eps_num]:   \n",
    "                            dom_tribe_reward[traj_num][dir_num][eps_num] = tribe_reward\n",
    "                            dominating_tribe[traj_num][dir_num][eps_num]  = tribe.name\n",
    "\n",
    "            # Team dominance calculation (only if more than 1 tribe)\n",
    "            if len(tribes) > 1:\n",
    "                print ('Dominating Tribe: {}'.format(dominating_tribe[traj_num][dir_num][eps_num]))\n",
    "                dominance[traj_num][dir_num][eps_num] = dom_tribe_reward[traj_num][dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[traj_num][dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "                print ('Team dominance: {0:.2f}x'.format(dominance[traj_num][dir_num][eps_num]))\n",
    "\n",
    "            print ('\\nAverage Statistics by Agent')\n",
    "            print ('=============================')\n",
    "            for i in range(num_ai_agents):\n",
    "                # print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                #                                               cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "                print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "                # print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "                # print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "            print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "            # print dominating team and dominance factor (only if more than 1 tribe)\n",
    "            if len(tribes) > 1:\n",
    "                for tribe in dominating_tribe:   # Dominating team\n",
    "                    print(tribe)\n",
    "                for value in dominance:      # Team dominance\n",
    "                    print(value)\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "for agents_crossed in av_agent_crossed:   # Average num agents gathering in 2nd food pile\n",
    "    print(agents_crossed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics for Research Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Agent Rewards\n",
      "For Trajectory 0\n",
      "[16.233333333333334, 15.52, 14.653333333333332, 12.559999999999999, 16.466666666666665, 12.496666666666666]\n",
      "[19.18, 19.826666666666668, 19.736666666666668, 16.106666666666666, 15.943333333333333, 14.343333333333334]\n",
      "[20.009999999999998, 21.17666666666667, 21.34, 19.96333333333333, 20.593333333333334, 18.43]\n",
      "For Trajectory 1\n",
      "[16.6, 16.46, 15.883333333333335, 13.303333333333333, 16.553333333333335, 12.493333333333334]\n",
      "[18.766666666666666, 18.94, 17.923333333333332, 16.366666666666667, 16.336666666666666, 14.966666666666665]\n",
      "[21.166666666666664, 20.116666666666667, 21.903333333333332, 19.533333333333335, 18.903333333333332, 22.943333333333335]\n",
      "For Trajectory 2\n",
      "[15.363333333333333, 15.01, 16.21333333333333, 13.543333333333333, 16.363333333333333, 11.503333333333334]\n",
      "[18.653333333333332, 18.856666666666666, 18.94, 16.10333333333333, 16.303333333333335, 15.026666666666667]\n",
      "[20.343333333333334, 19.666666666666664, 20.533333333333335, 19.473333333333333, 18.630000000000003, 20.28666666666667]\n",
      "For Trajectory 3\n",
      "[14.913333333333332, 15.363333333333333, 15.846666666666668, 14.253333333333334, 14.693333333333333, 11.443333333333333]\n",
      "[16.556666666666665, 18.67666666666667, 18.706666666666667, 14.946666666666667, 16.740000000000002, 16.53666666666667]\n",
      "[21.056666666666665, 24.016666666666666, 27.51666666666667, 25.886666666666667, 24.55, 26.866666666666667]\n",
      "For Trajectory 4\n",
      "[12.876666666666669, 13.430000000000001, 13.736666666666668, 13.126666666666669, 13.940000000000001, 10.613333333333333]\n",
      "[14.463333333333333, 18.453333333333333, 18.39666666666667, 14.166666666666666, 13.356666666666666, 13.873333333333331]\n",
      "[17.97, 18.91, 19.826666666666668, 18.496666666666666, 19.363333333333333, 19.043333333333333]\n",
      "For Trajectory 5\n",
      "[14.293333333333333, 14.506666666666666, 14.033333333333335, 11.796666666666667, 14.059999999999999, 9.52]\n",
      "[15.493333333333334, 15.95, 18.10333333333333, 14.016666666666666, 14.903333333333332, 12.223333333333333]\n",
      "[17.503333333333334, 17.416666666666664, 19.4, 18.416666666666664, 17.92666666666667, 22.256666666666668]\n",
      "For Trajectory 6\n",
      "[12.26, 13.930000000000001, 14.043333333333333, 11.35, 13.26, 10.486666666666666]\n",
      "[16.14, 17.23, 17.61, 14.773333333333332, 14.656666666666666, 13.4]\n",
      "[17.293333333333333, 18.443333333333335, 19.07, 17.293333333333333, 17.5, 21.193333333333335]\n",
      "For Trajectory 7\n",
      "[11.426666666666666, 13.919999999999998, 13.336666666666668, 11.563333333333334, 12.52, 8.933333333333334]\n",
      "[14.123333333333331, 14.873333333333331, 16.0, 11.953333333333333, 11.756666666666666, 11.209999999999999]\n",
      "[16.45, 18.009999999999998, 17.5, 16.236666666666668, 15.836666666666668, 21.083333333333336]\n",
      "Agents Crossed (2nd food pile)\n",
      "For Trajectory 0\n",
      "[6.066666666666666, 7.433333333333334, 6.0, 6.466666666666667, 4.666666666666667, 4.166666666666667]\n",
      "[7.133333333333334, 8.033333333333333, 7.166666666666667, 6.5, 6.266666666666667, 5.766666666666667]\n",
      "[5.766666666666667, 7.866666666666666, 8.0, 7.966666666666667, 7.233333333333333, 5.466666666666667]\n",
      "For Trajectory 1\n",
      "[6.4, 7.4, 7.066666666666666, 6.266666666666667, 5.433333333333334, 4.933333333333334]\n",
      "[7.533333333333333, 7.9, 7.433333333333334, 7.0, 6.9, 6.5]\n",
      "[6.133333333333334, 8.166666666666666, 8.266666666666667, 8.0, 7.9, 7.166666666666667]\n",
      "For Trajectory 2\n",
      "[6.433333333333334, 7.033333333333333, 6.766666666666667, 6.533333333333333, 5.233333333333333, 4.7]\n",
      "[7.666666666666667, 7.933333333333334, 7.433333333333334, 6.866666666666666, 7.3, 6.633333333333334]\n",
      "[6.333333333333333, 8.066666666666666, 8.3, 7.733333333333333, 8.1, 6.666666666666667]\n",
      "For Trajectory 3\n",
      "[6.133333333333334, 7.266666666666667, 6.733333333333333, 6.2, 4.7, 3.9]\n",
      "[6.533333333333333, 6.7, 6.966666666666667, 5.766666666666667, 6.433333333333334, 5.433333333333334]\n",
      "[5.366666666666666, 7.166666666666667, 7.566666666666666, 7.566666666666666, 7.066666666666666, 6.433333333333334]\n",
      "For Trajectory 4\n",
      "[5.466666666666667, 6.933333333333334, 6.333333333333333, 6.066666666666666, 4.333333333333333, 4.133333333333334]\n",
      "[5.966666666666667, 7.266666666666667, 6.533333333333333, 5.6, 5.833333333333333, 5.7]\n",
      "[5.133333333333334, 6.7, 7.833333333333333, 7.5, 6.833333333333333, 6.133333333333334]\n",
      "For Trajectory 5\n",
      "[5.966666666666667, 7.233333333333333, 6.8, 6.133333333333334, 5.0, 4.066666666666666]\n",
      "[7.133333333333334, 7.3, 7.3, 5.933333333333334, 6.533333333333333, 5.833333333333333]\n",
      "[5.0, 6.933333333333334, 8.0, 7.766666666666667, 7.033333333333333, 6.633333333333334]\n",
      "For Trajectory 6\n",
      "[5.366666666666666, 7.1, 6.433333333333334, 5.366666666666666, 4.8, 4.133333333333334]\n",
      "[6.833333333333333, 7.6, 7.333333333333333, 6.4, 6.733333333333333, 6.133333333333334]\n",
      "[5.233333333333333, 7.3, 7.533333333333333, 7.666666666666667, 6.8, 6.366666666666666]\n",
      "For Trajectory 7\n",
      "[5.066666666666666, 7.4, 6.5, 5.066666666666666, 5.233333333333333, 4.066666666666666]\n",
      "[6.9, 6.8, 7.4, 5.633333333333334, 5.733333333333333, 5.366666666666666]\n",
      "[4.9, 7.333333333333333, 7.566666666666666, 7.966666666666667, 7.366666666666666, 6.5]\n"
     ]
    }
   ],
   "source": [
    "# Note: Statistics for Research Report   \n",
    "print ('Average Agent Rewards')\n",
    "for k, reward_traj in enumerate(av_agent_reward):   # Average agent reward\n",
    "    print (\"For Trajectory {}\".format(k))\n",
    "    for j, reward in enumerate(reward_traj):\n",
    "        print (reward)\n",
    "    \n",
    "print ('Agents Crossed (2nd food pile)')    \n",
    "for k, crossed_traj in enumerate(av_agent_crossed):   # Average num agents gathering in 2nd food pile\n",
    "    print (\"For Trajectory {}\".format(k))\n",
    "    for j, agents_crossed in enumerate(crossed_traj):\n",
    "        print(agents_crossed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Game-Play - Trajectories (Map = food_d37_river_w1_d25)\n",
    "\n",
    "Our research requires the gathering of agent and team metrics averaged over 30 episodes of game play. The two metrics gathered and averaged are:\n",
    "\n",
    "* Average agent reward - average number of apples gathered per agent per episode  \n",
    "* The number of agents gathering apples at the 2nd food pile \n",
    "\n",
    "<img src=\"images/Crossing-river-leadfollow.png\" width=\"600\">\n",
    "\n",
    "This is a batch run of 30-episode game-plays over:  \n",
    "(1) Trajectories  \n",
    "(2) Training parameters (starting temp, steps/episode, static target loc, or moving target trajectory)  \n",
    "(3) Episodes trained (500, 1000, 1500, 2000, 2500, 3000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Trajectory = T1 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.1\n",
      "Av. agent reward = 22.31\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 4.7\n",
      "Agent1 reward is 52.4\n",
      "Agent2 reward is 13.8\n",
      "Agent3 reward is 8.8\n",
      "Agent4 reward is 22.6\n",
      "Agent5 reward is 6.8\n",
      "Agent6 reward is 47.8\n",
      "Agent7 reward is 38.0\n",
      "Agent8 reward is 11.8\n",
      "Agent9 reward is 16.5\n",
      "Training time per epochs: 5.53 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 234.4\n",
      "Av. agent reward = 23.44\n",
      "Agents crossed (2nd food pile) = 8.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 234.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.8\n",
      "Agent1 reward is 86.3\n",
      "Agent2 reward is 20.3\n",
      "Agent3 reward is 21.1\n",
      "Agent4 reward is 25.5\n",
      "Agent5 reward is 15.0\n",
      "Agent6 reward is 24.1\n",
      "Agent7 reward is 12.8\n",
      "Agent8 reward is 13.7\n",
      "Agent9 reward is 14.8\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 257.7\n",
      "Av. agent reward = 25.77\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 257.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 94.2\n",
      "Agent2 reward is 19.5\n",
      "Agent3 reward is 16.1\n",
      "Agent4 reward is 15.7\n",
      "Agent5 reward is 11.1\n",
      "Agent6 reward is 18.3\n",
      "Agent7 reward is 58.3\n",
      "Agent8 reward is 13.1\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.0\n",
      "Av. agent reward = 22.30\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.0\n",
      "Agent1 reward is 95.3\n",
      "Agent2 reward is 20.2\n",
      "Agent3 reward is 21.2\n",
      "Agent4 reward is 20.0\n",
      "Agent5 reward is 15.6\n",
      "Agent6 reward is 15.4\n",
      "Agent7 reward is 21.8\n",
      "Agent8 reward is 10.6\n",
      "Agent9 reward is 3.0\n",
      "Training time per epochs: 5.46 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 259.3\n",
      "Av. agent reward = 25.93\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 259.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.0\n",
      "Agent1 reward is 87.4\n",
      "Agent2 reward is 22.2\n",
      "Agent3 reward is 11.9\n",
      "Agent4 reward is 25.5\n",
      "Agent5 reward is 13.8\n",
      "Agent6 reward is 11.6\n",
      "Agent7 reward is 60.8\n",
      "Agent8 reward is 12.0\n",
      "Agent9 reward is 14.1\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 229.9\n",
      "Av. agent reward = 22.99\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 229.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 82.1\n",
      "Agent2 reward is 19.5\n",
      "Agent3 reward is 19.6\n",
      "Agent4 reward is 21.6\n",
      "Agent5 reward is 21.5\n",
      "Agent6 reward is 19.6\n",
      "Agent7 reward is 25.6\n",
      "Agent8 reward is 15.6\n",
      "Agent9 reward is 4.7\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 227.2\n",
      "Av. agent reward = 22.72\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 227.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 24.0\n",
      "Agent1 reward is 41.6\n",
      "Agent2 reward is 5.9\n",
      "Agent3 reward is 22.9\n",
      "Agent4 reward is 36.7\n",
      "Agent5 reward is 29.4\n",
      "Agent6 reward is 28.6\n",
      "Agent7 reward is 23.8\n",
      "Agent8 reward is -18.8\n",
      "Agent9 reward is 33.0\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.2\n",
      "Av. agent reward = 21.12\n",
      "Agents crossed (2nd food pile) = 8.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.7\n",
      "Agent1 reward is 40.2\n",
      "Agent2 reward is 16.7\n",
      "Agent3 reward is 27.1\n",
      "Agent4 reward is 6.8\n",
      "Agent5 reward is 9.7\n",
      "Agent6 reward is 4.1\n",
      "Agent7 reward is 20.6\n",
      "Agent8 reward is 5.8\n",
      "Agent9 reward is 65.6\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.5\n",
      "Av. agent reward = 19.65\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.7\n",
      "Agent1 reward is 51.7\n",
      "Agent2 reward is 24.8\n",
      "Agent3 reward is 20.8\n",
      "Agent4 reward is 22.7\n",
      "Agent5 reward is -0.3\n",
      "Agent6 reward is 14.6\n",
      "Agent7 reward is 21.2\n",
      "Agent8 reward is -28.4\n",
      "Agent9 reward is 48.5\n",
      "Training time per epochs: 5.47 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 228.5\n",
      "Av. agent reward = 22.85\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 228.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.2\n",
      "Agent1 reward is 54.2\n",
      "Agent2 reward is 17.5\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 17.5\n",
      "Agent5 reward is -0.5\n",
      "Agent6 reward is 5.7\n",
      "Agent7 reward is 10.6\n",
      "Agent8 reward is 45.1\n",
      "Agent9 reward is 41.2\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 234.6\n",
      "Av. agent reward = 23.46\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 234.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.6\n",
      "Agent1 reward is 31.3\n",
      "Agent2 reward is 15.2\n",
      "Agent3 reward is 28.3\n",
      "Agent4 reward is 24.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 10.6\n",
      "Agent7 reward is 18.7\n",
      "Agent8 reward is 63.6\n",
      "Agent9 reward is 28.7\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 126.6\n",
      "Av. agent reward = 12.66\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 126.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.8\n",
      "Agent1 reward is -0.9\n",
      "Agent2 reward is 17.3\n",
      "Agent3 reward is 13.3\n",
      "Agent4 reward is 18.7\n",
      "Agent5 reward is 2.8\n",
      "Agent6 reward is 25.8\n",
      "Agent7 reward is 10.7\n",
      "Agent8 reward is 21.4\n",
      "Agent9 reward is 15.7\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 193.1\n",
      "Av. agent reward = 19.31\n",
      "Agents crossed (2nd food pile) = 5.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 193.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.9\n",
      "Agent1 reward is 17.2\n",
      "Agent2 reward is 57.0\n",
      "Agent3 reward is 13.5\n",
      "Agent4 reward is 23.7\n",
      "Agent5 reward is 22.4\n",
      "Agent6 reward is 26.0\n",
      "Agent7 reward is 32.0\n",
      "Agent8 reward is 6.2\n",
      "Agent9 reward is -3.9\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 1000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 161.9\n",
      "Av. agent reward = 16.19\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 161.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.1\n",
      "Agent1 reward is 9.1\n",
      "Agent2 reward is 21.1\n",
      "Agent3 reward is 8.5\n",
      "Agent4 reward is 15.9\n",
      "Agent5 reward is 29.0\n",
      "Agent6 reward is 18.6\n",
      "Agent7 reward is 21.3\n",
      "Agent8 reward is 5.8\n",
      "Agent9 reward is 10.5\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.3\n",
      "Av. agent reward = 21.13\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.1\n",
      "Agent1 reward is -20.9\n",
      "Agent2 reward is 22.9\n",
      "Agent3 reward is 24.5\n",
      "Agent4 reward is 14.7\n",
      "Agent5 reward is 20.2\n",
      "Agent6 reward is 23.1\n",
      "Agent7 reward is 88.1\n",
      "Agent8 reward is 1.3\n",
      "Agent9 reward is 7.3\n",
      "Training time per epochs: 5.46 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 220.7\n",
      "Av. agent reward = 22.07\n",
      "Agents crossed (2nd food pile) = 6.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 220.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 43.0\n",
      "Agent1 reward is 18.3\n",
      "Agent2 reward is 14.1\n",
      "Agent3 reward is 9.4\n",
      "Agent4 reward is 6.1\n",
      "Agent5 reward is 12.9\n",
      "Agent6 reward is 16.4\n",
      "Agent7 reward is 99.6\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.8\n",
      "Training time per epochs: 5.47 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 187.5\n",
      "Av. agent reward = 18.75\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 187.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 46.5\n",
      "Agent1 reward is 22.4\n",
      "Agent2 reward is 10.1\n",
      "Agent3 reward is 34.1\n",
      "Agent4 reward is 15.4\n",
      "Agent5 reward is 3.6\n",
      "Agent6 reward is 20.9\n",
      "Agent7 reward is 23.5\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 11.1\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 128.9\n",
      "Av. agent reward = 12.89\n",
      "Agents crossed (2nd food pile) = 5.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 128.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.9\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 15.1\n",
      "Agent3 reward is 27.6\n",
      "Agent4 reward is -0.4\n",
      "Agent5 reward is 23.6\n",
      "Agent6 reward is 20.7\n",
      "Agent7 reward is 11.0\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 13.3\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.6\n",
      "Av. agent reward = 19.26\n",
      "Agents crossed (2nd food pile) = 5.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.8\n",
      "Agent1 reward is -2.0\n",
      "Agent2 reward is 17.7\n",
      "Agent3 reward is 2.3\n",
      "Agent4 reward is 26.6\n",
      "Agent5 reward is 23.0\n",
      "Agent6 reward is 26.4\n",
      "Agent7 reward is 39.8\n",
      "Agent8 reward is 16.6\n",
      "Agent9 reward is 20.5\n",
      "Training time per epochs: 5.47 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 213.3\n",
      "Av. agent reward = 21.33\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 213.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.0\n",
      "Agent1 reward is 33.9\n",
      "Agent2 reward is 17.8\n",
      "Agent3 reward is 20.6\n",
      "Agent4 reward is 34.7\n",
      "Agent5 reward is 28.8\n",
      "Agent6 reward is 21.5\n",
      "Agent7 reward is 14.5\n",
      "Agent8 reward is 13.8\n",
      "Agent9 reward is 6.6\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 214.9\n",
      "Av. agent reward = 21.49\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 214.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 44.1\n",
      "Agent1 reward is 23.5\n",
      "Agent2 reward is 9.8\n",
      "Agent3 reward is 23.1\n",
      "Agent4 reward is 31.0\n",
      "Agent5 reward is 19.6\n",
      "Agent6 reward is 10.0\n",
      "Agent7 reward is 23.1\n",
      "Agent8 reward is 21.5\n",
      "Agent9 reward is 9.4\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 208.2\n",
      "Av. agent reward = 20.82\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 208.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 36.1\n",
      "Agent1 reward is 16.4\n",
      "Agent2 reward is 4.7\n",
      "Agent3 reward is 21.6\n",
      "Agent4 reward is 24.5\n",
      "Agent5 reward is 21.3\n",
      "Agent6 reward is 19.6\n",
      "Agent7 reward is 28.1\n",
      "Agent8 reward is 24.0\n",
      "Agent9 reward is 11.9\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.3\n",
      "Av. agent reward = 22.33\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 55.0\n",
      "Agent1 reward is 21.9\n",
      "Agent2 reward is 11.9\n",
      "Agent3 reward is 17.4\n",
      "Agent4 reward is 25.6\n",
      "Agent5 reward is 22.8\n",
      "Agent6 reward is 19.4\n",
      "Agent7 reward is 18.8\n",
      "Agent8 reward is 19.7\n",
      "Agent9 reward is 10.8\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 292.1\n",
      "Av. agent reward = 29.21\n",
      "Agents crossed (2nd food pile) = 7.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 292.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 70.7\n",
      "Agent1 reward is 47.8\n",
      "Agent2 reward is 16.8\n",
      "Agent3 reward is 19.4\n",
      "Agent4 reward is 20.2\n",
      "Agent5 reward is 67.7\n",
      "Agent6 reward is 13.7\n",
      "Agent7 reward is 16.9\n",
      "Agent8 reward is 11.2\n",
      "Agent9 reward is 7.8\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trajectory = T2 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 219.4\n",
      "Av. agent reward = 21.94\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 219.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 3.9\n",
      "Agent1 reward is 46.5\n",
      "Agent2 reward is 9.7\n",
      "Agent3 reward is 11.0\n",
      "Agent4 reward is 26.5\n",
      "Agent5 reward is 6.5\n",
      "Agent6 reward is 50.0\n",
      "Agent7 reward is 31.3\n",
      "Agent8 reward is 14.0\n",
      "Agent9 reward is 19.9\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 235.0\n",
      "Av. agent reward = 23.50\n",
      "Agents crossed (2nd food pile) = 8.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 235.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.4\n",
      "Agent1 reward is 88.8\n",
      "Agent2 reward is 20.1\n",
      "Agent3 reward is 15.1\n",
      "Agent4 reward is 23.8\n",
      "Agent5 reward is 14.8\n",
      "Agent6 reward is 19.5\n",
      "Agent7 reward is 14.8\n",
      "Agent8 reward is 21.3\n",
      "Agent9 reward is 17.0\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 1500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 226.9\n",
      "Av. agent reward = 22.69\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 226.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.6\n",
      "Agent1 reward is 99.8\n",
      "Agent2 reward is 11.4\n",
      "Agent3 reward is 8.3\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 10.2\n",
      "Agent6 reward is 23.7\n",
      "Agent7 reward is 23.9\n",
      "Agent8 reward is 21.3\n",
      "Agent9 reward is 12.3\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 251.5\n",
      "Av. agent reward = 25.15\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 251.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.7\n",
      "Agent1 reward is 96.8\n",
      "Agent2 reward is 24.2\n",
      "Agent3 reward is 18.5\n",
      "Agent4 reward is 21.7\n",
      "Agent5 reward is 22.5\n",
      "Agent6 reward is 19.0\n",
      "Agent7 reward is 19.0\n",
      "Agent8 reward is 20.3\n",
      "Agent9 reward is 12.2\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 215.1\n",
      "Av. agent reward = 21.51\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 215.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.3\n",
      "Agent1 reward is 75.0\n",
      "Agent2 reward is 24.4\n",
      "Agent3 reward is 13.6\n",
      "Agent4 reward is 24.2\n",
      "Agent5 reward is 19.4\n",
      "Agent6 reward is 19.5\n",
      "Agent7 reward is 19.6\n",
      "Agent8 reward is 10.6\n",
      "Agent9 reward is 10.9\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 258.3\n",
      "Av. agent reward = 25.83\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 258.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 87.1\n",
      "Agent2 reward is 14.6\n",
      "Agent3 reward is 24.5\n",
      "Agent4 reward is 25.3\n",
      "Agent5 reward is 27.9\n",
      "Agent6 reward is 22.1\n",
      "Agent7 reward is 24.7\n",
      "Agent8 reward is 13.7\n",
      "Agent9 reward is 18.4\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 233.9\n",
      "Av. agent reward = 23.39\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 233.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.4\n",
      "Agent1 reward is 36.8\n",
      "Agent2 reward is 7.0\n",
      "Agent3 reward is 29.8\n",
      "Agent4 reward is 35.1\n",
      "Agent5 reward is 31.4\n",
      "Agent6 reward is 24.8\n",
      "Agent7 reward is 17.7\n",
      "Agent8 reward is -9.4\n",
      "Agent9 reward is 40.2\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 214.0\n",
      "Av. agent reward = 21.40\n",
      "Agents crossed (2nd food pile) = 9.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 214.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 24.5\n",
      "Agent1 reward is 46.4\n",
      "Agent2 reward is 19.6\n",
      "Agent3 reward is 21.7\n",
      "Agent4 reward is 14.7\n",
      "Agent5 reward is 8.7\n",
      "Agent6 reward is 15.0\n",
      "Agent7 reward is 26.7\n",
      "Agent8 reward is 5.7\n",
      "Agent9 reward is 31.1\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 137.9\n",
      "Av. agent reward = 13.79\n",
      "Agents crossed (2nd food pile) = 8.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 137.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.5\n",
      "Agent1 reward is 38.0\n",
      "Agent2 reward is 22.6\n",
      "Agent3 reward is 33.7\n",
      "Agent4 reward is 24.6\n",
      "Agent5 reward is 6.0\n",
      "Agent6 reward is 22.0\n",
      "Agent7 reward is 21.9\n",
      "Agent8 reward is -68.6\n",
      "Agent9 reward is 14.3\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.6\n",
      "Av. agent reward = 19.66\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 11.7\n",
      "Agent1 reward is 48.2\n",
      "Agent2 reward is 18.4\n",
      "Agent3 reward is 13.9\n",
      "Agent4 reward is 15.6\n",
      "Agent5 reward is 1.2\n",
      "Agent6 reward is 14.8\n",
      "Agent7 reward is 13.1\n",
      "Agent8 reward is 34.2\n",
      "Agent9 reward is 25.4\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 188.8\n",
      "Av. agent reward = 18.88\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 188.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 11.5\n",
      "Agent1 reward is 38.7\n",
      "Agent2 reward is 11.2\n",
      "Agent3 reward is 21.6\n",
      "Agent4 reward is 18.9\n",
      "Agent5 reward is -2.7\n",
      "Agent6 reward is 13.1\n",
      "Agent7 reward is 16.7\n",
      "Agent8 reward is 42.1\n",
      "Agent9 reward is 17.8\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 107.4\n",
      "Av. agent reward = 10.74\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 107.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.2\n",
      "Agent1 reward is -0.9\n",
      "Agent2 reward is 21.3\n",
      "Agent3 reward is 20.8\n",
      "Agent4 reward is 14.1\n",
      "Agent5 reward is 8.3\n",
      "Agent6 reward is 21.5\n",
      "Agent7 reward is 15.9\n",
      "Agent8 reward is 7.6\n",
      "Agent9 reward is 1.1\n",
      "Training time per epochs: 5.45 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 208.8\n",
      "Av. agent reward = 20.88\n",
      "Agents crossed (2nd food pile) = 5.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 208.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.6\n",
      "Agent1 reward is 18.7\n",
      "Agent2 reward is 53.8\n",
      "Agent3 reward is 13.5\n",
      "Agent4 reward is 33.3\n",
      "Agent5 reward is 30.1\n",
      "Agent6 reward is 15.9\n",
      "Agent7 reward is 30.8\n",
      "Agent8 reward is 12.8\n",
      "Agent9 reward is -1.8\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 146.0\n",
      "Av. agent reward = 14.60\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 146.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.6\n",
      "Agent1 reward is 14.9\n",
      "Agent2 reward is 4.3\n",
      "Agent3 reward is 12.3\n",
      "Agent4 reward is 17.0\n",
      "Agent5 reward is 29.4\n",
      "Agent6 reward is 19.0\n",
      "Agent7 reward is 37.5\n",
      "Agent8 reward is -8.0\n",
      "Agent9 reward is -2.0\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 200.8\n",
      "Av. agent reward = 20.08\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 200.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.6\n",
      "Agent1 reward is 0.3\n",
      "Agent2 reward is -0.8\n",
      "Agent3 reward is 16.0\n",
      "Agent4 reward is 12.8\n",
      "Agent5 reward is 15.5\n",
      "Agent6 reward is 17.1\n",
      "Agent7 reward is 102.1\n",
      "Agent8 reward is 0.1\n",
      "Agent9 reward is 16.1\n",
      "Training time per epochs: 5.68 sec\n",
      "###### Trained episodes = 2000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 230.8\n",
      "Av. agent reward = 23.08\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 230.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 31.9\n",
      "Agent1 reward is 14.7\n",
      "Agent2 reward is 16.7\n",
      "Agent3 reward is 8.6\n",
      "Agent4 reward is 1.0\n",
      "Agent5 reward is 19.3\n",
      "Agent6 reward is 22.1\n",
      "Agent7 reward is 103.9\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 12.5\n",
      "Training time per epochs: 7.36 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 165.3\n",
      "Av. agent reward = 16.53\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 165.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 37.0\n",
      "Agent1 reward is 11.8\n",
      "Agent2 reward is 11.0\n",
      "Agent3 reward is 23.2\n",
      "Agent4 reward is 8.7\n",
      "Agent5 reward is 3.4\n",
      "Agent6 reward is 24.8\n",
      "Agent7 reward is 28.3\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 17.3\n",
      "Training time per epochs: 7.56 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 149.4\n",
      "Av. agent reward = 14.94\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 149.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.1\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 18.2\n",
      "Agent3 reward is 32.2\n",
      "Agent4 reward is 0.8\n",
      "Agent5 reward is 17.5\n",
      "Agent6 reward is 21.8\n",
      "Agent7 reward is 23.0\n",
      "Agent8 reward is 0.9\n",
      "Agent9 reward is 21.0\n",
      "Training time per epochs: 7.84 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 199.5\n",
      "Av. agent reward = 19.95\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 199.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.7\n",
      "Agent1 reward is -2.0\n",
      "Agent2 reward is 17.6\n",
      "Agent3 reward is 2.0\n",
      "Agent4 reward is 24.1\n",
      "Agent5 reward is 22.6\n",
      "Agent6 reward is 33.8\n",
      "Agent7 reward is 43.3\n",
      "Agent8 reward is 20.8\n",
      "Agent9 reward is 17.7\n",
      "Training time per epochs: 7.81 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 221.3\n",
      "Av. agent reward = 22.13\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 221.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.8\n",
      "Agent1 reward is 30.6\n",
      "Agent2 reward is 13.6\n",
      "Agent3 reward is 19.7\n",
      "Agent4 reward is 40.8\n",
      "Agent5 reward is 26.4\n",
      "Agent6 reward is 27.5\n",
      "Agent7 reward is 19.4\n",
      "Agent8 reward is 12.6\n",
      "Agent9 reward is 6.9\n",
      "Training time per epochs: 8.22 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 227.1\n",
      "Av. agent reward = 22.71\n",
      "Agents crossed (2nd food pile) = 8.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 227.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 48.2\n",
      "Agent1 reward is 19.5\n",
      "Agent2 reward is 12.3\n",
      "Agent3 reward is 21.4\n",
      "Agent4 reward is 27.1\n",
      "Agent5 reward is 21.4\n",
      "Agent6 reward is 27.4\n",
      "Agent7 reward is 14.3\n",
      "Agent8 reward is 22.4\n",
      "Agent9 reward is 13.1\n",
      "Training time per epochs: 8.15 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 215.7\n",
      "Av. agent reward = 21.57\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 215.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 48.9\n",
      "Agent1 reward is 22.2\n",
      "Agent2 reward is 6.3\n",
      "Agent3 reward is 22.7\n",
      "Agent4 reward is 26.9\n",
      "Agent5 reward is 12.4\n",
      "Agent6 reward is 14.4\n",
      "Agent7 reward is 25.0\n",
      "Agent8 reward is 20.2\n",
      "Agent9 reward is 16.6\n",
      "Training time per epochs: 8.17 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 231.1\n",
      "Av. agent reward = 23.11\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 231.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 66.2\n",
      "Agent1 reward is 27.7\n",
      "Agent2 reward is 14.2\n",
      "Agent3 reward is 9.8\n",
      "Agent4 reward is 22.5\n",
      "Agent5 reward is 2.1\n",
      "Agent6 reward is 33.3\n",
      "Agent7 reward is 22.8\n",
      "Agent8 reward is 21.0\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 7.75 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 263.6\n",
      "Av. agent reward = 26.36\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 263.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 71.9\n",
      "Agent1 reward is 51.3\n",
      "Agent2 reward is 19.9\n",
      "Agent3 reward is 15.8\n",
      "Agent4 reward is 13.2\n",
      "Agent5 reward is 33.0\n",
      "Agent6 reward is 27.1\n",
      "Agent7 reward is 16.1\n",
      "Agent8 reward is 11.3\n",
      "Agent9 reward is 3.9\n",
      "Training time per epochs: 7.49 sec\n",
      "###### Trajectory = T3 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 231.9\n",
      "Av. agent reward = 23.19\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 231.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 4.8\n",
      "Agent1 reward is 62.1\n",
      "Agent2 reward is 12.5\n",
      "Agent3 reward is 7.3\n",
      "Agent4 reward is 23.3\n",
      "Agent5 reward is 7.3\n",
      "Agent6 reward is 51.8\n",
      "Agent7 reward is 32.8\n",
      "Agent8 reward is 13.0\n",
      "Agent9 reward is 17.0\n",
      "Training time per epochs: 7.41 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 237.5\n",
      "Av. agent reward = 23.75\n",
      "Agents crossed (2nd food pile) = 8.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 237.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.7\n",
      "Agent1 reward is 88.9\n",
      "Agent2 reward is 16.7\n",
      "Agent3 reward is 22.7\n",
      "Agent4 reward is 25.7\n",
      "Agent5 reward is 11.5\n",
      "Agent6 reward is 19.5\n",
      "Agent7 reward is 15.7\n",
      "Agent8 reward is 17.2\n",
      "Agent9 reward is 18.9\n",
      "Training time per epochs: 7.05 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 237.2\n",
      "Av. agent reward = 23.72\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 237.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.2\n",
      "Agent1 reward is 93.7\n",
      "Agent2 reward is 13.9\n",
      "Agent3 reward is 15.3\n",
      "Agent4 reward is 18.3\n",
      "Agent5 reward is 9.7\n",
      "Agent6 reward is 17.8\n",
      "Agent7 reward is 24.1\n",
      "Agent8 reward is 21.8\n",
      "Agent9 reward is 22.4\n",
      "Training time per epochs: 6.85 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 254.5\n",
      "Av. agent reward = 25.45\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 254.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 96.3\n",
      "Agent2 reward is 23.0\n",
      "Agent3 reward is 22.2\n",
      "Agent4 reward is 22.3\n",
      "Agent5 reward is 21.2\n",
      "Agent6 reward is 19.2\n",
      "Agent7 reward is 18.0\n",
      "Agent8 reward is 18.4\n",
      "Agent9 reward is 14.0\n",
      "Training time per epochs: 7.04 sec\n",
      "###### Trained episodes = 2500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 228.5\n",
      "Av. agent reward = 22.85\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 228.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 80.4\n",
      "Agent2 reward is 24.1\n",
      "Agent3 reward is 13.5\n",
      "Agent4 reward is 27.5\n",
      "Agent5 reward is 19.1\n",
      "Agent6 reward is 21.1\n",
      "Agent7 reward is 19.3\n",
      "Agent8 reward is 14.7\n",
      "Agent9 reward is 8.8\n",
      "Training time per epochs: 6.59 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 250.8\n",
      "Av. agent reward = 25.08\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 250.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 83.7\n",
      "Agent2 reward is 22.0\n",
      "Agent3 reward is 21.7\n",
      "Agent4 reward is 20.4\n",
      "Agent5 reward is 23.1\n",
      "Agent6 reward is 22.1\n",
      "Agent7 reward is 21.6\n",
      "Agent8 reward is 18.2\n",
      "Agent9 reward is 18.0\n",
      "Training time per epochs: 5.75 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 221.6\n",
      "Av. agent reward = 22.16\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 221.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.5\n",
      "Agent1 reward is 41.1\n",
      "Agent2 reward is 8.9\n",
      "Agent3 reward is 27.6\n",
      "Agent4 reward is 34.7\n",
      "Agent5 reward is 30.3\n",
      "Agent6 reward is 27.0\n",
      "Agent7 reward is 21.3\n",
      "Agent8 reward is -18.3\n",
      "Agent9 reward is 32.4\n",
      "Training time per epochs: 5.69 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 193.3\n",
      "Av. agent reward = 19.33\n",
      "Agents crossed (2nd food pile) = 8.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 193.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.1\n",
      "Agent1 reward is 38.0\n",
      "Agent2 reward is 17.4\n",
      "Agent3 reward is 22.6\n",
      "Agent4 reward is 16.2\n",
      "Agent5 reward is 9.0\n",
      "Agent6 reward is 11.3\n",
      "Agent7 reward is 27.1\n",
      "Agent8 reward is 4.0\n",
      "Agent9 reward is 31.6\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 156.7\n",
      "Av. agent reward = 15.67\n",
      "Agents crossed (2nd food pile) = 8.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 156.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.4\n",
      "Agent1 reward is 43.0\n",
      "Agent2 reward is 18.4\n",
      "Agent3 reward is 18.0\n",
      "Agent4 reward is 20.5\n",
      "Agent5 reward is 2.2\n",
      "Agent6 reward is 24.8\n",
      "Agent7 reward is 22.8\n",
      "Agent8 reward is -34.5\n",
      "Agent9 reward is 18.2\n",
      "Training time per epochs: 5.48 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 198.2\n",
      "Av. agent reward = 19.82\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 198.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 10.1\n",
      "Agent1 reward is 44.3\n",
      "Agent2 reward is 16.4\n",
      "Agent3 reward is 17.6\n",
      "Agent4 reward is 19.4\n",
      "Agent5 reward is -0.9\n",
      "Agent6 reward is 18.0\n",
      "Agent7 reward is 16.5\n",
      "Agent8 reward is 32.0\n",
      "Agent9 reward is 24.8\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 193.7\n",
      "Av. agent reward = 19.37\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 193.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 10.2\n",
      "Agent1 reward is 33.5\n",
      "Agent2 reward is 13.5\n",
      "Agent3 reward is 22.7\n",
      "Agent4 reward is 15.5\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 19.5\n",
      "Agent7 reward is 13.2\n",
      "Agent8 reward is 39.5\n",
      "Agent9 reward is 26.0\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 116.4\n",
      "Av. agent reward = 11.64\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 116.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -4.3\n",
      "Agent1 reward is -1.0\n",
      "Agent2 reward is 18.9\n",
      "Agent3 reward is 21.8\n",
      "Agent4 reward is 20.7\n",
      "Agent5 reward is 5.4\n",
      "Agent6 reward is 12.2\n",
      "Agent7 reward is 16.1\n",
      "Agent8 reward is 11.4\n",
      "Agent9 reward is 15.3\n",
      "Training time per epochs: 5.49 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 216.6\n",
      "Av. agent reward = 21.66\n",
      "Agents crossed (2nd food pile) = 5.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 216.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.3\n",
      "Agent1 reward is 19.4\n",
      "Agent2 reward is 55.2\n",
      "Agent3 reward is 12.4\n",
      "Agent4 reward is 27.9\n",
      "Agent5 reward is 36.4\n",
      "Agent6 reward is 17.4\n",
      "Agent7 reward is 36.0\n",
      "Agent8 reward is 13.2\n",
      "Agent9 reward is -2.5\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 152.5\n",
      "Av. agent reward = 15.25\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 152.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.1\n",
      "Agent1 reward is 10.8\n",
      "Agent2 reward is 19.5\n",
      "Agent3 reward is 10.3\n",
      "Agent4 reward is 15.8\n",
      "Agent5 reward is 30.4\n",
      "Agent6 reward is 18.7\n",
      "Agent7 reward is 31.3\n",
      "Agent8 reward is -4.2\n",
      "Agent9 reward is -1.2\n",
      "Training time per epochs: 5.58 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.2\n",
      "Av. agent reward = 22.32\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.7\n",
      "Agent1 reward is 0.4\n",
      "Agent2 reward is 13.6\n",
      "Agent3 reward is 15.2\n",
      "Agent4 reward is 16.8\n",
      "Agent5 reward is 19.0\n",
      "Agent6 reward is 25.1\n",
      "Agent7 reward is 99.8\n",
      "Agent8 reward is 0.4\n",
      "Agent9 reward is 10.3\n",
      "Training time per epochs: 5.75 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 232.4\n",
      "Av. agent reward = 23.24\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 232.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 36.8\n",
      "Agent1 reward is 7.5\n",
      "Agent2 reward is 16.7\n",
      "Agent3 reward is 11.4\n",
      "Agent4 reward is -1.6\n",
      "Agent5 reward is 23.2\n",
      "Agent6 reward is 18.9\n",
      "Agent7 reward is 103.9\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 15.7\n",
      "Training time per epochs: 5.82 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 134.5\n",
      "Av. agent reward = 13.45\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 134.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 40.1\n",
      "Agent1 reward is 11.8\n",
      "Agent2 reward is -7.9\n",
      "Agent3 reward is 21.9\n",
      "Agent4 reward is 10.5\n",
      "Agent5 reward is 7.0\n",
      "Agent6 reward is 17.2\n",
      "Agent7 reward is 21.5\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 12.4\n",
      "Training time per epochs: 5.88 sec\n",
      "###### Trained episodes = 3000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 126.8\n",
      "Av. agent reward = 12.68\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 126.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.4\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 4.0\n",
      "Agent3 reward is 21.3\n",
      "Agent4 reward is 0.7\n",
      "Agent5 reward is 21.8\n",
      "Agent6 reward is 22.4\n",
      "Agent7 reward is 19.6\n",
      "Agent8 reward is -0.0\n",
      "Agent9 reward is 22.7\n",
      "Training time per epochs: 5.76 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.9\n",
      "Av. agent reward = 19.29\n",
      "Agents crossed (2nd food pile) = 5.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.4\n",
      "Agent1 reward is -2.6\n",
      "Agent2 reward is 21.7\n",
      "Agent3 reward is -0.4\n",
      "Agent4 reward is 25.5\n",
      "Agent5 reward is 21.2\n",
      "Agent6 reward is 30.4\n",
      "Agent7 reward is 39.2\n",
      "Agent8 reward is 21.7\n",
      "Agent9 reward is 14.6\n",
      "Training time per epochs: 5.63 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 217.9\n",
      "Av. agent reward = 21.79\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 217.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.7\n",
      "Agent1 reward is 29.8\n",
      "Agent2 reward is 12.9\n",
      "Agent3 reward is 19.3\n",
      "Agent4 reward is 37.2\n",
      "Agent5 reward is 28.4\n",
      "Agent6 reward is 23.9\n",
      "Agent7 reward is 19.2\n",
      "Agent8 reward is 11.9\n",
      "Agent9 reward is 12.6\n",
      "Training time per epochs: 5.79 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 222.7\n",
      "Av. agent reward = 22.27\n",
      "Agents crossed (2nd food pile) = 8.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 222.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 49.4\n",
      "Agent1 reward is 18.6\n",
      "Agent2 reward is 10.9\n",
      "Agent3 reward is 18.2\n",
      "Agent4 reward is 26.5\n",
      "Agent5 reward is 17.6\n",
      "Agent6 reward is 23.4\n",
      "Agent7 reward is 19.9\n",
      "Agent8 reward is 19.8\n",
      "Agent9 reward is 18.3\n",
      "Training time per epochs: 5.77 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 190.7\n",
      "Av. agent reward = 19.07\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 190.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 44.4\n",
      "Agent1 reward is 15.3\n",
      "Agent2 reward is 4.2\n",
      "Agent3 reward is 22.0\n",
      "Agent4 reward is 20.5\n",
      "Agent5 reward is 14.7\n",
      "Agent6 reward is 12.0\n",
      "Agent7 reward is 22.8\n",
      "Agent8 reward is 20.8\n",
      "Agent9 reward is 13.9\n",
      "Training time per epochs: 5.73 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 202.5\n",
      "Av. agent reward = 20.25\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 202.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 63.5\n",
      "Agent1 reward is 22.4\n",
      "Agent2 reward is 15.6\n",
      "Agent3 reward is 13.4\n",
      "Agent4 reward is 20.5\n",
      "Agent5 reward is -0.4\n",
      "Agent6 reward is 24.2\n",
      "Agent7 reward is 16.6\n",
      "Agent8 reward is 17.7\n",
      "Agent9 reward is 9.0\n",
      "Training time per epochs: 5.77 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 266.0\n",
      "Av. agent reward = 26.60\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 266.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 69.5\n",
      "Agent1 reward is 63.4\n",
      "Agent2 reward is 17.1\n",
      "Agent3 reward is 18.3\n",
      "Agent4 reward is 11.6\n",
      "Agent5 reward is 30.6\n",
      "Agent6 reward is 21.3\n",
      "Agent7 reward is 18.8\n",
      "Agent8 reward is 9.2\n",
      "Agent9 reward is 6.2\n",
      "Training time per epochs: 5.60 sec\n",
      "###### Trajectory = T4 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 198.5\n",
      "Av. agent reward = 19.85\n",
      "Agents crossed (2nd food pile) = 4.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 198.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 4.0\n",
      "Agent1 reward is 56.9\n",
      "Agent2 reward is 12.3\n",
      "Agent3 reward is 8.1\n",
      "Agent4 reward is 25.1\n",
      "Agent5 reward is 5.4\n",
      "Agent6 reward is 10.7\n",
      "Agent7 reward is 53.9\n",
      "Agent8 reward is 13.0\n",
      "Agent9 reward is 9.0\n",
      "Training time per epochs: 5.55 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 221.3\n",
      "Av. agent reward = 22.13\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 221.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 2.2\n",
      "Agent1 reward is 73.4\n",
      "Agent2 reward is 38.3\n",
      "Agent3 reward is 12.9\n",
      "Agent4 reward is 8.2\n",
      "Agent5 reward is 27.3\n",
      "Agent6 reward is 11.1\n",
      "Agent7 reward is 15.5\n",
      "Agent8 reward is 17.2\n",
      "Agent9 reward is 15.2\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 252.0\n",
      "Av. agent reward = 25.20\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 252.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 86.5\n",
      "Agent2 reward is 6.9\n",
      "Agent3 reward is 2.1\n",
      "Agent4 reward is 2.2\n",
      "Agent5 reward is 18.9\n",
      "Agent6 reward is 11.3\n",
      "Agent7 reward is 80.7\n",
      "Agent8 reward is 24.4\n",
      "Agent9 reward is 19.3\n",
      "Training time per epochs: 5.64 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 154.5\n",
      "Av. agent reward = 15.45\n",
      "Agents crossed (2nd food pile) = 4.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 154.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 84.8\n",
      "Agent2 reward is 13.7\n",
      "Agent3 reward is 9.1\n",
      "Agent4 reward is 5.7\n",
      "Agent5 reward is -7.7\n",
      "Agent6 reward is 0.0\n",
      "Agent7 reward is 37.9\n",
      "Agent8 reward is 0.8\n",
      "Agent9 reward is 10.4\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 194.2\n",
      "Av. agent reward = 19.42\n",
      "Agents crossed (2nd food pile) = 4.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 194.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 79.3\n",
      "Agent2 reward is 23.4\n",
      "Agent3 reward is 5.5\n",
      "Agent4 reward is 8.8\n",
      "Agent5 reward is 26.3\n",
      "Agent6 reward is -0.1\n",
      "Agent7 reward is 78.0\n",
      "Agent8 reward is -1.3\n",
      "Agent9 reward is -25.7\n",
      "Training time per epochs: 5.76 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 188.2\n",
      "Av. agent reward = 18.82\n",
      "Agents crossed (2nd food pile) = 2.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 188.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 73.3\n",
      "Agent2 reward is 7.2\n",
      "Agent3 reward is 9.2\n",
      "Agent4 reward is 7.5\n",
      "Agent5 reward is 28.8\n",
      "Agent6 reward is -0.2\n",
      "Agent7 reward is 69.2\n",
      "Agent8 reward is -13.3\n",
      "Agent9 reward is 6.6\n",
      "Training time per epochs: 5.68 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 224.3\n",
      "Av. agent reward = 22.43\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 224.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 12.6\n",
      "Agent1 reward is 39.4\n",
      "Agent2 reward is 2.3\n",
      "Agent3 reward is 27.4\n",
      "Agent4 reward is 42.5\n",
      "Agent5 reward is 29.1\n",
      "Agent6 reward is 31.9\n",
      "Agent7 reward is 24.0\n",
      "Agent8 reward is -26.4\n",
      "Agent9 reward is 41.5\n",
      "Training time per epochs: 5.58 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 211.4\n",
      "Av. agent reward = 21.14\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 211.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 6.2\n",
      "Agent1 reward is 22.7\n",
      "Agent2 reward is 12.2\n",
      "Agent3 reward is 35.0\n",
      "Agent4 reward is 19.1\n",
      "Agent5 reward is 11.5\n",
      "Agent6 reward is 6.4\n",
      "Agent7 reward is 23.4\n",
      "Agent8 reward is 6.8\n",
      "Agent9 reward is 68.2\n",
      "Training time per epochs: 5.64 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 256.8\n",
      "Av. agent reward = 25.68\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 256.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.3\n",
      "Agent1 reward is 51.8\n",
      "Agent2 reward is 22.7\n",
      "Agent3 reward is 50.4\n",
      "Agent4 reward is 29.3\n",
      "Agent5 reward is 2.4\n",
      "Agent6 reward is 5.6\n",
      "Agent7 reward is 27.2\n",
      "Agent8 reward is 1.9\n",
      "Agent9 reward is 43.3\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 178.3\n",
      "Av. agent reward = 17.83\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 178.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.5\n",
      "Agent1 reward is 37.9\n",
      "Agent2 reward is 21.6\n",
      "Agent3 reward is 17.3\n",
      "Agent4 reward is 20.4\n",
      "Agent5 reward is 0.6\n",
      "Agent6 reward is 3.8\n",
      "Agent7 reward is 5.5\n",
      "Agent8 reward is 7.0\n",
      "Agent9 reward is 41.8\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 218.0\n",
      "Av. agent reward = 21.80\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 218.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.2\n",
      "Agent1 reward is 28.4\n",
      "Agent2 reward is 14.4\n",
      "Agent3 reward is 25.9\n",
      "Agent4 reward is 27.5\n",
      "Agent5 reward is -0.0\n",
      "Agent6 reward is 9.4\n",
      "Agent7 reward is 23.8\n",
      "Agent8 reward is 48.7\n",
      "Agent9 reward is 25.8\n",
      "Training time per epochs: 5.52 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 151.2\n",
      "Av. agent reward = 15.12\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 151.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -4.6\n",
      "Agent1 reward is -1.0\n",
      "Agent2 reward is 11.9\n",
      "Agent3 reward is 26.6\n",
      "Agent4 reward is 22.8\n",
      "Agent5 reward is 3.8\n",
      "Agent6 reward is 27.2\n",
      "Agent7 reward is 9.6\n",
      "Agent8 reward is 39.5\n",
      "Agent9 reward is 15.3\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 166.3\n",
      "Av. agent reward = 16.63\n",
      "Agents crossed (2nd food pile) = 4.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 166.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.3\n",
      "Agent1 reward is 18.6\n",
      "Agent2 reward is 54.3\n",
      "Agent3 reward is 12.4\n",
      "Agent4 reward is 31.0\n",
      "Agent5 reward is 11.4\n",
      "Agent6 reward is 18.6\n",
      "Agent7 reward is 25.7\n",
      "Agent8 reward is 4.1\n",
      "Agent9 reward is -10.0\n",
      "Training time per epochs: 5.56 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 160.0\n",
      "Av. agent reward = 16.00\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 160.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -5.7\n",
      "Agent1 reward is 26.4\n",
      "Agent2 reward is 2.6\n",
      "Agent3 reward is 4.3\n",
      "Agent4 reward is 15.9\n",
      "Agent5 reward is 45.8\n",
      "Agent6 reward is 21.8\n",
      "Agent7 reward is 35.3\n",
      "Agent8 reward is 6.3\n",
      "Agent9 reward is 7.3\n",
      "Training time per epochs: 5.54 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 187.0\n",
      "Av. agent reward = 18.70\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 187.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 11.8\n",
      "Agent1 reward is -32.8\n",
      "Agent2 reward is 15.5\n",
      "Agent3 reward is 20.1\n",
      "Agent4 reward is 16.2\n",
      "Agent5 reward is 29.4\n",
      "Agent6 reward is 27.4\n",
      "Agent7 reward is 84.1\n",
      "Agent8 reward is 1.3\n",
      "Agent9 reward is 14.0\n",
      "Training time per epochs: 5.65 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 209.4\n",
      "Av. agent reward = 20.94\n",
      "Agents crossed (2nd food pile) = 5.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 209.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 7.9\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 13.2\n",
      "Agent3 reward is 7.7\n",
      "Agent4 reward is 2.4\n",
      "Agent5 reward is 42.4\n",
      "Agent6 reward is 15.3\n",
      "Agent7 reward is 100.9\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 0.7\n",
      "Training time per epochs: 5.57 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 58.6\n",
      "Av. agent reward = 5.86\n",
      "Agents crossed (2nd food pile) = 5.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 58.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.3\n",
      "Agent1 reward is 22.3\n",
      "Agent2 reward is -50.9\n",
      "Agent3 reward is 40.3\n",
      "Agent4 reward is 7.4\n",
      "Agent5 reward is 5.6\n",
      "Agent6 reward is 57.9\n",
      "Agent7 reward is -51.1\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 1.7\n",
      "Training time per epochs: 5.63 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 155.4\n",
      "Av. agent reward = 15.54\n",
      "Agents crossed (2nd food pile) = 4.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 155.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 8.3\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 12.3\n",
      "Agent3 reward is 77.6\n",
      "Agent4 reward is 1.9\n",
      "Agent5 reward is 12.3\n",
      "Agent6 reward is 12.3\n",
      "Agent7 reward is 21.5\n",
      "Agent8 reward is 5.2\n",
      "Agent9 reward is 4.1\n",
      "Training time per epochs: 5.67 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 182.3\n",
      "Av. agent reward = 18.23\n",
      "Agents crossed (2nd food pile) = 5.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 182.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.6\n",
      "Agent1 reward is -2.4\n",
      "Agent2 reward is 16.1\n",
      "Agent3 reward is 0.5\n",
      "Agent4 reward is 24.3\n",
      "Agent5 reward is 23.4\n",
      "Agent6 reward is 22.0\n",
      "Agent7 reward is 41.3\n",
      "Agent8 reward is 11.1\n",
      "Agent9 reward is 24.3\n",
      "Training time per epochs: 5.59 sec\n",
      "###### Trained episodes = 1000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 208.5\n",
      "Av. agent reward = 20.85\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 208.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.0\n",
      "Agent1 reward is 30.3\n",
      "Agent2 reward is 18.6\n",
      "Agent3 reward is 26.4\n",
      "Agent4 reward is 21.1\n",
      "Agent5 reward is 27.7\n",
      "Agent6 reward is 19.8\n",
      "Agent7 reward is 16.3\n",
      "Agent8 reward is 13.9\n",
      "Agent9 reward is 13.3\n",
      "Training time per epochs: 5.53 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 230.4\n",
      "Av. agent reward = 23.04\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 230.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 33.8\n",
      "Agent1 reward is 21.9\n",
      "Agent2 reward is 15.7\n",
      "Agent3 reward is 26.6\n",
      "Agent4 reward is 20.8\n",
      "Agent5 reward is 32.1\n",
      "Agent6 reward is 19.5\n",
      "Agent7 reward is 26.2\n",
      "Agent8 reward is 23.0\n",
      "Agent9 reward is 10.9\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 210.1\n",
      "Av. agent reward = 21.01\n",
      "Agents crossed (2nd food pile) = 5.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 210.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 28.0\n",
      "Agent1 reward is 14.5\n",
      "Agent2 reward is 4.0\n",
      "Agent3 reward is 19.9\n",
      "Agent4 reward is 23.7\n",
      "Agent5 reward is 33.2\n",
      "Agent6 reward is 20.3\n",
      "Agent7 reward is 30.1\n",
      "Agent8 reward is 16.8\n",
      "Agent9 reward is 19.6\n",
      "Training time per epochs: 5.57 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 169.4\n",
      "Av. agent reward = 16.94\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 169.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 41.5\n",
      "Agent1 reward is 18.2\n",
      "Agent2 reward is 15.9\n",
      "Agent3 reward is 19.1\n",
      "Agent4 reward is 29.7\n",
      "Agent5 reward is -24.8\n",
      "Agent6 reward is 20.4\n",
      "Agent7 reward is 27.7\n",
      "Agent8 reward is 12.0\n",
      "Agent9 reward is 9.7\n",
      "Training time per epochs: 5.50 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 265.6\n",
      "Av. agent reward = 26.56\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 265.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 52.2\n",
      "Agent1 reward is 40.3\n",
      "Agent2 reward is 20.4\n",
      "Agent3 reward is 20.3\n",
      "Agent4 reward is 21.3\n",
      "Agent5 reward is 64.2\n",
      "Agent6 reward is 15.5\n",
      "Agent7 reward is 21.6\n",
      "Agent8 reward is 8.1\n",
      "Agent9 reward is 1.7\n",
      "Training time per epochs: 5.51 sec\n",
      "###### Trajectory = T5 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 175.4\n",
      "Av. agent reward = 17.54\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 3.6\n",
      "Agent1 reward is 35.8\n",
      "Agent2 reward is 12.7\n",
      "Agent3 reward is 6.5\n",
      "Agent4 reward is 8.1\n",
      "Agent5 reward is 4.4\n",
      "Agent6 reward is 42.1\n",
      "Agent7 reward is 33.0\n",
      "Agent8 reward is 12.7\n",
      "Agent9 reward is 16.5\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 208.0\n",
      "Av. agent reward = 20.80\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 208.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.2\n",
      "Agent1 reward is 61.8\n",
      "Agent2 reward is 21.8\n",
      "Agent3 reward is 21.8\n",
      "Agent4 reward is 15.5\n",
      "Agent5 reward is 15.4\n",
      "Agent6 reward is 23.5\n",
      "Agent7 reward is 11.5\n",
      "Agent8 reward is 16.2\n",
      "Agent9 reward is 19.4\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 245.1\n",
      "Av. agent reward = 24.51\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 245.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.5\n",
      "Agent1 reward is 78.0\n",
      "Agent2 reward is 15.3\n",
      "Agent3 reward is 17.1\n",
      "Agent4 reward is 18.5\n",
      "Agent5 reward is 12.8\n",
      "Agent6 reward is 24.5\n",
      "Agent7 reward is 40.1\n",
      "Agent8 reward is 17.0\n",
      "Agent9 reward is 21.3\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 217.2\n",
      "Av. agent reward = 21.72\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 217.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 76.3\n",
      "Agent2 reward is 22.1\n",
      "Agent3 reward is 20.2\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 20.4\n",
      "Agent6 reward is 14.0\n",
      "Agent7 reward is 25.5\n",
      "Agent8 reward is 11.0\n",
      "Agent9 reward is 9.1\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 238.9\n",
      "Av. agent reward = 23.89\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 238.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 69.1\n",
      "Agent2 reward is 23.3\n",
      "Agent3 reward is 13.7\n",
      "Agent4 reward is 26.1\n",
      "Agent5 reward is 20.1\n",
      "Agent6 reward is 16.1\n",
      "Agent7 reward is 47.0\n",
      "Agent8 reward is 13.4\n",
      "Agent9 reward is 10.1\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.0\n",
      "Av. agent reward = 19.60\n",
      "Agents crossed (2nd food pile) = 4.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 71.5\n",
      "Agent2 reward is 7.1\n",
      "Agent3 reward is 28.4\n",
      "Agent4 reward is 6.6\n",
      "Agent5 reward is 20.3\n",
      "Agent6 reward is 16.7\n",
      "Agent7 reward is 23.6\n",
      "Agent8 reward is 17.5\n",
      "Agent9 reward is 4.3\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 178.4\n",
      "Av. agent reward = 17.84\n",
      "Agents crossed (2nd food pile) = 6.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 178.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.3\n",
      "Agent1 reward is 30.8\n",
      "Agent2 reward is 0.5\n",
      "Agent3 reward is 12.7\n",
      "Agent4 reward is 37.8\n",
      "Agent5 reward is 26.8\n",
      "Agent6 reward is 18.9\n",
      "Agent7 reward is 11.7\n",
      "Agent8 reward is -17.8\n",
      "Agent9 reward is 35.7\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 189.3\n",
      "Av. agent reward = 18.93\n",
      "Agents crossed (2nd food pile) = 8.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 189.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.7\n",
      "Agent1 reward is 31.6\n",
      "Agent2 reward is 12.3\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 12.7\n",
      "Agent5 reward is 8.5\n",
      "Agent6 reward is 9.3\n",
      "Agent7 reward is 19.4\n",
      "Agent8 reward is 3.4\n",
      "Agent9 reward is 56.5\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 1500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 200.8\n",
      "Av. agent reward = 20.08\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 200.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.2\n",
      "Agent1 reward is 41.7\n",
      "Agent2 reward is 27.9\n",
      "Agent3 reward is 26.3\n",
      "Agent4 reward is 23.6\n",
      "Agent5 reward is 0.3\n",
      "Agent6 reward is 8.8\n",
      "Agent7 reward is 10.3\n",
      "Agent8 reward is 12.6\n",
      "Agent9 reward is 33.2\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 197.2\n",
      "Av. agent reward = 19.72\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 197.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.7\n",
      "Agent1 reward is 35.9\n",
      "Agent2 reward is 16.2\n",
      "Agent3 reward is 15.3\n",
      "Agent4 reward is 14.5\n",
      "Agent5 reward is 1.8\n",
      "Agent6 reward is 2.3\n",
      "Agent7 reward is 3.9\n",
      "Agent8 reward is 52.5\n",
      "Agent9 reward is 36.1\n",
      "Training time per epochs: 4.28 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 195.3\n",
      "Av. agent reward = 19.53\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 195.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.3\n",
      "Agent1 reward is 31.9\n",
      "Agent2 reward is 7.7\n",
      "Agent3 reward is 14.5\n",
      "Agent4 reward is 20.9\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 12.8\n",
      "Agent7 reward is 20.1\n",
      "Agent8 reward is 46.3\n",
      "Agent9 reward is 22.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 110.7\n",
      "Av. agent reward = 11.07\n",
      "Agents crossed (2nd food pile) = 5.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 110.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.8\n",
      "Agent1 reward is -0.9\n",
      "Agent2 reward is 7.8\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 21.4\n",
      "Agent5 reward is 5.5\n",
      "Agent6 reward is 22.8\n",
      "Agent7 reward is 7.0\n",
      "Agent8 reward is 13.7\n",
      "Agent9 reward is 12.7\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 165.1\n",
      "Av. agent reward = 16.51\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 165.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.2\n",
      "Agent1 reward is 13.2\n",
      "Agent2 reward is 45.8\n",
      "Agent3 reward is 11.3\n",
      "Agent4 reward is 31.0\n",
      "Agent5 reward is 34.8\n",
      "Agent6 reward is 10.5\n",
      "Agent7 reward is 26.5\n",
      "Agent8 reward is -4.0\n",
      "Agent9 reward is -3.7\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 155.5\n",
      "Av. agent reward = 15.55\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 155.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.5\n",
      "Agent1 reward is 15.1\n",
      "Agent2 reward is 24.4\n",
      "Agent3 reward is 10.1\n",
      "Agent4 reward is 17.2\n",
      "Agent5 reward is 30.0\n",
      "Agent6 reward is 22.4\n",
      "Agent7 reward is 19.4\n",
      "Agent8 reward is 2.3\n",
      "Agent9 reward is -1.9\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.4\n",
      "Av. agent reward = 22.34\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 28.4\n",
      "Agent1 reward is 12.8\n",
      "Agent2 reward is 22.5\n",
      "Agent3 reward is 24.4\n",
      "Agent4 reward is 18.7\n",
      "Agent5 reward is 20.1\n",
      "Agent6 reward is 22.6\n",
      "Agent7 reward is 67.7\n",
      "Agent8 reward is 0.6\n",
      "Agent9 reward is 5.7\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 214.4\n",
      "Av. agent reward = 21.44\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 214.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 35.4\n",
      "Agent1 reward is 19.8\n",
      "Agent2 reward is 17.7\n",
      "Agent3 reward is 19.0\n",
      "Agent4 reward is 6.8\n",
      "Agent5 reward is 16.4\n",
      "Agent6 reward is 19.7\n",
      "Agent7 reward is 72.3\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 7.4\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 169.6\n",
      "Av. agent reward = 16.96\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 169.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 40.3\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 5.7\n",
      "Agent3 reward is 29.1\n",
      "Agent4 reward is 13.1\n",
      "Agent5 reward is 5.4\n",
      "Agent6 reward is 23.6\n",
      "Agent7 reward is 25.6\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 7.8\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 114.4\n",
      "Av. agent reward = 11.44\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 114.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.1\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 18.4\n",
      "Agent3 reward is 29.6\n",
      "Agent4 reward is 0.2\n",
      "Agent5 reward is 15.4\n",
      "Agent6 reward is 17.9\n",
      "Agent7 reward is 4.8\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 10.0\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 156.2\n",
      "Av. agent reward = 15.62\n",
      "Agents crossed (2nd food pile) = 4.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 156.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.6\n",
      "Agent1 reward is -1.0\n",
      "Agent2 reward is 8.9\n",
      "Agent3 reward is -4.1\n",
      "Agent4 reward is 21.1\n",
      "Agent5 reward is 18.6\n",
      "Agent6 reward is 21.3\n",
      "Agent7 reward is 47.1\n",
      "Agent8 reward is 12.9\n",
      "Agent9 reward is 13.8\n",
      "Training time per epochs: 4.28 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.6\n",
      "Av. agent reward = 19.26\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.7\n",
      "Agent1 reward is 28.7\n",
      "Agent2 reward is 19.6\n",
      "Agent3 reward is 18.7\n",
      "Agent4 reward is 22.5\n",
      "Agent5 reward is 21.0\n",
      "Agent6 reward is 18.3\n",
      "Agent7 reward is 19.1\n",
      "Agent8 reward is 16.6\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 198.3\n",
      "Av. agent reward = 19.83\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 198.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.7\n",
      "Agent1 reward is 21.0\n",
      "Agent2 reward is 11.7\n",
      "Agent3 reward is 22.8\n",
      "Agent4 reward is 28.8\n",
      "Agent5 reward is 16.2\n",
      "Agent6 reward is 15.6\n",
      "Agent7 reward is 20.2\n",
      "Agent8 reward is 23.1\n",
      "Agent9 reward is 6.2\n",
      "Training time per epochs: 4.28 sec\n",
      "###### Trained episodes = 2000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.9\n",
      "Av. agent reward = 18.69\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.1\n",
      "Agent1 reward is 21.2\n",
      "Agent2 reward is 4.7\n",
      "Agent3 reward is 18.4\n",
      "Agent4 reward is 12.1\n",
      "Agent5 reward is 14.7\n",
      "Agent6 reward is 16.7\n",
      "Agent7 reward is 27.0\n",
      "Agent8 reward is 26.0\n",
      "Agent9 reward is 16.0\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 206.3\n",
      "Av. agent reward = 20.63\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 206.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 41.6\n",
      "Agent1 reward is 18.4\n",
      "Agent2 reward is 12.1\n",
      "Agent3 reward is 14.0\n",
      "Agent4 reward is 27.8\n",
      "Agent5 reward is 11.8\n",
      "Agent6 reward is 15.7\n",
      "Agent7 reward is 24.0\n",
      "Agent8 reward is 19.1\n",
      "Agent9 reward is 21.9\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 191.4\n",
      "Av. agent reward = 19.14\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 191.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 49.4\n",
      "Agent1 reward is 31.7\n",
      "Agent2 reward is 13.2\n",
      "Agent3 reward is 19.7\n",
      "Agent4 reward is 21.4\n",
      "Agent5 reward is 8.9\n",
      "Agent6 reward is 7.9\n",
      "Agent7 reward is 21.4\n",
      "Agent8 reward is 11.5\n",
      "Agent9 reward is 6.3\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trajectory = T6 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 182.2\n",
      "Av. agent reward = 18.22\n",
      "Agents crossed (2nd food pile) = 5.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 182.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 2.8\n",
      "Agent1 reward is 42.6\n",
      "Agent2 reward is 5.3\n",
      "Agent3 reward is 7.7\n",
      "Agent4 reward is 9.4\n",
      "Agent5 reward is 6.1\n",
      "Agent6 reward is 43.9\n",
      "Agent7 reward is 29.7\n",
      "Agent8 reward is 16.4\n",
      "Agent9 reward is 18.2\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 190.6\n",
      "Av. agent reward = 19.06\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 190.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -3.1\n",
      "Agent1 reward is 68.1\n",
      "Agent2 reward is 20.0\n",
      "Agent3 reward is 23.5\n",
      "Agent4 reward is 15.1\n",
      "Agent5 reward is 13.4\n",
      "Agent6 reward is 3.3\n",
      "Agent7 reward is 13.0\n",
      "Agent8 reward is 18.1\n",
      "Agent9 reward is 19.2\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 206.8\n",
      "Av. agent reward = 20.68\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 206.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.6\n",
      "Agent1 reward is 72.2\n",
      "Agent2 reward is 12.0\n",
      "Agent3 reward is 16.1\n",
      "Agent4 reward is 15.9\n",
      "Agent5 reward is 11.0\n",
      "Agent6 reward is 21.1\n",
      "Agent7 reward is 21.5\n",
      "Agent8 reward is 16.6\n",
      "Agent9 reward is 21.0\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 216.4\n",
      "Av. agent reward = 21.64\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 216.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.8\n",
      "Agent1 reward is 71.4\n",
      "Agent2 reward is 21.0\n",
      "Agent3 reward is 20.9\n",
      "Agent4 reward is 19.7\n",
      "Agent5 reward is 21.1\n",
      "Agent6 reward is 16.1\n",
      "Agent7 reward is 23.4\n",
      "Agent8 reward is 5.9\n",
      "Agent9 reward is 19.7\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 179.5\n",
      "Av. agent reward = 17.95\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 179.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -4.4\n",
      "Agent1 reward is 64.5\n",
      "Agent2 reward is 11.5\n",
      "Agent3 reward is 11.7\n",
      "Agent4 reward is 20.2\n",
      "Agent5 reward is 18.6\n",
      "Agent6 reward is 15.8\n",
      "Agent7 reward is 28.1\n",
      "Agent8 reward is 4.2\n",
      "Agent9 reward is 9.4\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 216.2\n",
      "Av. agent reward = 21.62\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 216.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -1.1\n",
      "Agent1 reward is 64.6\n",
      "Agent2 reward is 19.8\n",
      "Agent3 reward is 25.0\n",
      "Agent4 reward is 15.7\n",
      "Agent5 reward is 22.3\n",
      "Agent6 reward is 19.2\n",
      "Agent7 reward is 26.4\n",
      "Agent8 reward is 1.6\n",
      "Agent9 reward is 22.6\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 174.8\n",
      "Av. agent reward = 17.48\n",
      "Agents crossed (2nd food pile) = 6.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 174.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 19.8\n",
      "Agent1 reward is 30.7\n",
      "Agent2 reward is 6.9\n",
      "Agent3 reward is 15.3\n",
      "Agent4 reward is 26.5\n",
      "Agent5 reward is 26.6\n",
      "Agent6 reward is 21.4\n",
      "Agent7 reward is 24.8\n",
      "Agent8 reward is -24.6\n",
      "Agent9 reward is 27.5\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 173.2\n",
      "Av. agent reward = 17.32\n",
      "Agents crossed (2nd food pile) = 8.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 173.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.1\n",
      "Agent1 reward is 36.2\n",
      "Agent2 reward is 13.6\n",
      "Agent3 reward is 18.2\n",
      "Agent4 reward is 12.4\n",
      "Agent5 reward is 7.5\n",
      "Agent6 reward is 10.7\n",
      "Agent7 reward is 18.0\n",
      "Agent8 reward is 1.4\n",
      "Agent9 reward is 34.2\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 187.6\n",
      "Av. agent reward = 18.76\n",
      "Agents crossed (2nd food pile) = 8.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 187.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.1\n",
      "Agent1 reward is 30.3\n",
      "Agent2 reward is 19.3\n",
      "Agent3 reward is 31.7\n",
      "Agent4 reward is 20.3\n",
      "Agent5 reward is 4.5\n",
      "Agent6 reward is 21.0\n",
      "Agent7 reward is 11.0\n",
      "Agent8 reward is 7.6\n",
      "Agent9 reward is 14.8\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 170.0\n",
      "Av. agent reward = 17.00\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 170.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.6\n",
      "Agent1 reward is 40.2\n",
      "Agent2 reward is 7.8\n",
      "Agent3 reward is 9.7\n",
      "Agent4 reward is 11.5\n",
      "Agent5 reward is 3.6\n",
      "Agent6 reward is 12.1\n",
      "Agent7 reward is -0.2\n",
      "Agent8 reward is 48.1\n",
      "Agent9 reward is 23.8\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 2500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 168.0\n",
      "Av. agent reward = 16.80\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 168.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.9\n",
      "Agent1 reward is 28.5\n",
      "Agent2 reward is 6.4\n",
      "Agent3 reward is 13.1\n",
      "Agent4 reward is 19.9\n",
      "Agent5 reward is 1.3\n",
      "Agent6 reward is 8.0\n",
      "Agent7 reward is 6.9\n",
      "Agent8 reward is 51.6\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 94.4\n",
      "Av. agent reward = 9.44\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 94.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.6\n",
      "Agent1 reward is -1.0\n",
      "Agent2 reward is 3.9\n",
      "Agent3 reward is 26.3\n",
      "Agent4 reward is 11.7\n",
      "Agent5 reward is 14.7\n",
      "Agent6 reward is 18.4\n",
      "Agent7 reward is 5.1\n",
      "Agent8 reward is 3.3\n",
      "Agent9 reward is 12.5\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 159.5\n",
      "Av. agent reward = 15.95\n",
      "Agents crossed (2nd food pile) = 4.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 159.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -2.4\n",
      "Agent1 reward is 14.0\n",
      "Agent2 reward is 43.2\n",
      "Agent3 reward is 10.9\n",
      "Agent4 reward is 27.0\n",
      "Agent5 reward is 28.2\n",
      "Agent6 reward is 9.3\n",
      "Agent7 reward is 30.4\n",
      "Agent8 reward is 0.4\n",
      "Agent9 reward is -1.4\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 148.0\n",
      "Av. agent reward = 14.80\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 148.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.3\n",
      "Agent1 reward is 10.6\n",
      "Agent2 reward is 7.5\n",
      "Agent3 reward is 12.3\n",
      "Agent4 reward is 17.5\n",
      "Agent5 reward is 29.9\n",
      "Agent6 reward is 16.3\n",
      "Agent7 reward is 29.4\n",
      "Agent8 reward is -0.6\n",
      "Agent9 reward is 1.8\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.2\n",
      "Av. agent reward = 19.22\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.5\n",
      "Agent1 reward is 12.7\n",
      "Agent2 reward is 9.4\n",
      "Agent3 reward is 17.7\n",
      "Agent4 reward is 20.1\n",
      "Agent5 reward is 17.0\n",
      "Agent6 reward is 19.2\n",
      "Agent7 reward is 57.6\n",
      "Agent8 reward is 0.8\n",
      "Agent9 reward is 12.2\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 177.6\n",
      "Av. agent reward = 17.76\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 177.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 29.8\n",
      "Agent1 reward is 10.1\n",
      "Agent2 reward is 20.3\n",
      "Agent3 reward is 19.9\n",
      "Agent4 reward is -0.8\n",
      "Agent5 reward is 17.4\n",
      "Agent6 reward is 17.8\n",
      "Agent7 reward is 47.6\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 15.7\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 157.2\n",
      "Av. agent reward = 15.72\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 157.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 30.3\n",
      "Agent1 reward is 18.2\n",
      "Agent2 reward is 17.7\n",
      "Agent3 reward is 22.7\n",
      "Agent4 reward is 2.7\n",
      "Agent5 reward is 5.6\n",
      "Agent6 reward is 18.9\n",
      "Agent7 reward is 21.9\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 19.2\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 131.2\n",
      "Av. agent reward = 13.12\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 131.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.7\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 15.5\n",
      "Agent3 reward is 27.3\n",
      "Agent4 reward is 2.1\n",
      "Agent5 reward is 13.3\n",
      "Agent6 reward is 21.8\n",
      "Agent7 reward is 18.8\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 17.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 163.0\n",
      "Av. agent reward = 16.30\n",
      "Agents crossed (2nd food pile) = 5.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 163.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.2\n",
      "Agent1 reward is -1.5\n",
      "Agent2 reward is 15.4\n",
      "Agent3 reward is -1.7\n",
      "Agent4 reward is 21.3\n",
      "Agent5 reward is 17.4\n",
      "Agent6 reward is 22.6\n",
      "Agent7 reward is 42.1\n",
      "Agent8 reward is 14.5\n",
      "Agent9 reward is 15.7\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 185.9\n",
      "Av. agent reward = 18.59\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 185.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.6\n",
      "Agent1 reward is 25.2\n",
      "Agent2 reward is 13.0\n",
      "Agent3 reward is 19.5\n",
      "Agent4 reward is 22.5\n",
      "Agent5 reward is 17.4\n",
      "Agent6 reward is 25.4\n",
      "Agent7 reward is 16.4\n",
      "Agent8 reward is 16.1\n",
      "Agent9 reward is 13.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 181.0\n",
      "Av. agent reward = 18.10\n",
      "Agents crossed (2nd food pile) = 7.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 181.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 31.2\n",
      "Agent1 reward is 21.9\n",
      "Agent2 reward is 8.6\n",
      "Agent3 reward is 15.4\n",
      "Agent4 reward is 24.1\n",
      "Agent5 reward is 4.0\n",
      "Agent6 reward is 25.2\n",
      "Agent7 reward is 18.9\n",
      "Agent8 reward is 23.0\n",
      "Agent9 reward is 8.7\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 172.4\n",
      "Av. agent reward = 17.24\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 28.0\n",
      "Agent1 reward is 18.9\n",
      "Agent2 reward is 4.2\n",
      "Agent3 reward is 15.5\n",
      "Agent4 reward is 15.9\n",
      "Agent5 reward is 14.5\n",
      "Agent6 reward is 19.7\n",
      "Agent7 reward is 23.2\n",
      "Agent8 reward is 17.8\n",
      "Agent9 reward is 14.7\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 209.2\n",
      "Av. agent reward = 20.92\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 209.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 50.3\n",
      "Agent1 reward is 20.5\n",
      "Agent2 reward is 13.0\n",
      "Agent3 reward is 14.6\n",
      "Agent4 reward is 26.7\n",
      "Agent5 reward is 1.6\n",
      "Agent6 reward is 27.6\n",
      "Agent7 reward is 20.9\n",
      "Agent8 reward is 18.2\n",
      "Agent9 reward is 15.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 206.2\n",
      "Av. agent reward = 20.62\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 206.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 55.4\n",
      "Agent1 reward is 36.2\n",
      "Agent2 reward is 13.3\n",
      "Agent3 reward is 9.2\n",
      "Agent4 reward is 17.5\n",
      "Agent5 reward is 11.9\n",
      "Agent6 reward is 31.6\n",
      "Agent7 reward is 15.2\n",
      "Agent8 reward is 18.2\n",
      "Agent9 reward is -2.3\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trajectory = T7 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 193.7\n",
      "Av. agent reward = 19.37\n",
      "Agents crossed (2nd food pile) = 5.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 193.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 4.9\n",
      "Agent1 reward is 45.4\n",
      "Agent2 reward is 9.6\n",
      "Agent3 reward is 8.3\n",
      "Agent4 reward is 12.2\n",
      "Agent5 reward is 3.9\n",
      "Agent6 reward is 47.0\n",
      "Agent7 reward is 31.1\n",
      "Agent8 reward is 12.5\n",
      "Agent9 reward is 19.0\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.6\n",
      "Av. agent reward = 19.66\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.2\n",
      "Agent1 reward is 66.1\n",
      "Agent2 reward is 17.9\n",
      "Agent3 reward is 20.9\n",
      "Agent4 reward is 19.5\n",
      "Agent5 reward is 12.6\n",
      "Agent6 reward is 16.9\n",
      "Agent7 reward is 11.6\n",
      "Agent8 reward is 13.6\n",
      "Agent9 reward is 17.3\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 223.4\n",
      "Av. agent reward = 22.34\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.0\n",
      "Agent1 reward is 73.5\n",
      "Agent2 reward is 16.1\n",
      "Agent3 reward is 17.6\n",
      "Agent4 reward is 18.6\n",
      "Agent5 reward is 13.2\n",
      "Agent6 reward is 20.6\n",
      "Agent7 reward is 22.9\n",
      "Agent8 reward is 19.4\n",
      "Agent9 reward is 21.6\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 220.3\n",
      "Av. agent reward = 22.03\n",
      "Agents crossed (2nd food pile) = 7.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 220.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 71.9\n",
      "Agent2 reward is 22.4\n",
      "Agent3 reward is 21.7\n",
      "Agent4 reward is 19.5\n",
      "Agent5 reward is 17.6\n",
      "Agent6 reward is 15.5\n",
      "Agent7 reward is 23.8\n",
      "Agent8 reward is 9.0\n",
      "Agent9 reward is 19.1\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 188.7\n",
      "Av. agent reward = 18.87\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 188.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 65.8\n",
      "Agent2 reward is 23.2\n",
      "Agent3 reward is 14.1\n",
      "Agent4 reward is 23.7\n",
      "Agent5 reward is 21.1\n",
      "Agent6 reward is 11.7\n",
      "Agent7 reward is 21.7\n",
      "Agent8 reward is 4.0\n",
      "Agent9 reward is 3.3\n",
      "Training time per epochs: 4.32 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 222.2\n",
      "Av. agent reward = 22.22\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 222.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 63.8\n",
      "Agent2 reward is 22.7\n",
      "Agent3 reward is 25.2\n",
      "Agent4 reward is 14.2\n",
      "Agent5 reward is 20.8\n",
      "Agent6 reward is 22.0\n",
      "Agent7 reward is 22.8\n",
      "Agent8 reward is 7.2\n",
      "Agent9 reward is 23.4\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 185.9\n",
      "Av. agent reward = 18.59\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 185.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 14.5\n",
      "Agent1 reward is 31.3\n",
      "Agent2 reward is 4.4\n",
      "Agent3 reward is 17.9\n",
      "Agent4 reward is 28.5\n",
      "Agent5 reward is 23.3\n",
      "Agent6 reward is 25.1\n",
      "Agent7 reward is 17.9\n",
      "Agent8 reward is -6.5\n",
      "Agent9 reward is 29.5\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 166.9\n",
      "Av. agent reward = 16.69\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 166.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.2\n",
      "Agent1 reward is 36.9\n",
      "Agent2 reward is 12.0\n",
      "Agent3 reward is 22.8\n",
      "Agent4 reward is 10.1\n",
      "Agent5 reward is 8.3\n",
      "Agent6 reward is 9.1\n",
      "Agent7 reward is 15.8\n",
      "Agent8 reward is 1.6\n",
      "Agent9 reward is 33.1\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.5\n",
      "Av. agent reward = 18.45\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 21.6\n",
      "Agent1 reward is 38.8\n",
      "Agent2 reward is 17.6\n",
      "Agent3 reward is 26.3\n",
      "Agent4 reward is 20.7\n",
      "Agent5 reward is 2.0\n",
      "Agent6 reward is 21.2\n",
      "Agent7 reward is 14.4\n",
      "Agent8 reward is 6.5\n",
      "Agent9 reward is 15.3\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.5\n",
      "Av. agent reward = 19.25\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.3\n",
      "Agent1 reward is 43.2\n",
      "Agent2 reward is 9.2\n",
      "Agent3 reward is 13.5\n",
      "Agent4 reward is 15.4\n",
      "Agent5 reward is 0.6\n",
      "Agent6 reward is 11.3\n",
      "Agent7 reward is 5.2\n",
      "Agent8 reward is 53.3\n",
      "Agent9 reward is 23.5\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 172.8\n",
      "Av. agent reward = 17.28\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 20.3\n",
      "Agent1 reward is 30.6\n",
      "Agent2 reward is 6.9\n",
      "Agent3 reward is 13.4\n",
      "Agent4 reward is 21.7\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 14.3\n",
      "Agent7 reward is 7.4\n",
      "Agent8 reward is 46.5\n",
      "Agent9 reward is 11.4\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 101.7\n",
      "Av. agent reward = 10.17\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 101.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.0\n",
      "Agent1 reward is -0.3\n",
      "Agent2 reward is 10.4\n",
      "Agent3 reward is 24.4\n",
      "Agent4 reward is 10.2\n",
      "Agent5 reward is 12.1\n",
      "Agent6 reward is 26.0\n",
      "Agent7 reward is 2.0\n",
      "Agent8 reward is -2.0\n",
      "Agent9 reward is 18.0\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 169.7\n",
      "Av. agent reward = 16.97\n",
      "Agents crossed (2nd food pile) = 4.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 169.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.0\n",
      "Agent1 reward is 14.3\n",
      "Agent2 reward is 46.2\n",
      "Agent3 reward is 8.6\n",
      "Agent4 reward is 31.4\n",
      "Agent5 reward is 34.6\n",
      "Agent6 reward is 5.6\n",
      "Agent7 reward is 31.0\n",
      "Agent8 reward is -1.4\n",
      "Agent9 reward is -1.5\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 162.3\n",
      "Av. agent reward = 16.23\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.2\n",
      "Agent1 reward is 16.8\n",
      "Agent2 reward is 19.0\n",
      "Agent3 reward is 13.3\n",
      "Agent4 reward is 19.7\n",
      "Agent5 reward is 28.6\n",
      "Agent6 reward is 17.5\n",
      "Agent7 reward is 34.7\n",
      "Agent8 reward is 2.2\n",
      "Agent9 reward is -2.7\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 201.9\n",
      "Av. agent reward = 20.19\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 201.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 27.9\n",
      "Agent1 reward is 19.0\n",
      "Agent2 reward is 11.7\n",
      "Agent3 reward is 21.5\n",
      "Agent4 reward is 15.2\n",
      "Agent5 reward is 17.5\n",
      "Agent6 reward is 22.2\n",
      "Agent7 reward is 56.4\n",
      "Agent8 reward is 0.7\n",
      "Agent9 reward is 9.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.7\n",
      "Av. agent reward = 18.67\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 24.4\n",
      "Agent1 reward is 9.6\n",
      "Agent2 reward is 19.4\n",
      "Agent3 reward is 15.0\n",
      "Agent4 reward is -1.6\n",
      "Agent5 reward is 20.4\n",
      "Agent6 reward is 19.8\n",
      "Agent7 reward is 64.6\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 15.0\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 126.2\n",
      "Av. agent reward = 12.62\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 126.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.8\n",
      "Agent1 reward is 14.6\n",
      "Agent2 reward is -4.6\n",
      "Agent3 reward is 22.9\n",
      "Agent4 reward is 0.9\n",
      "Agent5 reward is 7.3\n",
      "Agent6 reward is 18.0\n",
      "Agent7 reward is 13.7\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 20.6\n",
      "Training time per epochs: 4.34 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 145.3\n",
      "Av. agent reward = 14.53\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 145.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 12.5\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 20.2\n",
      "Agent3 reward is 22.7\n",
      "Agent4 reward is -0.2\n",
      "Agent5 reward is 20.9\n",
      "Agent6 reward is 23.7\n",
      "Agent7 reward is 25.8\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 19.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 151.6\n",
      "Av. agent reward = 15.16\n",
      "Agents crossed (2nd food pile) = 5.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 151.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.1\n",
      "Agent1 reward is 0.1\n",
      "Agent2 reward is 12.4\n",
      "Agent3 reward is 0.4\n",
      "Agent4 reward is 23.1\n",
      "Agent5 reward is 14.6\n",
      "Agent6 reward is 19.8\n",
      "Agent7 reward is 34.6\n",
      "Agent8 reward is 11.8\n",
      "Agent9 reward is 17.6\n",
      "Training time per epochs: 4.29 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 173.3\n",
      "Av. agent reward = 17.33\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 173.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 17.4\n",
      "Agent1 reward is 26.8\n",
      "Agent2 reward is 15.0\n",
      "Agent3 reward is 17.4\n",
      "Agent4 reward is 23.8\n",
      "Agent5 reward is 15.4\n",
      "Agent6 reward is 15.1\n",
      "Agent7 reward is 18.4\n",
      "Agent8 reward is 12.8\n",
      "Agent9 reward is 11.1\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 188.4\n",
      "Av. agent reward = 18.84\n",
      "Agents crossed (2nd food pile) = 7.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 188.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 31.2\n",
      "Agent1 reward is 19.2\n",
      "Agent2 reward is 15.8\n",
      "Agent3 reward is 18.2\n",
      "Agent4 reward is 26.9\n",
      "Agent5 reward is 6.4\n",
      "Agent6 reward is 17.1\n",
      "Agent7 reward is 21.8\n",
      "Agent8 reward is 19.9\n",
      "Agent9 reward is 11.8\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 168.1\n",
      "Av. agent reward = 16.81\n",
      "Agents crossed (2nd food pile) = 6.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 168.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 32.1\n",
      "Agent1 reward is 21.1\n",
      "Agent2 reward is 1.8\n",
      "Agent3 reward is 14.4\n",
      "Agent4 reward is 16.2\n",
      "Agent5 reward is 11.6\n",
      "Agent6 reward is 11.4\n",
      "Agent7 reward is 23.2\n",
      "Agent8 reward is 22.7\n",
      "Agent9 reward is 13.5\n",
      "Training time per epochs: 4.30 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 167.7\n",
      "Av. agent reward = 16.77\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 167.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 47.0\n",
      "Agent1 reward is 21.0\n",
      "Agent2 reward is 12.1\n",
      "Agent3 reward is 13.8\n",
      "Agent4 reward is 23.4\n",
      "Agent5 reward is -16.3\n",
      "Agent6 reward is 4.7\n",
      "Agent7 reward is 21.1\n",
      "Agent8 reward is 20.1\n",
      "Agent9 reward is 20.6\n",
      "Training time per epochs: 4.31 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 216.0\n",
      "Av. agent reward = 21.60\n",
      "Agents crossed (2nd food pile) = 8.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 216.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 54.9\n",
      "Agent1 reward is 42.2\n",
      "Agent2 reward is 18.9\n",
      "Agent3 reward is 16.5\n",
      "Agent4 reward is 16.9\n",
      "Agent5 reward is 11.7\n",
      "Agent6 reward is 16.0\n",
      "Agent7 reward is 17.6\n",
      "Agent8 reward is 15.9\n",
      "Agent9 reward is 5.2\n",
      "Training time per epochs: 4.33 sec\n",
      "###### Trajectory = T8 #######\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.8\n",
      "Av. agent reward = 14.08\n",
      "Agents crossed (2nd food pile) = 4.4\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -3.5\n",
      "Agent1 reward is 37.2\n",
      "Agent2 reward is 8.4\n",
      "Agent3 reward is 5.8\n",
      "Agent4 reward is 9.5\n",
      "Agent5 reward is 3.5\n",
      "Agent6 reward is 10.9\n",
      "Agent7 reward is 39.7\n",
      "Agent8 reward is 13.1\n",
      "Agent9 reward is 16.3\n",
      "Training time per epochs: 3.69 sec\n",
      "###### Trained episodes = 1000 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 190.0\n",
      "Av. agent reward = 19.00\n",
      "Agents crossed (2nd food pile) = 7.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 190.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 2.5\n",
      "Agent1 reward is 50.3\n",
      "Agent2 reward is 21.2\n",
      "Agent3 reward is 21.3\n",
      "Agent4 reward is 10.0\n",
      "Agent5 reward is 21.9\n",
      "Agent6 reward is 9.3\n",
      "Agent7 reward is 15.3\n",
      "Agent8 reward is 17.6\n",
      "Agent9 reward is 20.6\n",
      "Training time per epochs: 3.68 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 195.6\n",
      "Av. agent reward = 19.56\n",
      "Agents crossed (2nd food pile) = 7.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 195.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is -0.1\n",
      "Agent1 reward is 57.2\n",
      "Agent2 reward is 14.4\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 12.8\n",
      "Agent5 reward is 13.2\n",
      "Agent6 reward is 14.9\n",
      "Agent7 reward is 24.0\n",
      "Agent8 reward is 21.0\n",
      "Agent9 reward is 19.2\n",
      "Training time per epochs: 3.70 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.9\n",
      "Av. agent reward = 18.49\n",
      "Agents crossed (2nd food pile) = 6.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 59.4\n",
      "Agent2 reward is 8.6\n",
      "Agent3 reward is 22.2\n",
      "Agent4 reward is 20.9\n",
      "Agent5 reward is 20.0\n",
      "Agent6 reward is 2.5\n",
      "Agent7 reward is 22.4\n",
      "Agent8 reward is 12.6\n",
      "Agent9 reward is 16.4\n",
      "Training time per epochs: 3.73 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 176.3\n",
      "Av. agent reward = 17.63\n",
      "Agents crossed (2nd food pile) = 5.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 176.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 48.2\n",
      "Agent2 reward is 7.4\n",
      "Agent3 reward is 15.5\n",
      "Agent4 reward is 18.4\n",
      "Agent5 reward is 27.9\n",
      "Agent6 reward is 2.7\n",
      "Agent7 reward is 29.3\n",
      "Agent8 reward is 16.7\n",
      "Agent9 reward is 10.2\n",
      "Training time per epochs: 3.75 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 183.3\n",
      "Av. agent reward = 18.33\n",
      "Agents crossed (2nd food pile) = 4.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 183.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.0\n",
      "Agent1 reward is 53.6\n",
      "Agent2 reward is 0.6\n",
      "Agent3 reward is 23.0\n",
      "Agent4 reward is 27.7\n",
      "Agent5 reward is 25.7\n",
      "Agent6 reward is 2.3\n",
      "Agent7 reward is 28.8\n",
      "Agent8 reward is -0.0\n",
      "Agent9 reward is 21.5\n",
      "Training time per epochs: 3.69 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 185.1\n",
      "Av. agent reward = 18.51\n",
      "Agents crossed (2nd food pile) = 6.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 185.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 16.0\n",
      "Agent1 reward is 28.4\n",
      "Agent2 reward is 7.7\n",
      "Agent3 reward is 12.3\n",
      "Agent4 reward is 34.9\n",
      "Agent5 reward is 19.7\n",
      "Agent6 reward is 17.2\n",
      "Agent7 reward is 22.7\n",
      "Agent8 reward is -8.9\n",
      "Agent9 reward is 34.9\n",
      "Training time per epochs: 3.72 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 168.0\n",
      "Av. agent reward = 16.80\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 168.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 15.3\n",
      "Agent1 reward is 22.7\n",
      "Agent2 reward is 11.2\n",
      "Agent3 reward is 22.0\n",
      "Agent4 reward is 22.0\n",
      "Agent5 reward is 4.9\n",
      "Agent6 reward is 17.5\n",
      "Agent7 reward is 24.8\n",
      "Agent8 reward is 0.8\n",
      "Agent9 reward is 26.7\n",
      "Training time per epochs: 3.70 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 196.6\n",
      "Av. agent reward = 19.66\n",
      "Agents crossed (2nd food pile) = 7.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 23.0\n",
      "Agent1 reward is 28.1\n",
      "Agent2 reward is 20.5\n",
      "Agent3 reward is 25.3\n",
      "Agent4 reward is 26.9\n",
      "Agent5 reward is 0.2\n",
      "Agent6 reward is 25.4\n",
      "Agent7 reward is 19.1\n",
      "Agent8 reward is 8.3\n",
      "Agent9 reward is 19.8\n",
      "Training time per epochs: 3.69 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 185.2\n",
      "Av. agent reward = 18.52\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 185.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.5\n",
      "Agent1 reward is 21.3\n",
      "Agent2 reward is 16.0\n",
      "Agent3 reward is 15.7\n",
      "Agent4 reward is 20.2\n",
      "Agent5 reward is 0.7\n",
      "Agent6 reward is 18.0\n",
      "Agent7 reward is 19.1\n",
      "Agent8 reward is 42.9\n",
      "Agent9 reward is 17.8\n",
      "Training time per epochs: 3.72 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 181.0\n",
      "Av. agent reward = 18.10\n",
      "Agents crossed (2nd food pile) = 7.3\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 181.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.4\n",
      "Agent1 reward is 28.3\n",
      "Agent2 reward is 15.5\n",
      "Agent3 reward is 11.8\n",
      "Agent4 reward is 25.8\n",
      "Agent5 reward is 0.0\n",
      "Agent6 reward is 13.3\n",
      "Agent7 reward is 13.2\n",
      "Agent8 reward is 39.3\n",
      "Agent9 reward is 15.5\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 144.8\n",
      "Av. agent reward = 14.48\n",
      "Agents crossed (2nd food pile) = 6.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 144.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 0.9\n",
      "Agent1 reward is -0.5\n",
      "Agent2 reward is 17.2\n",
      "Agent3 reward is 27.9\n",
      "Agent4 reward is 24.2\n",
      "Agent5 reward is 0.6\n",
      "Agent6 reward is 20.4\n",
      "Agent7 reward is 17.1\n",
      "Agent8 reward is 15.0\n",
      "Agent9 reward is 22.1\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 135.5\n",
      "Av. agent reward = 13.55\n",
      "Agents crossed (2nd food pile) = 3.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 135.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 1.0\n",
      "Agent1 reward is 12.6\n",
      "Agent2 reward is 30.6\n",
      "Agent3 reward is 6.5\n",
      "Agent4 reward is 29.7\n",
      "Agent5 reward is 22.3\n",
      "Agent6 reward is 12.6\n",
      "Agent7 reward is 22.5\n",
      "Agent8 reward is -4.0\n",
      "Agent9 reward is 1.7\n",
      "Training time per epochs: 3.74 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 162.1\n",
      "Av. agent reward = 16.21\n",
      "Agents crossed (2nd food pile) = 5.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.4\n",
      "Agent1 reward is 19.0\n",
      "Agent2 reward is -3.6\n",
      "Agent3 reward is 15.9\n",
      "Agent4 reward is 14.1\n",
      "Agent5 reward is 40.0\n",
      "Agent6 reward is 19.6\n",
      "Agent7 reward is 25.7\n",
      "Agent8 reward is 2.5\n",
      "Agent9 reward is 6.6\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Trained episodes = 1500 #######\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 169.1\n",
      "Av. agent reward = 16.91\n",
      "Agents crossed (2nd food pile) = 6.8\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 169.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 15.7\n",
      "Agent1 reward is -0.9\n",
      "Agent2 reward is 15.1\n",
      "Agent3 reward is 20.9\n",
      "Agent4 reward is 19.0\n",
      "Agent5 reward is 21.2\n",
      "Agent6 reward is 25.2\n",
      "Agent7 reward is 38.0\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 15.0\n",
      "Training time per epochs: 3.70 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 192.0\n",
      "Av. agent reward = 19.20\n",
      "Agents crossed (2nd food pile) = 6.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 192.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 34.7\n",
      "Agent1 reward is 14.1\n",
      "Agent2 reward is 12.6\n",
      "Agent3 reward is 23.4\n",
      "Agent4 reward is 1.7\n",
      "Agent5 reward is 21.6\n",
      "Agent6 reward is 14.8\n",
      "Agent7 reward is 51.7\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 17.4\n",
      "Training time per epochs: 3.74 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 167.8\n",
      "Av. agent reward = 16.78\n",
      "Agents crossed (2nd food pile) = 6.2\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 167.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 36.7\n",
      "Agent1 reward is 10.0\n",
      "Agent2 reward is 0.4\n",
      "Agent3 reward is 21.8\n",
      "Agent4 reward is 0.9\n",
      "Agent5 reward is 7.8\n",
      "Agent6 reward is 24.1\n",
      "Agent7 reward is 47.3\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 18.8\n",
      "Training time per epochs: 3.69 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 140.9\n",
      "Av. agent reward = 14.09\n",
      "Agents crossed (2nd food pile) = 6.0\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 18.1\n",
      "Agent1 reward is 0.0\n",
      "Agent2 reward is 21.8\n",
      "Agent3 reward is 27.7\n",
      "Agent4 reward is -0.3\n",
      "Agent5 reward is 21.8\n",
      "Agent6 reward is 23.7\n",
      "Agent7 reward is 6.4\n",
      "Agent8 reward is 0.0\n",
      "Agent9 reward is 21.7\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Dir = models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/ #######\n",
      "###### Trained episodes = 500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 145.1\n",
      "Av. agent reward = 14.51\n",
      "Agents crossed (2nd food pile) = 4.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 145.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.0\n",
      "Agent1 reward is 0.7\n",
      "Agent2 reward is 11.8\n",
      "Agent3 reward is -1.2\n",
      "Agent4 reward is 15.4\n",
      "Agent5 reward is 14.9\n",
      "Agent6 reward is 26.1\n",
      "Agent7 reward is 36.9\n",
      "Agent8 reward is 11.4\n",
      "Agent9 reward is 16.1\n",
      "Training time per epochs: 3.68 sec\n",
      "###### Trained episodes = 1000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 177.3\n",
      "Av. agent reward = 17.73\n",
      "Agents crossed (2nd food pile) = 7.1\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 177.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 13.5\n",
      "Agent1 reward is 29.5\n",
      "Agent2 reward is 20.6\n",
      "Agent3 reward is 20.1\n",
      "Agent4 reward is 17.4\n",
      "Agent5 reward is 14.0\n",
      "Agent6 reward is 16.8\n",
      "Agent7 reward is 17.5\n",
      "Agent8 reward is 14.4\n",
      "Agent9 reward is 13.5\n",
      "Training time per epochs: 3.73 sec\n",
      "###### Trained episodes = 1500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 184.3\n",
      "Av. agent reward = 18.43\n",
      "Agents crossed (2nd food pile) = 7.9\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 25.7\n",
      "Agent1 reward is 16.9\n",
      "Agent2 reward is 21.3\n",
      "Agent3 reward is 18.9\n",
      "Agent4 reward is 24.6\n",
      "Agent5 reward is 3.5\n",
      "Agent6 reward is 19.8\n",
      "Agent7 reward is 19.3\n",
      "Agent8 reward is 21.9\n",
      "Agent9 reward is 12.4\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 186.4\n",
      "Av. agent reward = 18.64\n",
      "Agents crossed (2nd food pile) = 6.7\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 186.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 22.9\n",
      "Agent1 reward is 20.6\n",
      "Agent2 reward is 5.2\n",
      "Agent3 reward is 19.7\n",
      "Agent4 reward is 15.8\n",
      "Agent5 reward is 14.5\n",
      "Agent6 reward is 21.2\n",
      "Agent7 reward is 23.7\n",
      "Agent8 reward is 21.5\n",
      "Agent9 reward is 21.3\n",
      "Training time per epochs: 3.70 sec\n",
      "###### Trained episodes = 2500 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 203.0\n",
      "Av. agent reward = 20.30\n",
      "Agents crossed (2nd food pile) = 7.5\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 203.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 38.9\n",
      "Agent1 reward is 21.9\n",
      "Agent2 reward is 18.1\n",
      "Agent3 reward is 20.4\n",
      "Agent4 reward is 24.0\n",
      "Agent5 reward is 2.1\n",
      "Agent6 reward is 21.8\n",
      "Agent7 reward is 22.6\n",
      "Agent8 reward is 12.3\n",
      "Agent9 reward is 21.1\n",
      "Training time per epochs: 3.71 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 220.0\n",
      "Av. agent reward = 22.00\n",
      "Agents crossed (2nd food pile) = 7.6\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 220.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 reward is 41.7\n",
      "Agent1 reward is 28.2\n",
      "Agent2 reward is 22.9\n",
      "Agent3 reward is 19.4\n",
      "Agent4 reward is 19.1\n",
      "Agent5 reward is 23.5\n",
      "Agent6 reward is 21.5\n",
      "Agent7 reward is 19.2\n",
      "Agent8 reward is 22.3\n",
      "Agent9 reward is 2.2\n",
      "Training time per epochs: 3.75 sec\n",
      "[[22.313333333333333, 23.436666666666667, 25.76666666666667, 22.303333333333335, 25.926666666666666, 22.986666666666668], [22.723333333333333, 21.12333333333333, 19.64666666666667, 22.846666666666668, 23.456666666666667, 12.66], [19.31, 16.19, 21.130000000000003, 22.07333333333333, 18.753333333333334, 12.89], [19.259999999999998, 21.326666666666668, 21.493333333333332, 20.82333333333333, 22.326666666666668, 29.21333333333333]]\n",
      "[[21.936666666666667, 23.496666666666666, 22.693333333333335, 25.15, 21.506666666666668, 25.826666666666664], [23.393333333333334, 21.39666666666667, 13.793333333333333, 19.663333333333334, 18.883333333333333, 10.743333333333334], [20.883333333333333, 14.6, 20.083333333333336, 23.080000000000002, 16.533333333333335, 14.943333333333333], [19.946666666666665, 22.12666666666667, 22.71333333333333, 21.57, 23.11, 26.356666666666666]]\n",
      "[[23.19, 23.75, 23.716666666666665, 25.45, 22.85333333333333, 25.080000000000002], [22.163333333333334, 19.330000000000002, 15.669999999999998, 19.82333333333333, 19.369999999999997, 11.643333333333334], [21.663333333333334, 15.246666666666666, 22.32, 23.240000000000002, 13.446666666666667, 12.676666666666666], [19.293333333333333, 21.793333333333333, 22.273333333333333, 19.07333333333333, 20.25, 26.596666666666664]]\n",
      "[[19.85, 22.12666666666667, 25.2, 15.453333333333333, 19.416666666666664, 18.816666666666666], [22.433333333333334, 21.143333333333334, 25.68333333333333, 17.833333333333336, 21.803333333333335, 15.116666666666665], [16.633333333333333, 16.003333333333334, 18.7, 20.936666666666667, 5.86, 15.543333333333333], [18.226666666666667, 20.85, 23.043333333333333, 21.013333333333332, 16.943333333333335, 26.560000000000002]]\n",
      "[[17.543333333333333, 20.8, 24.513333333333332, 21.716666666666665, 23.893333333333334, 19.60333333333333], [17.843333333333334, 18.93, 20.080000000000002, 19.72, 19.53, 11.073333333333334], [16.513333333333332, 15.546666666666667, 22.34, 21.443333333333335, 16.96, 11.440000000000001], [15.62, 19.259999999999998, 19.833333333333336, 18.69, 20.633333333333333, 19.14]]\n",
      "[[18.216666666666665, 19.06, 20.683333333333334, 21.643333333333334, 17.95, 21.62333333333333], [17.483333333333334, 17.32333333333333, 18.759999999999998, 17.003333333333334, 16.796666666666667, 9.440000000000001], [15.95, 14.803333333333333, 19.216666666666665, 17.763333333333332, 15.723333333333333, 13.123333333333331], [16.296666666666667, 18.586666666666666, 18.10333333333333, 17.243333333333332, 20.919999999999998, 20.619999999999997]]\n",
      "[[19.369999999999997, 19.66, 22.34, 22.03, 18.869999999999997, 22.223333333333333], [18.593333333333334, 16.693333333333335, 18.446666666666665, 19.25, 17.276666666666667, 10.17], [16.97, 16.23, 20.193333333333335, 18.666666666666664, 12.623333333333333, 14.533333333333335], [15.16, 17.333333333333336, 18.836666666666666, 16.806666666666665, 16.766666666666666, 21.596666666666668]]\n",
      "[[14.083333333333334, 18.996666666666666, 19.563333333333333, 18.486666666666668, 17.630000000000003, 18.326666666666668], [18.506666666666668, 16.8, 19.66, 18.52, 18.096666666666668, 14.483333333333334], [13.546666666666667, 16.21333333333333, 16.91, 19.2, 16.776666666666667, 14.086666666666668], [14.513333333333332, 17.726666666666667, 18.433333333333334, 18.636666666666667, 20.303333333333335, 22.003333333333334]]\n",
      "[[6.1, 8.266666666666667, 7.7, 6.833333333333333, 7.033333333333333, 6.3], [6.766666666666667, 8.166666666666666, 7.6, 7.266666666666667, 7.033333333333333, 6.866666666666666], [5.3, 7.333333333333333, 7.166666666666667, 6.2, 6.733333333333333, 5.9], [5.633333333333334, 6.933333333333334, 7.366666666666666, 6.466666666666667, 6.966666666666667, 7.8]]\n",
      "[[6.533333333333333, 8.233333333333333, 7.9, 7.466666666666667, 6.933333333333334, 7.0], [7.366666666666666, 9.0, 8.5, 7.6, 7.166666666666667, 7.5], [5.466666666666667, 7.333333333333333, 7.533333333333333, 7.333333333333333, 6.933333333333334, 6.866666666666666], [5.2, 7.233333333333333, 8.066666666666666, 6.966666666666667, 7.333333333333333, 7.733333333333333]]\n",
      "[[6.333333333333333, 8.4, 7.7, 7.633333333333334, 6.833333333333333, 7.266666666666667], [6.966666666666667, 8.4, 8.266666666666667, 7.6, 7.3, 7.6], [5.8, 7.9, 7.466666666666667, 7.133333333333334, 7.066666666666666, 7.0], [5.733333333333333, 7.3, 8.1, 6.733333333333333, 7.1, 7.433333333333334]]\n",
      "[[4.566666666666666, 5.966666666666667, 5.166666666666667, 4.766666666666667, 4.333333333333333, 2.566666666666667], [6.466666666666667, 7.266666666666667, 7.333333333333333, 6.866666666666666, 7.1, 6.6], [4.8, 6.033333333333333, 6.4, 5.133333333333334, 5.866666666666666, 4.333333333333333], [5.266666666666667, 6.833333333333333, 6.933333333333334, 5.933333333333334, 6.3, 6.866666666666666]]\n",
      "[[5.433333333333334, 7.933333333333334, 7.733333333333333, 6.766666666666667, 6.6, 4.866666666666666], [6.233333333333333, 8.133333333333333, 7.033333333333333, 7.0, 7.233333333333333, 5.633333333333334], [4.1, 6.733333333333333, 7.266666666666667, 6.6, 6.4, 5.966666666666667], [4.733333333333333, 6.766666666666667, 7.533333333333333, 6.966666666666667, 7.366666666666666, 7.6]]\n",
      "[[5.433333333333334, 7.6, 7.666666666666667, 7.6, 6.8, 6.7], [6.433333333333334, 8.233333333333333, 8.2, 6.933333333333334, 7.033333333333333, 6.266666666666667], [4.133333333333334, 6.766666666666667, 7.133333333333334, 7.233333333333333, 7.0, 6.466666666666667], [5.266666666666667, 7.1, 7.766666666666667, 6.866666666666666, 7.533333333333333, 7.933333333333334]]\n",
      "[[5.633333333333334, 7.866666666666666, 7.933333333333334, 7.4, 6.7, 7.333333333333333], [6.766666666666667, 8.033333333333333, 7.933333333333334, 7.233333333333333, 7.066666666666666, 6.7], [4.666666666666667, 6.9, 7.266666666666667, 7.166666666666667, 6.966666666666667, 6.633333333333334], [5.233333333333333, 7.166666666666667, 7.8, 6.933333333333334, 7.633333333333334, 8.0]]\n",
      "[[4.366666666666666, 7.2, 7.0, 6.1, 5.033333333333333, 4.9], [6.3, 7.733333333333333, 7.7, 7.9, 7.333333333333333, 6.566666666666666], [3.5, 5.866666666666666, 6.766666666666667, 6.533333333333333, 6.233333333333333, 5.966666666666667], [4.9, 7.1, 7.9, 6.7, 7.466666666666667, 7.6]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\n",
    "    # Agents trained using moving target zone and map = food_d37_river_w1_d25\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_600gs_s1/\",   # scenario=11\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t1.5_rp-1.0_500gs_s2/\",   # scenario=12\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_600gs_s1/\",   # scenario=13\n",
    "    \"models/1T-10L/followers_trajectory/food_d37_river_w1_d25/pacifist_follower/tr5.0_t2.0_rp-1.0_500gs_s2/\"   # scenario=14\n",
    "]\n",
    "\n",
    "episodes = [500, 1000, 1500, 2000, 2500, 3000] \n",
    "\n",
    "game = 'Crossing'\n",
    "map_name = \"food_d37_river_w1_d25\"\n",
    "culture = \"pacifist_follower\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "av_agent_crossed = [[[0 for i in episodes] for j in dir_names] for k in trajectories]  \n",
    "dominating_tribe = [[[None for i in episodes] for j in dir_names] for k in trajectories]\n",
    "dom_tribe_reward = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "dominance = [[[0 for i in episodes] for j in dir_names] for k in trajectories]\n",
    "\n",
    "# There will be 10 agents - 0 teams of 0 AI agents each and 0 random agent\n",
    "num_ai_agents = 10\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = True\n",
    "SPEED = 1/30\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 7\n",
    "max_episodes = 30\n",
    "# max_frames = 800\n",
    "verbose = False\n",
    "\n",
    "# Initialize parameters for Crossing and Explore\n",
    "river_penalty = -1\n",
    "crossed = [0 for i in range(num_ai_agents)]  # Keep track of agents gathering from 2nd food pile\n",
    "second_pile_x = 50   # x-coordinate of the 2nd food pile\n",
    "jumping_zone = False\n",
    "\n",
    "for traj_num, trajectory in enumerate(trajectories):\n",
    "    print (\"###### Trajectory = T{} #######\".format(traj_num+1))\n",
    "    \n",
    "    # Adjust game steps per episode based on the trajectory pacing\n",
    "    max_frames=0\n",
    "    for point in trajectory:\n",
    "        max_frames += point['duration']\n",
    "\n",
    "    position = trajectory [0]  # shift the target zone to first position in trajectory\n",
    "    target_zone = position['loc']  \n",
    "    duration = position['duration']\n",
    "    \n",
    "    for dir_num, dir_name in enumerate(dir_names):\n",
    "        print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "        for eps_num, eps in enumerate(episodes):\n",
    "            print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "            # Load models for AI agents\n",
    "            agents= [[] for i in range(num_ai_agents)]\n",
    "            # If episodes is provided (not 0), load the model for each AI agent\n",
    "            for i in range(num_ai_agents):\n",
    "                model_file = dir_name+'MA{}_{}_ep{}.p'.format(i,game,eps)\n",
    "                try:\n",
    "                    with open(model_file, 'rb') as f:\n",
    "                        print(\"Load saved model for agent {}\".format(i))\n",
    "                        agent = Policy(num_frames, num_actions, 0)\n",
    "                        optimizer = optim.Adam(agent.parameters(), lr=0.1)\n",
    "\n",
    "                        # New way to save and load models - based on: \n",
    "                        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                        _ = load_model(agent, optimizer, f)\n",
    "                        agent.eval()\n",
    "                        agents[i] = agent\n",
    "                except OSError:\n",
    "                    print('Model file not found.')\n",
    "                    raise\n",
    "\n",
    "            # Load random agents    \n",
    "            for i in range(num_ai_agents,num_agents):\n",
    "                # print(\"Load random agent {}\".format(i))\n",
    "                agents.append(Rdn_Policy())\n",
    "        \n",
    "            # Establish tribal association\n",
    "            tribes = []\n",
    "            tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2], agents[3], agents[4], \\\n",
    "                           agents[5], agents[6], agents[7], agents[8], agents[9]]))\n",
    "            tribes[0].set_target_zone(target_zone)\n",
    "\n",
    "            # Set up agent and tribe info to pass into env\n",
    "            agent_colors = [agent.color for agent in agents]\n",
    "            agent_tribes = [agent.tribe for agent in agents]\n",
    "            tribe_names = [tribe.name for tribe in tribes]\n",
    "            tribe_target_zones = [tribe.target_zone for tribe in tribes]\n",
    "        \n",
    "            env = CrossingEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty, tribes=tribe_names, \\\n",
    "                  target_zones=tribe_target_zones, debug_agent=0) \n",
    "\n",
    "            # Used to accumulate episode stats for averaging\n",
    "            cum_rewards = 0\n",
    "            cum_crossed = 0\n",
    "            cum_tags = 0\n",
    "            cum_US_hits = 0\n",
    "            cum_THEM_hits = 0\n",
    "            cum_agent_rewards = [0 for agent in agents]\n",
    "            cum_agent_tags = [0 for agent in agents]\n",
    "            cum_agent_US_hits = [0 for agent in agents]\n",
    "            cum_agent_THEM_hits = [0 for agent in agents]\n",
    "            cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "            cuda = False\n",
    "            start = time.time()\n",
    "\n",
    "            for ep in range(max_episodes):\n",
    "    \n",
    "                print('.', end='')  # To show progress\n",
    "    \n",
    "                # Initialize AI and random agent data\n",
    "                actions = [0 for i in range(num_agents)]\n",
    "                tags = [0 for i in range(num_agents)]\n",
    "                US_hits = [0 for i in range(num_agents)]\n",
    "                THEM_hits = [0 for i in range(num_agents)]\n",
    "            \n",
    "                # Keep track of agents gathering from 2nd food pile\n",
    "                crossed = [0 for i in range(num_ai_agents)]\n",
    "\n",
    "                env_obs = env.reset()  # Environment return observations\n",
    "                \"\"\"\n",
    "                # For Debug only\n",
    "                print (len(agents_obs))\n",
    "                print (agents_obs[0].shape)\n",
    "                \"\"\"\n",
    "    \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "                for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                    agents[i].reset_info()    \n",
    "    \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(SPEED)  # Change speed of video rendering\n",
    "    \n",
    "                \"\"\"\n",
    "                # For Debug only\n",
    "                print (len(agents_obs))\n",
    "                print (agents_obs[0].shape)\n",
    "                \"\"\"\n",
    "    \n",
    "                \"\"\"\n",
    "                For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "                state = np.stack([state]*num_frames)\n",
    "\n",
    "                # Reset LSTM hidden units when episode begins\n",
    "                cx = Variable(torch.zeros(1, 256))\n",
    "                hx = Variable(torch.zeros(1, 256))\n",
    "                \"\"\"\n",
    "    \n",
    "                index = 0\n",
    "                position = trajectory [index]  # shift the target zone to first position in trajectory\n",
    "                env.target_zones[0] = position['loc']  \n",
    "                duration = position['duration']\n",
    "    \n",
    "                for frame in range(max_frames):\n",
    "            \n",
    "                    if (frame+1) % duration == 0:     # time to shift the target zone\n",
    "                        index += 1                    # shift the target zone to new point in trajectory \n",
    "                        if index < len(trajectory):   \n",
    "                            position = trajectory[index]  \n",
    "                            duration = position['duration']\n",
    "                            env.target_zones[0] = position['loc'] \n",
    "             \n",
    "                    for i in range(num_ai_agents):    # For AI agents\n",
    "                        actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                        if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                    for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                        actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                        if actions[i] is 6:\n",
    "                            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                    \"\"\"\n",
    "                    For now, we do not implement LSTM\n",
    "                    # Select action\n",
    "                    action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                    \"\"\"\n",
    "\n",
    "                    # if frame % 10 == 0:\n",
    "                    #     print (actions)    \n",
    "            \n",
    "                    # Perform step        \n",
    "                    env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                    \"\"\"\n",
    "                    For Debug only\n",
    "                    print (env_obs)\n",
    "                    print (reward)\n",
    "                    print (done) \n",
    "                    \"\"\"\n",
    "\n",
    "                    for i in range(num_ai_agents):\n",
    "                        agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                    # Unpack observations into data structure compatible with agent Policy\n",
    "                    agents_obs = unpack_env_obs(env_obs)\n",
    "                    load_info(agents, info, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                    for i in range(num_agents):\n",
    "                        US_hits[i] += agents[i].US_hit\n",
    "                        THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                    \"\"\"\n",
    "                    For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                    # Evict oldest diff add new diff to state\n",
    "                    next_state = np.stack([next_state]*num_frames)\n",
    "                    next_state[1:, :, :] = state[:-1, :, :]\n",
    "                    state = next_state\n",
    "                    \"\"\"\n",
    "        \n",
    "                    if render and ep is 0:   # render only the 1st episode per batch of 30\n",
    "                        env.render()\n",
    "                        time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "                    if any(done):\n",
    "                        print(\"Done after {} frames\".format(frame))\n",
    "                        break\n",
    "                    \n",
    "                    for (i, loc) in env.consumption:\n",
    "                        if loc[0] > second_pile_x:\n",
    "                            # print ('agent {} gathered an apple in 2nd pile'.format(i))\n",
    "                            crossed[i] = 1\n",
    "            \n",
    "                # Print out statistics of AI agents\n",
    "                ep_rewards = 0\n",
    "                ep_tags = 0\n",
    "                ep_US_hits = 0\n",
    "                ep_THEM_hits = 0\n",
    "                ep_crossed = sum(crossed)     # calculated num agents gathering in 2nd pile for episode\n",
    "\n",
    "                if verbose:\n",
    "                    print ('\\nStatistics by Agent')\n",
    "                    print ('===================')\n",
    "                for i in range(num_ai_agents):\n",
    "                    agent_tags = sum(agents[i].tag_hist)\n",
    "                    ep_tags += agent_tags\n",
    "                    cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                    agent_reward = sum(agents[i].rewards)\n",
    "                    ep_rewards += agent_reward\n",
    "                    cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                    agent_US_hits = sum(agents[i].US_hits)\n",
    "                    agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                    ep_US_hits += agent_US_hits\n",
    "                    ep_THEM_hits += agent_THEM_hits\n",
    "                    cum_agent_US_hits[i] += agent_US_hits\n",
    "                    cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                    if verbose:\n",
    "                        # print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                        print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                        # print('US agents hit = {}'.format(agent_US_hits))\n",
    "                        # print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "                cum_rewards += ep_rewards\n",
    "                cum_crossed += ep_crossed\n",
    "                cum_tags += ep_tags\n",
    "                cum_US_hits += ep_US_hits\n",
    "                cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "                if verbose:\n",
    "                    print ('\\nStatistics in Aggregate')\n",
    "                    print ('=======================')\n",
    "                    print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                    print ('Num agents crossed = {}'.format(ep_crossed))\n",
    "                    # print ('Num laser fired = {}'.format(ep_tags))\n",
    "                    # print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                    # print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                    # print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "                if verbose:\n",
    "                    print ('\\nStatistics by Tribe')\n",
    "                    print ('===================')\n",
    "                for i, t in enumerate(tribes):\n",
    "                    if t.name is not 'Crazies':\n",
    "                        ep_tribe_reward = sum(t.sum_rewards())\n",
    "                        cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                        if verbose:\n",
    "                            print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].clear_history()\n",
    "\n",
    "            env.close()  # Close the rendering window\n",
    "            end = time.time()\n",
    "\n",
    "            print ('\\nAverage Statistics in Aggregate')\n",
    "            print ('=================================')\n",
    "            total_rewards = cum_rewards/max_episodes\n",
    "            print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "            av_agent_reward[traj_num][dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "            print ('Av. agent reward = {:.2f}'.format(av_agent_reward[traj_num][dir_num][eps_num]))\n",
    "            av_agent_crossed[traj_num][dir_num][eps_num] = cum_crossed/max_episodes\n",
    "            print ('Agents crossed (2nd food pile) = {:.1f}'.format(av_agent_crossed[traj_num][dir_num][eps_num]))\n",
    "            # print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "            # print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "            # print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "            # print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "            print ('\\nAverage Statistics by Tribe')\n",
    "            print ('=============================')\n",
    "       \n",
    "            for i, tribe in enumerate(tribes):\n",
    "                if tribe.name is not 'Crazies':\n",
    "                    tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                    print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                    # Keep track of dominating team and the rewards gathered (only if more than 1 tribe)\n",
    "                    if len(tribes) > 1:\n",
    "                        if tribe_reward > dom_tribe_reward[traj_num][dir_num][eps_num]:   \n",
    "                            dom_tribe_reward[traj_num][dir_num][eps_num] = tribe_reward\n",
    "                            dominating_tribe[traj_num][dir_num][eps_num]  = tribe.name\n",
    "\n",
    "            # Team dominance calculation (only if more than 1 tribe)\n",
    "            if len(tribes) > 1:\n",
    "                print ('Dominating Tribe: {}'.format(dominating_tribe[traj_num][dir_num][eps_num]))\n",
    "                dominance[traj_num][dir_num][eps_num] = dom_tribe_reward[traj_num][dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[traj_num][dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "                print ('Team dominance: {0:.2f}x'.format(dominance[traj_num][dir_num][eps_num]))\n",
    "\n",
    "            print ('\\nAverage Statistics by Agent')\n",
    "            print ('=============================')\n",
    "            for i in range(num_ai_agents):\n",
    "                # print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                #                                               cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "                print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "                # print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "                # print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "            print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "            # print dominating team and dominance factor (only if more than 1 tribe)\n",
    "            if len(tribes) > 1:\n",
    "                for tribe in dominating_tribe:   # Dominating team\n",
    "                    print(tribe)\n",
    "                for value in dominance:      # Team dominance\n",
    "                    print(value)\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "for agents_crossed in av_agent_crossed:   # Average num agents gathering in 2nd food pile\n",
    "    print(agents_crossed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics for Research Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Agent Rewards\n",
      "For Trajectory 0\n",
      "[22.313333333333333, 23.436666666666667, 25.76666666666667, 22.303333333333335, 25.926666666666666, 22.986666666666668]\n",
      "[22.723333333333333, 21.12333333333333, 19.64666666666667, 22.846666666666668, 23.456666666666667, 12.66]\n",
      "[19.31, 16.19, 21.130000000000003, 22.07333333333333, 18.753333333333334, 12.89]\n",
      "[19.259999999999998, 21.326666666666668, 21.493333333333332, 20.82333333333333, 22.326666666666668, 29.21333333333333]\n",
      "For Trajectory 1\n",
      "[21.936666666666667, 23.496666666666666, 22.693333333333335, 25.15, 21.506666666666668, 25.826666666666664]\n",
      "[23.393333333333334, 21.39666666666667, 13.793333333333333, 19.663333333333334, 18.883333333333333, 10.743333333333334]\n",
      "[20.883333333333333, 14.6, 20.083333333333336, 23.080000000000002, 16.533333333333335, 14.943333333333333]\n",
      "[19.946666666666665, 22.12666666666667, 22.71333333333333, 21.57, 23.11, 26.356666666666666]\n",
      "For Trajectory 2\n",
      "[23.19, 23.75, 23.716666666666665, 25.45, 22.85333333333333, 25.080000000000002]\n",
      "[22.163333333333334, 19.330000000000002, 15.669999999999998, 19.82333333333333, 19.369999999999997, 11.643333333333334]\n",
      "[21.663333333333334, 15.246666666666666, 22.32, 23.240000000000002, 13.446666666666667, 12.676666666666666]\n",
      "[19.293333333333333, 21.793333333333333, 22.273333333333333, 19.07333333333333, 20.25, 26.596666666666664]\n",
      "For Trajectory 3\n",
      "[19.85, 22.12666666666667, 25.2, 15.453333333333333, 19.416666666666664, 18.816666666666666]\n",
      "[22.433333333333334, 21.143333333333334, 25.68333333333333, 17.833333333333336, 21.803333333333335, 15.116666666666665]\n",
      "[16.633333333333333, 16.003333333333334, 18.7, 20.936666666666667, 5.86, 15.543333333333333]\n",
      "[18.226666666666667, 20.85, 23.043333333333333, 21.013333333333332, 16.943333333333335, 26.560000000000002]\n",
      "For Trajectory 4\n",
      "[17.543333333333333, 20.8, 24.513333333333332, 21.716666666666665, 23.893333333333334, 19.60333333333333]\n",
      "[17.843333333333334, 18.93, 20.080000000000002, 19.72, 19.53, 11.073333333333334]\n",
      "[16.513333333333332, 15.546666666666667, 22.34, 21.443333333333335, 16.96, 11.440000000000001]\n",
      "[15.62, 19.259999999999998, 19.833333333333336, 18.69, 20.633333333333333, 19.14]\n",
      "For Trajectory 5\n",
      "[18.216666666666665, 19.06, 20.683333333333334, 21.643333333333334, 17.95, 21.62333333333333]\n",
      "[17.483333333333334, 17.32333333333333, 18.759999999999998, 17.003333333333334, 16.796666666666667, 9.440000000000001]\n",
      "[15.95, 14.803333333333333, 19.216666666666665, 17.763333333333332, 15.723333333333333, 13.123333333333331]\n",
      "[16.296666666666667, 18.586666666666666, 18.10333333333333, 17.243333333333332, 20.919999999999998, 20.619999999999997]\n",
      "For Trajectory 6\n",
      "[19.369999999999997, 19.66, 22.34, 22.03, 18.869999999999997, 22.223333333333333]\n",
      "[18.593333333333334, 16.693333333333335, 18.446666666666665, 19.25, 17.276666666666667, 10.17]\n",
      "[16.97, 16.23, 20.193333333333335, 18.666666666666664, 12.623333333333333, 14.533333333333335]\n",
      "[15.16, 17.333333333333336, 18.836666666666666, 16.806666666666665, 16.766666666666666, 21.596666666666668]\n",
      "For Trajectory 7\n",
      "[14.083333333333334, 18.996666666666666, 19.563333333333333, 18.486666666666668, 17.630000000000003, 18.326666666666668]\n",
      "[18.506666666666668, 16.8, 19.66, 18.52, 18.096666666666668, 14.483333333333334]\n",
      "[13.546666666666667, 16.21333333333333, 16.91, 19.2, 16.776666666666667, 14.086666666666668]\n",
      "[14.513333333333332, 17.726666666666667, 18.433333333333334, 18.636666666666667, 20.303333333333335, 22.003333333333334]\n",
      "Agents Crossed (2nd food pile)\n",
      "For Trajectory 0\n",
      "[6.1, 8.266666666666667, 7.7, 6.833333333333333, 7.033333333333333, 6.3]\n",
      "[6.766666666666667, 8.166666666666666, 7.6, 7.266666666666667, 7.033333333333333, 6.866666666666666]\n",
      "[5.3, 7.333333333333333, 7.166666666666667, 6.2, 6.733333333333333, 5.9]\n",
      "[5.633333333333334, 6.933333333333334, 7.366666666666666, 6.466666666666667, 6.966666666666667, 7.8]\n",
      "For Trajectory 1\n",
      "[6.533333333333333, 8.233333333333333, 7.9, 7.466666666666667, 6.933333333333334, 7.0]\n",
      "[7.366666666666666, 9.0, 8.5, 7.6, 7.166666666666667, 7.5]\n",
      "[5.466666666666667, 7.333333333333333, 7.533333333333333, 7.333333333333333, 6.933333333333334, 6.866666666666666]\n",
      "[5.2, 7.233333333333333, 8.066666666666666, 6.966666666666667, 7.333333333333333, 7.733333333333333]\n",
      "For Trajectory 2\n",
      "[6.333333333333333, 8.4, 7.7, 7.633333333333334, 6.833333333333333, 7.266666666666667]\n",
      "[6.966666666666667, 8.4, 8.266666666666667, 7.6, 7.3, 7.6]\n",
      "[5.8, 7.9, 7.466666666666667, 7.133333333333334, 7.066666666666666, 7.0]\n",
      "[5.733333333333333, 7.3, 8.1, 6.733333333333333, 7.1, 7.433333333333334]\n",
      "For Trajectory 3\n",
      "[4.566666666666666, 5.966666666666667, 5.166666666666667, 4.766666666666667, 4.333333333333333, 2.566666666666667]\n",
      "[6.466666666666667, 7.266666666666667, 7.333333333333333, 6.866666666666666, 7.1, 6.6]\n",
      "[4.8, 6.033333333333333, 6.4, 5.133333333333334, 5.866666666666666, 4.333333333333333]\n",
      "[5.266666666666667, 6.833333333333333, 6.933333333333334, 5.933333333333334, 6.3, 6.866666666666666]\n",
      "For Trajectory 4\n",
      "[5.433333333333334, 7.933333333333334, 7.733333333333333, 6.766666666666667, 6.6, 4.866666666666666]\n",
      "[6.233333333333333, 8.133333333333333, 7.033333333333333, 7.0, 7.233333333333333, 5.633333333333334]\n",
      "[4.1, 6.733333333333333, 7.266666666666667, 6.6, 6.4, 5.966666666666667]\n",
      "[4.733333333333333, 6.766666666666667, 7.533333333333333, 6.966666666666667, 7.366666666666666, 7.6]\n",
      "For Trajectory 5\n",
      "[5.433333333333334, 7.6, 7.666666666666667, 7.6, 6.8, 6.7]\n",
      "[6.433333333333334, 8.233333333333333, 8.2, 6.933333333333334, 7.033333333333333, 6.266666666666667]\n",
      "[4.133333333333334, 6.766666666666667, 7.133333333333334, 7.233333333333333, 7.0, 6.466666666666667]\n",
      "[5.266666666666667, 7.1, 7.766666666666667, 6.866666666666666, 7.533333333333333, 7.933333333333334]\n",
      "For Trajectory 6\n",
      "[5.633333333333334, 7.866666666666666, 7.933333333333334, 7.4, 6.7, 7.333333333333333]\n",
      "[6.766666666666667, 8.033333333333333, 7.933333333333334, 7.233333333333333, 7.066666666666666, 6.7]\n",
      "[4.666666666666667, 6.9, 7.266666666666667, 7.166666666666667, 6.966666666666667, 6.633333333333334]\n",
      "[5.233333333333333, 7.166666666666667, 7.8, 6.933333333333334, 7.633333333333334, 8.0]\n",
      "For Trajectory 7\n",
      "[4.366666666666666, 7.2, 7.0, 6.1, 5.033333333333333, 4.9]\n",
      "[6.3, 7.733333333333333, 7.7, 7.9, 7.333333333333333, 6.566666666666666]\n",
      "[3.5, 5.866666666666666, 6.766666666666667, 6.533333333333333, 6.233333333333333, 5.966666666666667]\n",
      "[4.9, 7.1, 7.9, 6.7, 7.466666666666667, 7.6]\n"
     ]
    }
   ],
   "source": [
    "# Note: Statistics for Research Report   \n",
    "print ('Average Agent Rewards')\n",
    "for k, reward_traj in enumerate(av_agent_reward):   # Average agent reward\n",
    "    print (\"For Trajectory {}\".format(k))\n",
    "    for j, reward in enumerate(reward_traj):\n",
    "        print (reward)\n",
    "    \n",
    "print ('Agents Crossed (2nd food pile)')    \n",
    "for k, crossed_traj in enumerate(av_agent_crossed):   # Average num agents gathering in 2nd food pile\n",
    "    print (\"For Trajectory {}\".format(k))\n",
    "    for j, agents_crossed in enumerate(crossed_traj):\n",
    "        print(agents_crossed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
